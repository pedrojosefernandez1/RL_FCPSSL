{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldaniel-hm/eml_k_bandit/blob/main/MonteCarloTodasLasVisitas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SipaVo-gz1ey"
      },
      "source": [
        "# **Monte Carlo con Políticas epsilon-soft**\n",
        "\n",
        "_Esto es un ejemplo de uso de Gymnasium e informe sobre un experimento de aprendizaje por refuerzo_\n",
        "\n",
        "````\n",
        "Luis D. Hernández.\n",
        "<ldaniel at um.es>\n",
        "````\n",
        "\n",
        "Este notebook describe un experimento de aprendizaje por refuerzo utilizando el algoritmo de Monte Carlo con políticas epsilon-soft. El propósito de este análisis es entrenar un agente en un entorno de gym con el juego \"FrozenLake\", un entorno estándar en el que el agente debe aprender a moverse a través de un mapa en busca de una meta, evitando caer en agujeros. A continuación, se presenta una descripción de las diferentes partes del código y el proceso utilizado en el experimento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loCIjd-T0AVg"
      },
      "source": [
        "## **1. Preparación del Entorno**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2MTvyPWcU2q"
      },
      "source": [
        "La preparación consta de las siguientes partes:\n",
        "- **Instalación de Dependencias**: Se instalan las librerías necesarias para utilizar el entorno `gymnasium` para la simulación, con el objetivo de crear un ambiente controlado para que el agente pueda interactuar.\n",
        "- **Importación de Librerías**: Se importan las bibliotecas necesarias como `numpy` para el manejo de matrices y `matplotlib` para la visualización de los resultados.\n",
        "\n",
        "- **Importación del Entorno \"FrozenLake\"**:\n",
        "Se cargan dos versiones del entorno \"FrozenLake\": una de 4x4 y otra de 8x8. Ambas versiones no son resbaladizas, lo que facilita la comprensión de los resultados, dado que el entorno resbaladizo podría dificultar la comprensión inicial del aprendizaje.\n",
        "\n",
        "#### 3. **Funciones para Mostrar los Resultados**\n",
        "   - Se define una función para graficar la proporción de recompensas obtenidas en cada episodio del entrenamiento. Esto ayuda a visualizar el progreso del agente en términos de su desempeño durante el entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P7_98YrcsZw"
      },
      "source": [
        "##### _________ **Código de la Instalación e Importación**\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "s-wSiHxNyuBH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title Instalamos gym\n",
        "! pip install 'gym[box2d]==0.20.0'\n",
        "! pip install tqdm\n",
        "! pip install gymnasium\n",
        "## Instalación de algunos paquetes.\n",
        "#!apt-get update\n",
        "## Para usar gymnasium[box2d]\n",
        "#!pip install swig\n",
        "#!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "o5s4pz9Hzk7r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['C:\\\\Users\\\\Jaime\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python312.zip', 'C:\\\\Users\\\\Jaime\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\DLLs', 'C:\\\\Users\\\\Jaime\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib', 'C:\\\\Users\\\\Jaime\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv', '', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'src']\n"
          ]
        }
      ],
      "source": [
        "#@title Importamos librerias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import gymnasium as gym\n",
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append('src')\n",
        "\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "0ogCwKft-Ki9"
      },
      "outputs": [],
      "source": [
        "#@title Importamos el lago helado\n",
        "name = 'FrozenLake-v1'\n",
        "env4 = gym.make(name, is_slippery=False, map_name=\"4x4\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados.\n",
        "env8 = gym.make(name, is_slippery=False, map_name=\"8x8\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1ySdi2wdXdm"
      },
      "source": [
        "## **2. Diseño del Agente**\n",
        "\n",
        "El diseño del agente consta de dos partes, el algoritmo con el que aprende y las políticas (toma de decisiones) que realiza.\n",
        "\n",
        "- **Políticas del Agente**\n",
        "   - **Política epsilon-soft**: Se define una política donde todas las acciones tienen una probabilidad de ser elegida.\n",
        "   - **Política epsilon-greedy**: basada en la política epsilon-soft. De esta forma el agente tiene una pequeña probabilidad de explorar (tomar una acción aleatoria) y una mayor probabilidad de explotar (tomar la acción que considera mejor). Esto permite equilibrar la exploración y la explotación.\n",
        "   - **Política greedy**: Es la usada una vez que \"ha aprendido\".\n",
        "\n",
        "- **Algoritmo de Iteración de Valor**\n",
        "  - Se implementa el algoritmo de iteración de valor utilizando Monte Carlo.\n",
        "  - Se usa una versión \"on-policy\" de Monte Carlo con políticas epsilon greedy sobre una política epsilon-soft.\n",
        "  - Se basa en el criterio de todas las visitas.\n",
        "  - Otro aspecto es que la actualización de los retornos no se realiza en el orden inverso a las visitas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vDI1gmKfDPT"
      },
      "source": [
        "#### **Código de las políticas y algoritmo MC**\n",
        "----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "lVEIYzaJ4p8N"
      },
      "outputs": [],
      "source": [
        "# @title Políticas del agente\n",
        "\n",
        "# actions\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "\n",
        "# Política epsilon-soft. Se usa para el entrenamiento\n",
        "def random_epsilon_greedy_policy(Q, epsilon, state, nA):\n",
        "    pi_A = np.ones(nA, dtype=float) * epsilon / nA\n",
        "    best_action = np.argmax(Q[state])\n",
        "    pi_A[best_action] += (1.0 - epsilon)\n",
        "    return pi_A\n",
        "\n",
        "# Política epsilon-greedy a partir de una epsilon-soft\n",
        "def epsilon_greedy_policy(Q, epsilon, state, nA):\n",
        "    pi_A = random_epsilon_greedy_policy(Q, epsilon, state, nA)\n",
        "    return np.random.choice(np.arange(nA), p=pi_A)\n",
        "\n",
        "# Política Greedy a partir de los valones Q. Se usa para mostrar la solución.\n",
        "def pi_star_from_Q(env, Q):\n",
        "    done = False\n",
        "    pi_star = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "    state, info = env.reset() # start in top-left, = 0\n",
        "    actions = \"\"\n",
        "    while not done:\n",
        "        action = np.argmax(Q[state, :])\n",
        "        actions += f\"{action}, \"\n",
        "        pi_star[state,action] = action\n",
        "        state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "    return pi_star, actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpUWKye-7YA1"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3265823854.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    @title Algoritmo de Iteración de Valor versión MC con Políticas epsilon-soft\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#@title Algoritmo de Iteración de Valor versión MC con Políticas epsilon-soft\n",
        "\n",
        "def on_policy_all_visit(env, num_episodes=5000, epsilon=0.4, decay=False, discount_factor=1):\n",
        "  # Matriz de valores  Q\n",
        "  nA = env.action_space.n\n",
        "  Q = np.zeros([env.observation_space.n, nA])\n",
        "\n",
        "  # Número de visitas. Vamoa a realizar la versión incremental.\n",
        "  n_visits = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "  # Para mostrar la evolución en el terminal y algún dato que mostrar\n",
        "  stats = 0.0\n",
        "  list_stats = [stats]\n",
        "  step_display = num_episodes / 10\n",
        "\n",
        "  for t in tqdm(range(num_episodes)):\n",
        "      state, info = env.reset(seed=100)\n",
        "      done = False\n",
        "      episode = []\n",
        "      result_sum = 0.0  # Retorno\n",
        "      factor = 1\n",
        "      while not done:\n",
        "          if decay:\n",
        "            epsilon = min(1.0, 1000.0/(t+1))\n",
        "\n",
        "          action = epsilon_greedy_policy(Q, epsilon, state, nA) # GET ACTION\n",
        "          new_state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "          done = terminated or truncated\n",
        "\n",
        "          episode.append((state, action))\n",
        "          result_sum += factor * reward\n",
        "          factor *= discount_factor\n",
        "          state = new_state\n",
        "\n",
        "      # UPDATE\n",
        "      for (state, action) in episode:\n",
        "          n_visits[state, action] += 1.0\n",
        "          alpha = 1.0 / n_visits[state, action]\n",
        "          Q[state, action] += alpha * (result_sum - Q[state, action])\n",
        "\n",
        "      # Guardamos datos sobre la evolución\n",
        "      stats += result_sum\n",
        "      list_stats.append(stats/(t+1))\n",
        "\n",
        "      # Para mostrar la evolución.  Comentar si no se quiere mostrar\n",
        "      if t % step_display == 0 and t != 0:\n",
        "          print(f\"success: {stats/t}, epsilon: {epsilon}\")\n",
        "\n",
        "  return Q, list_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:51<00:00, 19.47it/s]\n"
          ]
        }
      ],
      "source": [
        "from agents import MonteCarloAgent\n",
        "\n",
        "env = gym.make('FrozenLake-v1', is_slippery=False, map_name='4x4')\n",
        "agent = MonteCarloAgent(env)\n",
        "n_episodes = 1000\n",
        "\n",
        "for episode in tqdm(range(n_episodes)):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        action = agent.get_action(obs)\n",
        "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
        "        agent.update(obs, action, next_obs, reward, terminated, truncated, info)\n",
        "        done = terminated or truncated\n",
        "        obs = next_obs\n",
        "    \n",
        "stats = agent.stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "LEFT, DOWN, RIGHT, UP = 0, 1, 2, 3\n",
        "\n",
        "class AgentNew:\n",
        "    def __init__(self, env: gym.Env, hiperparámetros):\n",
        "        \"\"\"Inicializa todo lo necesario para el aprendizaje\"\"\"\n",
        "        self.env = env\n",
        "        self.epsilon = hiperparámetros.get(\"epsilon\", 0.4)\n",
        "        self.decay = hiperparámetros.get(\"decay\", False)\n",
        "        self.discount_factor = hiperparámetros.get(\"discount_factor\", 1.0)\n",
        "        self.num_episodes = hiperparámetros.get(\"num_episodes\", 5000)\n",
        "        self.nA = env.action_space.n\n",
        "        self.Q = np.zeros([env.observation_space.n, self.nA])\n",
        "        self.n_visits = np.zeros([env.observation_space.n, self.nA])\n",
        "\n",
        "    def get_action(self, state) -> int:\n",
        "        \"\"\"\n",
        "        Indicará qué acción realizar de acuerdo al estado.\n",
        "        Responde a la política del agente.\n",
        "        \"\"\"\n",
        "        return np.random.choice(np.arange(self.nA), p=self.random_epsilon_greedy_policy(state))\n",
        "\n",
        "    def random_epsilon_greedy_policy(self, state):\n",
        "        pi_A = np.ones(self.nA, dtype=float) * self.epsilon / self.nA\n",
        "        best_action = np.argmax(self.Q[state])\n",
        "        pi_A[best_action] += (1.0 - self.epsilon)\n",
        "        return pi_A\n",
        "\n",
        "    def update(self, obs, action, next_obs, reward, terminated, truncated, info):\n",
        "        \"\"\"\n",
        "        Con la muestra (s, a, s', r) e información complementaria aplicamos el algoritmo.\n",
        "        \"\"\"\n",
        "        self.n_visits[obs, action] += 1.0\n",
        "        alpha = 1.0 / self.n_visits[obs, action]\n",
        "        self.Q[obs, action] += alpha * (reward - self.Q[obs, action])\n",
        "\n",
        "    def train(self):\n",
        "        stats = 0.0\n",
        "        list_stats = [stats]\n",
        "        step_display = self.num_episodes / 10\n",
        "\n",
        "        for t in tqdm(range(self.num_episodes)):\n",
        "            state, _ = self.env.reset()\n",
        "            done = False\n",
        "            episode = []\n",
        "            result_sum = 0.0\n",
        "            factor = 1.0\n",
        "\n",
        "            while not done:\n",
        "                if self.decay:\n",
        "                    self.epsilon = min(1.0, 1000.0 / (t + 1))\n",
        "                action = self.get_action(state)\n",
        "                next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
        "                done = terminated or truncated\n",
        "                episode.append((state, action))\n",
        "                result_sum += factor * reward\n",
        "                factor *= self.discount_factor\n",
        "                state = next_state\n",
        "\n",
        "            for (state, action) in episode:\n",
        "                self.update(state, action, None, result_sum, None, None, None)\n",
        "\n",
        "            stats += result_sum\n",
        "            list_stats.append(stats / (t + 1))\n",
        "\n",
        "            if t % step_display == 0 and t != 0:\n",
        "                print(f\"Episode {t}: Success rate {stats/t:.3f}, epsilon {self.epsilon:.3f}\")\n",
        "        \n",
        "        return list_stats\n",
        "\n",
        "    def evaluate_policy(self, num_episodes=100):\n",
        "        total_rewards = []\n",
        "        for _ in range(num_episodes):\n",
        "            state, _ = self.env.reset()\n",
        "            done = False\n",
        "            total_reward = 0\n",
        "            while not done:\n",
        "                action = np.argmax(self.Q[state, :])\n",
        "                state, reward, terminated, truncated, _ = self.env.step(action)\n",
        "                total_reward += reward\n",
        "                done = terminated or truncated\n",
        "            total_rewards.append(total_reward)\n",
        "        \n",
        "        avg_reward = np.mean(total_rewards)\n",
        "        print(f\"Evaluación: Recompensa media en {num_episodes} episodios = {avg_reward:.2f}\")\n",
        "        return avg_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 731/5000 [00:00<00:02, 1809.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 500: Success rate 0.008, epsilon 1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 1318/5000 [00:00<00:02, 1770.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1000: Success rate 0.011, epsilon 0.999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 1693/5000 [00:00<00:01, 1796.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 1500: Success rate 0.013, epsilon 0.666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 2226/5000 [00:01<00:01, 1694.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 2000: Success rate 0.019, epsilon 0.500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 2733/5000 [00:01<00:01, 1634.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 2500: Success rate 0.024, epsilon 0.400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 3221/5000 [00:01<00:01, 1592.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 3000: Success rate 0.027, epsilon 0.333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 3712/5000 [00:02<00:00, 1619.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 3500: Success rate 0.031, epsilon 0.286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 4221/5000 [00:02<00:00, 1535.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 4000: Success rate 0.034, epsilon 0.250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 4710/5000 [00:02<00:00, 1590.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 4500: Success rate 0.036, epsilon 0.222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:03<00:00, 1641.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluación: Recompensa media en 100 episodios = 0.11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"FrozenLake-v1\", is_slippery=True, render_mode=None)\n",
        "hiperparámetros = {\"epsilon\": 0.4, \"decay\": True, \"discount_factor\": 1.0, \"num_episodes\": 5000}\n",
        "\n",
        "agent = AgentNew(env, hiperparámetros)\n",
        "agent.train()\n",
        "agent.evaluate_policy()\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'AgentNew' object has no attribute 'stats'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m()\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'AgentNew' object has no attribute 'stats'"
          ]
        }
      ],
      "source": [
        "agent.stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Q-table': array([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]]),\n",
              " 'episode_rewards': []}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XxVyTFTfVkL"
      },
      "source": [
        "## **3. Experimentación**\n",
        "\n",
        "   - En esta sección, el algoritmo de Monte Carlo con la política epsilon-soft se ejecuta tanto para el entorno de 4x4 como al de 8x8 de FrozenLake sin resbalar.\n",
        "   \n",
        "   - En ambos casos se realiza un entrenamiento con un número determinado de episodios (5000 en concreto)\n",
        "\n",
        "   - Además en el escenario 8x8 el  epsilon tiene decaimiento de acuerdo a la expresión: $\\epsilon = min(1.0, 1000.0/(t+1))$\n",
        "\n",
        "   - Durante el entrenamiento hay una visualización de la proporción de recompensas obtenidas a lo largo del entrenamiento.\n",
        "\n",
        "   - Junto a dicho volcado se muestra gráficamente la proporcion de recompensas obtendias.\n",
        "\n",
        "   - También se hace un volcado de los valores Q de cada estado, donde se muestra cómo el agente valora diferentes acciones en distintos estados del entorno, lo que puede interpretarse como su conocimiento sobre las mejores estrategias para alcanzar la meta sin caer en los agujeros.\n",
        "\n",
        "   - Además, se muestra la política óptima derivada de los valores Q. Esta política es la que el agente seguiría si tuviera que elegir siempre la acción que maximiza su recompensa esperada.\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqdLUE8zQN2v"
      },
      "source": [
        "### **3.1 Repressentaciones Gráficas**\n",
        "\n",
        "Para comprobar el aprendizaje se mostrará la función $f(t)=\\frac{\\sum_{i=1}^t R_i}{t}$ para $t=1,2,\\ldots, NumeroEpisodios$. La justificación es la siguiente. Como sabemmos que el retorno en el estados inicial 1 (pues no hay descuento) o 9, si se divide por el número de episodios ejecutados se calcular el porcentaje de recompensas positivas obtenidas. Dicho de otra forma, nos dirá el porcentaje de veces que el agente ha llegado al estado terminal.\n",
        "\n",
        "*TODO:* Contruir una gráfica que muestre la longitud de los episodios en cada estado junto con la curva de tendencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u42-YlgazukU"
      },
      "outputs": [],
      "source": [
        "# @title Funciones para mostrar los resultados\n",
        "\n",
        "def plot(list_stats):\n",
        "  # Creamos una lista de índices para el eje x\n",
        "  indices = list(range(len(list_stats)))\n",
        "\n",
        "  # Creamos el gráfico\n",
        "  plt.figure(figsize=(6, 3))\n",
        "  plt.plot(indices, list_stats)\n",
        "\n",
        "  # Añadimos título y etiquetas\n",
        "  plt.title('Proporción de recompensas')\n",
        "  plt.xlabel('Episodio')\n",
        "  plt.ylabel('Proporción')\n",
        "\n",
        "  # Mostramos el gráfico\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "# Define la función para mostrar el tamaño de los episodios\n",
        "# Pon aquí tu código."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvnGJVGF_j2j"
      },
      "source": [
        "### **3.2 Experimentación en el escenario 4x4**\n",
        "\n",
        "\n",
        "\n",
        "   - Se realizan 5000 epsisodios y se actualizan los valores Q (valor de acción) basándose en las recompensas obtenidas durante cada episodio completo (e.d. aplicamos Monte Carlo) Se apica una política $\\epsilon$ greedy sobre una política $\\epsilon$ soft con un valor $\\epsilon$ constante\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "j_Dronjr_mAN",
        "outputId": "1c0f7ad3-0686-494e-b7eb-1b4a49573329"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 5331/50000 [00:03<00:24, 1860.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.2638, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 10320/50000 [00:06<00:21, 1868.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.3693, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 15345/50000 [00:08<00:18, 1832.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.4036666666666667, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 20221/50000 [00:11<00:17, 1747.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.4234, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 25181/50000 [00:14<00:15, 1652.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.43328, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 30299/50000 [00:17<00:11, 1764.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.43976666666666664, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 35404/50000 [00:20<00:05, 2732.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.4471428571428571, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 40364/50000 [00:21<00:02, 3234.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.457275, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 45340/50000 [00:23<00:01, 3228.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.465, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:24<00:00, 2028.91it/s]\n"
          ]
        }
      ],
      "source": [
        "# @title Aprendizaje\n",
        "Q, list_stats = on_policy_all_visit(env4, num_episodes=50000, epsilon=0.4, discount_factor=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "KLhdk1SFtn8S",
        "outputId": "30d22b75-74ae-4735-99a7-0401d3a836ea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Máxima proporcion: 0.47004\n"
          ]
        }
      ],
      "source": [
        "#@title Proporción de aciertos por número de episodios\n",
        "\n",
        "plot(list_stats)\n",
        "print(f\"Máxima proporcion: {list_stats[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoP1jHL_StI9"
      },
      "source": [
        "####.\n",
        "Mostramos los valores Q para cada estado. Cada estado tienen 4 valores, que se corresponden con las 4 acciones que se pueden en cada estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "psRtMmxyFkFq",
        "outputId": "f9e44658-ea7b-49fe-affb-b1453c055dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores Q para cada estado:\n",
            " [[0.29589277 0.3994403  0.49264012 0.47290253]\n",
            " [0.35187396 0.         0.59760714 0.4847541 ]\n",
            " [0.50523343 0.62551897 0.52461677 0.59503106]\n",
            " [0.59880609 0.         0.49255952 0.53846154]\n",
            " [0.14051702 0.45153115 0.         0.45640172]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.80099237 0.         0.62467866]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.06582399 0.         0.60414585 0.22088353]\n",
            " [0.40533981 0.75925926 0.79355889 0.        ]\n",
            " [0.6935609  0.95633637 0.         0.62506329]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.78969957 0.96081606 0.68197279]\n",
            " [0.81329394 0.96070786 1.         0.80140804]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "# @title Tabla de valores Q\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "print(\"Valores Q para cada estado:\\n\", Q)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsJ-AgwcTgdO"
      },
      "source": [
        "- También se muestra la política óptima (greedy) obtenida a partir del aprendizaje anterior.\n",
        "\n",
        "- Cada estado tienen 4 valores, pero todos son 0 menos 1. Es decir, en cada estado se aplica de manera determinística una única acción.\n",
        "\n",
        "*TODO:* Mostrar de forma gráfica el escenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "dA0-q-woGYL2",
        "outputId": "b5cfb689-5329-49d1-8c47-b96de08a5105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Política óptima obtenida\n",
            " [[0. 0. 2. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 0.]] \n",
            " Acciones 2, 2, 1, 1, 1, 2,  \n",
            " Para el siguiente grid\n",
            "   (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Política final\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "pi, actions = pi_star_from_Q(env4, Q)\n",
        "\n",
        "print(\"Política óptima obtenida\\n\", pi, f\"\\n Acciones {actions} \\n Para el siguiente grid\\n\", env4.render())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tUyGCBuS41T"
      },
      "source": [
        "### **3.3 Experimentación en el escenario 8x8**\n",
        "\n",
        "  - Se realizan 5000 epsisodios y se actualizan los valores Q (valor de acción) basándose en las recompensas obtenidas durante cada episodio completo (e.d. aplicamos Monte Carlo) Se apica una política $\\epsilon$ greedy sobre una política $\\epsilon$ soft con un valor $\\epsilon$ decreciente\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "ttDsqDX16sSj",
        "outputId": "ea0da61a-0fd7-4fad-b75e-f92deaaf6551"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5046/50000 [00:12<02:27, 304.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.19996000799840033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 10052/50000 [00:30<02:15, 294.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.0999900009999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 15040/50000 [00:48<02:00, 290.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.06666222251849876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 20033/50000 [01:06<02:22, 210.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.04999750012499375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 25032/50000 [01:24<01:34, 264.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.03999840006399744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 30031/50000 [01:42<01:12, 276.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.033332222259258026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 35057/50000 [02:01<00:54, 272.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.02857061226822091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 40026/50000 [02:19<00:35, 281.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.02499937501562461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 45036/50000 [02:37<00:17, 280.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.02222172840603542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [02:55<00:00, 285.50it/s]\n"
          ]
        }
      ],
      "source": [
        "# @title Aprendizaje\n",
        "Q, list_stats = on_policy_all_visit(env8, num_episodes=50000, epsilon=0.4, decay=True, discount_factor=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Z_tbLcAq6yWR",
        "outputId": "bd14600f-00cd-4cc1-a5d0-81f972a3a295"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Máxima proporcion: 0.0\n"
          ]
        }
      ],
      "source": [
        "#@title Proporción de aciertos por número de episodios\n",
        "\n",
        "plot(list_stats)\n",
        "print(f\"Máxima proporcion: {list_stats[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dptS3Xv8v8H7"
      },
      "source": [
        "####.\n",
        "Mostramos los valores Q para cada estado. Cada estado tienen 4 valores, que se corresponden con las 4 acciones que se pueden en cada estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "scmn1mwlwBam",
        "outputId": "f2597e0f-bcd0-4daa-e4a3-0e939279f24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores Q para cada estado:\n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# @title Tabla de valores Q\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "print(\"Valores Q para cada estado:\\n\", Q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWQWD7UqwH2Y"
      },
      "source": [
        "- También se muestra la política óptima (greedy) obtenida a partir del aprendizaje anterior.\n",
        "\n",
        "- Cada estado tienen 4 valores, pero todos son 0 menos 1. Es decir, en cada estado se aplica de manera determinística una única acción.\n",
        "\n",
        "*TODO:* Mostrar de forma gráfica el escenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1n6i3oMzwSG3",
        "outputId": "0dd2772e-e096-41d8-e2ae-18d809e2b098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Política óptima obtenida\n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]] \n",
            " Acciones 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  \n",
            " Para el siguiente grid\n",
            "   (Left)\n",
            "\u001b[41mS\u001b[0mFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Política final\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "pi, actions = pi_star_from_Q(env8, Q)\n",
        "\n",
        "print(\"Política óptima obtenida\\n\", pi, f\"\\n Acciones {actions} \\n Para el siguiente grid\\n\", env8.render())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG0Z813yhKz7"
      },
      "source": [
        "## **4. Análisis y Estudios Futuros**\n",
        "\n",
        "### **4.1 Análisis de Resultados**\n",
        "\n",
        "- En los dos entornos (4x4 y 8x8), el agente comienza con un conocimiento muy limitado, pero gradualmente mejora su desempeño a medida que avanza en los episodios. Este comportamiento se puede observar en el gráfico de la proporción de recompensas, que aumenta con el tiempo.\n",
        "- En el entorno 4x4, la máxima proporción de éxito alcanzada fue 0.522, mientras que en el entorno 8x8, la máxima alcanzada fue 0.914. Esto refleja que el agente aprendió a optimizar su estrategia en un entorno más complejo.\n",
        "- La política óptima obtenida muestra las acciones recomendadas por el agente en cada estado del entorno. En el entorno 8x8, la política es más compleja debido a la mayor cantidad de estados y la dificultad del entorno.\n",
        "\n",
        "### **4.2 Propuestas para Estudios Futuros**\n",
        "\n",
        "1. **Evaluar con Otros Entornos**: Sería interesante aplicar este algoritmo a otros entornos más complejos de `gym`, como \"Taxi-v3\" o \"MountainCar\", para analizar cómo se comporta el agente en situaciones con dinámicas más complicadas.\n",
        "   \n",
        "2. **Optimización del Decaimiento de Epsilon**: Aunque se utilizó un decaimiento de epsilon en el segundo experimento, se podría investigar la efectividad de diferentes tasas de decaimiento o incluso explorar algoritmos como `Q-learning` para comparar su desempeño. Graficamente se trataría de mostrar la curva de la tasa de aciertos para distintas funciones de decaimientos\n",
        "\n",
        "3. **Análisis del Impacto de los descuentos en las Recompensas**: El estudio se ha hecho para $\\gamma = 1$; pero no se ha probado qué pasa cuando  $0 \\leq \\gamma < 1$. Se trataría de estudiar la curva para distintos valores de $\\gamma$\n",
        "\n",
        "4. **Nuevas gráficas**: Aquí solo se ha usado la proporción de aciertos, pero sería interesante qué relación entre dicha tasa y las tamaños de los episodios.\n",
        "\n",
        "4. **Ampliación del Algoritmo**: Explorar otros enfoques de Monte Carlo o incluso combinar Monte Carlo con otros algoritmos de aprendizaje por refuerzo, como el Deep Q-Network (DQN), podría mejorar aún más los resultados en entornos más complejos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNjZJK7Hx6/LtHVZ0/ulFcl",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

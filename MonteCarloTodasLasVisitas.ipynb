{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldaniel-hm/eml_k_bandit/blob/main/MonteCarloTodasLasVisitas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SipaVo-gz1ey"
      },
      "source": [
        "# **Monte Carlo con Políticas epsilon-soft**\n",
        "\n",
        "_Esto es un ejemplo de uso de Gymnasium e informe sobre un experimento de aprendizaje por refuerzo_\n",
        "\n",
        "````\n",
        "Luis D. Hernández.\n",
        "<ldaniel at um.es>\n",
        "````\n",
        "\n",
        "Este notebook describe un experimento de aprendizaje por refuerzo utilizando el algoritmo de Monte Carlo con políticas epsilon-soft. El propósito de este análisis es entrenar un agente en un entorno de gym con el juego \"FrozenLake\", un entorno estándar en el que el agente debe aprender a moverse a través de un mapa en busca de una meta, evitando caer en agujeros. A continuación, se presenta una descripción de las diferentes partes del código y el proceso utilizado en el experimento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loCIjd-T0AVg"
      },
      "source": [
        "## **1. Preparación del Entorno**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2MTvyPWcU2q"
      },
      "source": [
        "La preparación consta de las siguientes partes:\n",
        "- **Instalación de Dependencias**: Se instalan las librerías necesarias para utilizar el entorno `gymnasium` para la simulación, con el objetivo de crear un ambiente controlado para que el agente pueda interactuar.\n",
        "- **Importación de Librerías**: Se importan las bibliotecas necesarias como `numpy` para el manejo de matrices y `matplotlib` para la visualización de los resultados.\n",
        "\n",
        "- **Importación del Entorno \"FrozenLake\"**:\n",
        "Se cargan dos versiones del entorno \"FrozenLake\": una de 4x4 y otra de 8x8. Ambas versiones no son resbaladizas, lo que facilita la comprensión de los resultados, dado que el entorno resbaladizo podría dificultar la comprensión inicial del aprendizaje.\n",
        "\n",
        "#### 3. **Funciones para Mostrar los Resultados**\n",
        "   - Se define una función para graficar la proporción de recompensas obtenidas en cada episodio del entrenamiento. Esto ayuda a visualizar el progreso del agente en términos de su desempeño durante el entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P7_98YrcsZw"
      },
      "source": [
        "##### _________ **Código de la Instalación e Importación**\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "s-wSiHxNyuBH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Requirement already satisfied: gymnasium in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium) (2.2.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: gymnasium[toy-text] in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[toy-text]) (2.2.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[toy-text]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[toy-text]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[toy-text]) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[toy-text]) (2.6.1)\n",
            "Requirement already satisfied: gymnasium[other] in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[other]) (2.2.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[other]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[other]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[other]) (0.0.4)\n",
            "Collecting moviepy>=1.0.0 (from gymnasium[other])\n",
            "  Downloading moviepy-2.1.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: matplotlib>=3.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from gymnasium[other]) (3.10.0)\n",
            "Collecting opencv-python>=3.0 (from gymnasium[other])\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from matplotlib>=3.0->gymnasium[other]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from matplotlib>=3.0->gymnasium[other]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from matplotlib>=3.0->gymnasium[other]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from matplotlib>=3.0->gymnasium[other]) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from matplotlib>=3.0->gymnasium[other]) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from matplotlib>=3.0->gymnasium[other]) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from matplotlib>=3.0->gymnasium[other]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from matplotlib>=3.0->gymnasium[other]) (2.9.0.post0)\n",
            "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from moviepy>=1.0.0->gymnasium[other]) (5.1.1)\n",
            "Collecting imageio<3.0,>=2.5 (from moviepy>=1.0.0->gymnasium[other])\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting imageio_ffmpeg>=0.2.0 (from moviepy>=1.0.0->gymnasium[other])\n",
            "  Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
            "Collecting proglog<=1.0.0 (from moviepy>=1.0.0->gymnasium[other])\n",
            "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting python-dotenv>=0.10 (from moviepy>=1.0.0->gymnasium[other])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pillow>=8 (from matplotlib>=3.0->gymnasium[other])\n",
            "  Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from proglog<=1.0.0->moviepy>=1.0.0->gymnasium[other]) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0->gymnasium[other]) (1.17.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\jaime\\desktop\\master\\eml_2\\.venv\\lib\\site-packages (from tqdm->proglog<=1.0.0->moviepy>=1.0.0->gymnasium[other]) (0.4.6)\n",
            "Downloading moviepy-2.1.2-py3-none-any.whl (126 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
            "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.3/39.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.3/39.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.3/39.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.3/39.5 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.5/39.5 MB 305.2 kB/s eta 0:02:08\n",
            "    --------------------------------------- 0.5/39.5 MB 305.2 kB/s eta 0:02:08\n",
            "    --------------------------------------- 0.5/39.5 MB 305.2 kB/s eta 0:02:08\n",
            "    --------------------------------------- 0.5/39.5 MB 305.2 kB/s eta 0:02:08\n",
            "    --------------------------------------- 0.5/39.5 MB 305.2 kB/s eta 0:02:08\n",
            "    --------------------------------------- 0.5/39.5 MB 305.2 kB/s eta 0:02:08\n",
            "    --------------------------------------- 0.5/39.5 MB 305.2 kB/s eta 0:02:08\n",
            "    --------------------------------------- 0.5/39.5 MB 305.2 kB/s eta 0:02:08\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "    --------------------------------------- 0.8/39.5 MB 216.5 kB/s eta 0:02:59\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.0/39.5 MB 147.2 kB/s eta 0:04:22\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.3/39.5 MB 126.9 kB/s eta 0:05:01\n",
            "   - -------------------------------------- 1.6/39.5 MB 92.9 kB/s eta 0:06:49\n",
            "   - -------------------------------------- 1.6/39.5 MB 92.9 kB/s eta 0:06:49\n",
            "   - -------------------------------------- 1.6/39.5 MB 92.9 kB/s eta 0:06:49\n",
            "   - -------------------------------------- 1.6/39.5 MB 92.9 kB/s eta 0:06:49\n",
            "   - -------------------------------------- 1.6/39.5 MB 92.9 kB/s eta 0:06:49\n",
            "   - -------------------------------------- 1.8/39.5 MB 104.6 kB/s eta 0:06:00\n",
            "   - -------------------------------------- 1.8/39.5 MB 104.6 kB/s eta 0:06:00\n",
            "   - -------------------------------------- 1.8/39.5 MB 104.6 kB/s eta 0:06:00\n",
            "   -- ------------------------------------- 2.1/39.5 MB 117.0 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 2.1/39.5 MB 117.0 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 2.1/39.5 MB 117.0 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 2.1/39.5 MB 117.0 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 2.4/39.5 MB 127.2 kB/s eta 0:04:52\n",
            "   -- ------------------------------------- 2.4/39.5 MB 127.2 kB/s eta 0:04:52\n",
            "   -- ------------------------------------- 2.4/39.5 MB 127.2 kB/s eta 0:04:52\n",
            "   -- ------------------------------------- 2.6/39.5 MB 137.6 kB/s eta 0:04:28\n",
            "   -- ------------------------------------- 2.6/39.5 MB 137.6 kB/s eta 0:04:28\n",
            "   -- ------------------------------------- 2.9/39.5 MB 148.5 kB/s eta 0:04:07\n",
            "   -- ------------------------------------- 2.9/39.5 MB 148.5 kB/s eta 0:04:07\n",
            "   --- ------------------------------------ 3.1/39.5 MB 159.0 kB/s eta 0:03:49\n",
            "   --- ------------------------------------ 3.1/39.5 MB 159.0 kB/s eta 0:03:49\n",
            "   --- ------------------------------------ 3.4/39.5 MB 170.2 kB/s eta 0:03:33\n",
            "   --- ------------------------------------ 3.4/39.5 MB 170.2 kB/s eta 0:03:33\n",
            "   --- ------------------------------------ 3.7/39.5 MB 180.4 kB/s eta 0:03:19\n",
            "   --- ------------------------------------ 3.7/39.5 MB 180.4 kB/s eta 0:03:19\n",
            "   --- ------------------------------------ 3.9/39.5 MB 190.0 kB/s eta 0:03:08\n",
            "   ---- ----------------------------------- 4.2/39.5 MB 200.4 kB/s eta 0:02:57\n",
            "   ---- ----------------------------------- 4.2/39.5 MB 200.4 kB/s eta 0:02:57\n",
            "   ---- ----------------------------------- 4.5/39.5 MB 210.4 kB/s eta 0:02:47\n",
            "   ---- ----------------------------------- 4.7/39.5 MB 220.7 kB/s eta 0:02:38\n",
            "   ----- ---------------------------------- 5.0/39.5 MB 230.9 kB/s eta 0:02:30\n",
            "   ----- ---------------------------------- 5.2/39.5 MB 240.8 kB/s eta 0:02:23\n",
            "   ----- ---------------------------------- 5.5/39.5 MB 251.5 kB/s eta 0:02:16\n",
            "   ------ --------------------------------- 6.0/39.5 MB 272.0 kB/s eta 0:02:04\n",
            "   ------ --------------------------------- 6.3/39.5 MB 283.3 kB/s eta 0:01:58\n",
            "   ------ --------------------------------- 6.6/39.5 MB 293.5 kB/s eta 0:01:53\n",
            "   ------- -------------------------------- 7.1/39.5 MB 312.0 kB/s eta 0:01:44\n",
            "   ------- -------------------------------- 7.1/39.5 MB 312.0 kB/s eta 0:01:44\n",
            "   ------- -------------------------------- 7.3/39.5 MB 320.6 kB/s eta 0:01:41\n",
            "   ------- -------------------------------- 7.9/39.5 MB 338.8 kB/s eta 0:01:34\n",
            "   -------- ------------------------------- 8.1/39.5 MB 346.9 kB/s eta 0:01:31\n",
            "   -------- ------------------------------- 8.1/39.5 MB 346.9 kB/s eta 0:01:31\n",
            "   -------- ------------------------------- 8.4/39.5 MB 354.3 kB/s eta 0:01:28\n",
            "   --------- ------------------------------ 8.9/39.5 MB 372.1 kB/s eta 0:01:23\n",
            "   --------- ------------------------------ 9.4/39.5 MB 389.4 kB/s eta 0:01:18\n",
            "   --------- ------------------------------ 9.7/39.5 MB 398.9 kB/s eta 0:01:15\n",
            "   ---------- ----------------------------- 10.2/39.5 MB 416.7 kB/s eta 0:01:11\n",
            "   ---------- ----------------------------- 10.5/39.5 MB 424.6 kB/s eta 0:01:09\n",
            "   ----------- ---------------------------- 11.0/39.5 MB 440.6 kB/s eta 0:01:05\n",
            "   ----------- ---------------------------- 11.3/39.5 MB 448.2 kB/s eta 0:01:03\n",
            "   ----------- ---------------------------- 11.5/39.5 MB 455.7 kB/s eta 0:01:02\n",
            "   ------------ --------------------------- 12.1/39.5 MB 470.7 kB/s eta 0:00:59\n",
            "   ------------ --------------------------- 12.3/39.5 MB 477.9 kB/s eta 0:00:57\n",
            "   ------------ --------------------------- 12.6/39.5 MB 483.8 kB/s eta 0:00:56\n",
            "   ------------- -------------------------- 12.8/39.5 MB 492.5 kB/s eta 0:00:55\n",
            "   ------------- -------------------------- 13.4/39.5 MB 506.6 kB/s eta 0:00:52\n",
            "   ------------- -------------------------- 13.6/39.5 MB 513.0 kB/s eta 0:00:51\n",
            "   -------------- ------------------------- 13.9/39.5 MB 519.6 kB/s eta 0:00:50\n",
            "   -------------- ------------------------- 14.4/39.5 MB 534.8 kB/s eta 0:00:47\n",
            "   --------------- ------------------------ 14.9/39.5 MB 548.2 kB/s eta 0:00:45\n",
            "   --------------- ------------------------ 15.2/39.5 MB 554.7 kB/s eta 0:00:44\n",
            "   --------------- ------------------------ 15.5/39.5 MB 562.5 kB/s eta 0:00:43\n",
            "   ---------------- ----------------------- 16.0/39.5 MB 573.9 kB/s eta 0:00:41\n",
            "   ---------------- ----------------------- 16.3/39.5 MB 581.1 kB/s eta 0:00:40\n",
            "   ---------------- ----------------------- 16.8/39.5 MB 593.1 kB/s eta 0:00:39\n",
            "   ----------------- ---------------------- 17.0/39.5 MB 598.5 kB/s eta 0:00:38\n",
            "   ----------------- ---------------------- 17.6/39.5 MB 613.8 kB/s eta 0:00:36\n",
            "   ------------------ --------------------- 17.8/39.5 MB 619.3 kB/s eta 0:00:35\n",
            "   ------------------ --------------------- 18.1/39.5 MB 624.4 kB/s eta 0:00:35\n",
            "   ------------------ --------------------- 18.6/39.5 MB 635.9 kB/s eta 0:00:33\n",
            "   ------------------- -------------------- 18.9/39.5 MB 642.2 kB/s eta 0:00:33\n",
            "   ------------------- -------------------- 19.4/39.5 MB 651.8 kB/s eta 0:00:31\n",
            "   ------------------- -------------------- 19.7/39.5 MB 657.9 kB/s eta 0:00:31\n",
            "   -------------------- ------------------- 20.2/39.5 MB 669.3 kB/s eta 0:00:29\n",
            "   -------------------- ------------------- 20.4/39.5 MB 674.6 kB/s eta 0:00:29\n",
            "   -------------------- ------------------- 20.7/39.5 MB 691.2 kB/s eta 0:00:28\n",
            "   --------------------- ------------------ 21.0/39.5 MB 694.2 kB/s eta 0:00:27\n",
            "   --------------------- ------------------ 21.2/39.5 MB 697.2 kB/s eta 0:00:27\n",
            "   --------------------- ------------------ 21.5/39.5 MB 699.8 kB/s eta 0:00:26\n",
            "   ---------------------- ----------------- 21.8/39.5 MB 734.6 kB/s eta 0:00:25\n",
            "   ---------------------- ----------------- 22.3/39.5 MB 744.4 kB/s eta 0:00:24\n",
            "   ---------------------- ----------------- 22.5/39.5 MB 749.5 kB/s eta 0:00:23\n",
            "   ----------------------- ---------------- 22.8/39.5 MB 754.0 kB/s eta 0:00:23\n",
            "   ----------------------- ---------------- 23.1/39.5 MB 756.5 kB/s eta 0:00:22\n",
            "   ----------------------- ---------------- 23.6/39.5 MB 768.2 kB/s eta 0:00:21\n",
            "   ------------------------ --------------- 23.9/39.5 MB 771.0 kB/s eta 0:00:21\n",
            "   ------------------------ --------------- 24.1/39.5 MB 847.1 kB/s eta 0:00:19\n",
            "   ------------------------ --------------- 24.4/39.5 MB 849.8 kB/s eta 0:00:18\n",
            "   ------------------------ --------------- 24.4/39.5 MB 849.8 kB/s eta 0:00:18\n",
            "   ------------------------- -------------- 24.9/39.5 MB 854.3 kB/s eta 0:00:18\n",
            "   ------------------------- -------------- 25.2/39.5 MB 858.0 kB/s eta 0:00:17\n",
            "   ------------------------- -------------- 25.4/39.5 MB 860.1 kB/s eta 0:00:17\n",
            "   -------------------------- ------------- 25.7/39.5 MB 865.1 kB/s eta 0:00:16\n",
            "   -------------------------- ------------- 26.0/39.5 MB 870.0 kB/s eta 0:00:16\n",
            "   -------------------------- ------------- 26.5/39.5 MB 878.7 kB/s eta 0:00:15\n",
            "   --------------------------- ------------ 26.7/39.5 MB 880.6 kB/s eta 0:00:15\n",
            "   --------------------------- ------------ 27.3/39.5 MB 891.5 kB/s eta 0:00:14\n",
            "   --------------------------- ------------ 27.5/39.5 MB 895.1 kB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 27.8/39.5 MB 898.8 kB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 28.0/39.5 MB 905.2 kB/s eta 0:00:13\n",
            "   ---------------------------- ----------- 28.6/39.5 MB 1.0 MB/s eta 0:00:11\n",
            "   ----------------------------- ---------- 28.8/39.5 MB 1.0 MB/s eta 0:00:11\n",
            "   ----------------------------- ---------- 29.4/39.5 MB 1.0 MB/s eta 0:00:10\n",
            "   ------------------------------ --------- 29.6/39.5 MB 1.0 MB/s eta 0:00:10\n",
            "   ------------------------------ --------- 30.1/39.5 MB 1.0 MB/s eta 0:00:10\n",
            "   ------------------------------- -------- 30.7/39.5 MB 1.0 MB/s eta 0:00:09\n",
            "   ------------------------------- -------- 30.9/39.5 MB 1.0 MB/s eta 0:00:09\n",
            "   ------------------------------- -------- 31.5/39.5 MB 1.0 MB/s eta 0:00:08\n",
            "   -------------------------------- ------- 31.7/39.5 MB 1.1 MB/s eta 0:00:08\n",
            "   -------------------------------- ------- 32.0/39.5 MB 1.1 MB/s eta 0:00:08\n",
            "   -------------------------------- ------- 32.5/39.5 MB 1.1 MB/s eta 0:00:07\n",
            "   --------------------------------- ------ 32.8/39.5 MB 1.1 MB/s eta 0:00:07\n",
            "   --------------------------------- ------ 33.0/39.5 MB 1.1 MB/s eta 0:00:07\n",
            "   --------------------------------- ------ 33.6/39.5 MB 1.3 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 34.1/39.5 MB 1.3 MB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 34.3/39.5 MB 1.3 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 34.6/39.5 MB 1.3 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 35.1/39.5 MB 1.3 MB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 35.4/39.5 MB 1.3 MB/s eta 0:00:04\n",
            "   ------------------------------------ --- 35.9/39.5 MB 1.3 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 36.2/39.5 MB 1.3 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 36.4/39.5 MB 1.3 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 36.7/39.5 MB 1.3 MB/s eta 0:00:03\n",
            "   ------------------------------------- -- 37.2/39.5 MB 1.4 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 37.5/39.5 MB 1.4 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 38.0/39.5 MB 1.4 MB/s eta 0:00:02\n",
            "   ---------------------------------------  38.5/39.5 MB 1.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  38.8/39.5 MB 1.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  39.1/39.5 MB 1.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 39.5/39.5 MB 1.4 MB/s eta 0:00:00\n",
            "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl (31.2 MB)\n",
            "   ---------------------------------------- 0.0/31.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.3/31.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.8/31.2 MB 1.9 MB/s eta 0:00:17\n",
            "   - -------------------------------------- 1.0/31.2 MB 2.1 MB/s eta 0:00:15\n",
            "   -- ------------------------------------- 1.6/31.2 MB 2.1 MB/s eta 0:00:15\n",
            "   -- ------------------------------------- 1.8/31.2 MB 1.8 MB/s eta 0:00:17\n",
            "   --- ------------------------------------ 2.4/31.2 MB 1.9 MB/s eta 0:00:16\n",
            "   --- ------------------------------------ 2.6/31.2 MB 1.9 MB/s eta 0:00:15\n",
            "   --- ------------------------------------ 2.9/31.2 MB 1.9 MB/s eta 0:00:16\n",
            "   ---- ----------------------------------- 3.4/31.2 MB 1.8 MB/s eta 0:00:16\n",
            "   ---- ----------------------------------- 3.7/31.2 MB 1.7 MB/s eta 0:00:16\n",
            "   ----- ---------------------------------- 3.9/31.2 MB 1.8 MB/s eta 0:00:16\n",
            "   ----- ---------------------------------- 4.5/31.2 MB 1.8 MB/s eta 0:00:15\n",
            "   ------ --------------------------------- 5.0/31.2 MB 1.8 MB/s eta 0:00:15\n",
            "   ------ --------------------------------- 5.2/31.2 MB 1.8 MB/s eta 0:00:15\n",
            "   ------- -------------------------------- 5.5/31.2 MB 1.8 MB/s eta 0:00:15\n",
            "   ------- -------------------------------- 6.0/31.2 MB 1.8 MB/s eta 0:00:15\n",
            "   -------- ------------------------------- 6.6/31.2 MB 1.8 MB/s eta 0:00:14\n",
            "   -------- ------------------------------- 6.6/31.2 MB 1.8 MB/s eta 0:00:14\n",
            "   --------- ------------------------------ 7.1/31.2 MB 1.7 MB/s eta 0:00:14\n",
            "   --------- ------------------------------ 7.3/31.2 MB 1.7 MB/s eta 0:00:14\n",
            "   --------- ------------------------------ 7.6/31.2 MB 1.7 MB/s eta 0:00:14\n",
            "   ---------- ----------------------------- 7.9/31.2 MB 1.7 MB/s eta 0:00:14\n",
            "   ---------- ----------------------------- 8.1/31.2 MB 1.7 MB/s eta 0:00:14\n",
            "   ---------- ----------------------------- 8.4/31.2 MB 1.7 MB/s eta 0:00:14\n",
            "   ----------- ---------------------------- 8.7/31.2 MB 1.7 MB/s eta 0:00:14\n",
            "   ----------- ---------------------------- 8.9/31.2 MB 1.6 MB/s eta 0:00:14\n",
            "   ----------- ---------------------------- 9.2/31.2 MB 1.6 MB/s eta 0:00:14\n",
            "   ------------ --------------------------- 9.7/31.2 MB 1.6 MB/s eta 0:00:14\n",
            "   ------------ --------------------------- 10.0/31.2 MB 1.6 MB/s eta 0:00:14\n",
            "   ------------- -------------------------- 10.2/31.2 MB 1.6 MB/s eta 0:00:13\n",
            "   ------------- -------------------------- 10.5/31.2 MB 1.6 MB/s eta 0:00:13\n",
            "   ------------- -------------------------- 10.7/31.2 MB 1.6 MB/s eta 0:00:13\n",
            "   -------------- ------------------------- 11.0/31.2 MB 1.6 MB/s eta 0:00:13\n",
            "   -------------- ------------------------- 11.5/31.2 MB 1.6 MB/s eta 0:00:13\n",
            "   -------------- ------------------------- 11.5/31.2 MB 1.6 MB/s eta 0:00:13\n",
            "   --------------- ------------------------ 11.8/31.2 MB 1.6 MB/s eta 0:00:13\n",
            "   --------------- ------------------------ 12.3/31.2 MB 1.6 MB/s eta 0:00:13\n",
            "   ---------------- ----------------------- 12.6/31.2 MB 1.5 MB/s eta 0:00:13\n",
            "   ---------------- ----------------------- 12.8/31.2 MB 1.6 MB/s eta 0:00:12\n",
            "   ---------------- ----------------------- 13.1/31.2 MB 1.6 MB/s eta 0:00:12\n",
            "   ----------------- ---------------------- 13.6/31.2 MB 1.6 MB/s eta 0:00:12\n",
            "   ----------------- ---------------------- 13.6/31.2 MB 1.6 MB/s eta 0:00:12\n",
            "   ------------------ --------------------- 14.2/31.2 MB 1.5 MB/s eta 0:00:12\n",
            "   ------------------ --------------------- 14.4/31.2 MB 1.5 MB/s eta 0:00:11\n",
            "   ------------------- -------------------- 14.9/31.2 MB 1.6 MB/s eta 0:00:11\n",
            "   ------------------- -------------------- 15.2/31.2 MB 1.6 MB/s eta 0:00:11\n",
            "   -------------------- ------------------- 15.7/31.2 MB 1.6 MB/s eta 0:00:10\n",
            "   -------------------- ------------------- 16.0/31.2 MB 1.6 MB/s eta 0:00:10\n",
            "   --------------------- ------------------ 16.5/31.2 MB 1.6 MB/s eta 0:00:10\n",
            "   --------------------- ------------------ 16.8/31.2 MB 1.6 MB/s eta 0:00:10\n",
            "   --------------------- ------------------ 17.0/31.2 MB 1.6 MB/s eta 0:00:10\n",
            "   ---------------------- ----------------- 17.6/31.2 MB 1.6 MB/s eta 0:00:09\n",
            "   ---------------------- ----------------- 17.8/31.2 MB 1.6 MB/s eta 0:00:09\n",
            "   ----------------------- ---------------- 18.1/31.2 MB 1.6 MB/s eta 0:00:09\n",
            "   ----------------------- ---------------- 18.4/31.2 MB 1.6 MB/s eta 0:00:09\n",
            "   ----------------------- ---------------- 18.6/31.2 MB 1.6 MB/s eta 0:00:09\n",
            "   ------------------------ --------------- 19.1/31.2 MB 1.6 MB/s eta 0:00:08\n",
            "   ------------------------- -------------- 19.7/31.2 MB 1.6 MB/s eta 0:00:08\n",
            "   ------------------------- -------------- 19.9/31.2 MB 1.6 MB/s eta 0:00:08\n",
            "   ------------------------- -------------- 20.2/31.2 MB 1.6 MB/s eta 0:00:08\n",
            "   -------------------------- ------------- 20.4/31.2 MB 1.6 MB/s eta 0:00:07\n",
            "   -------------------------- ------------- 20.7/31.2 MB 1.6 MB/s eta 0:00:07\n",
            "   --------------------------- ------------ 21.2/31.2 MB 1.6 MB/s eta 0:00:07\n",
            "   --------------------------- ------------ 21.2/31.2 MB 1.6 MB/s eta 0:00:07\n",
            "   --------------------------- ------------ 21.8/31.2 MB 1.6 MB/s eta 0:00:07\n",
            "   ---------------------------- ----------- 22.0/31.2 MB 1.6 MB/s eta 0:00:06\n",
            "   ---------------------------- ----------- 22.3/31.2 MB 1.6 MB/s eta 0:00:06\n",
            "   ----------------------------- ---------- 22.8/31.2 MB 1.6 MB/s eta 0:00:06\n",
            "   ----------------------------- ---------- 23.1/31.2 MB 1.6 MB/s eta 0:00:06\n",
            "   ----------------------------- ---------- 23.3/31.2 MB 1.6 MB/s eta 0:00:06\n",
            "   ------------------------------ --------- 23.9/31.2 MB 1.6 MB/s eta 0:00:05\n",
            "   ------------------------------ --------- 24.1/31.2 MB 1.6 MB/s eta 0:00:05\n",
            "   ------------------------------- -------- 24.4/31.2 MB 1.6 MB/s eta 0:00:05\n",
            "   ------------------------------- -------- 24.9/31.2 MB 1.6 MB/s eta 0:00:05\n",
            "   -------------------------------- ------- 25.2/31.2 MB 1.6 MB/s eta 0:00:04\n",
            "   -------------------------------- ------- 25.4/31.2 MB 1.6 MB/s eta 0:00:04\n",
            "   -------------------------------- ------- 25.7/31.2 MB 1.6 MB/s eta 0:00:04\n",
            "   --------------------------------- ------ 26.2/31.2 MB 1.6 MB/s eta 0:00:04\n",
            "   --------------------------------- ------ 26.5/31.2 MB 1.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ----- 26.7/31.2 MB 1.6 MB/s eta 0:00:03\n",
            "   ---------------------------------- ----- 27.0/31.2 MB 1.6 MB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 27.5/31.2 MB 1.6 MB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 28.0/31.2 MB 1.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ --- 28.6/31.2 MB 1.6 MB/s eta 0:00:02\n",
            "   ------------------------------------ --- 28.8/31.2 MB 1.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 29.1/31.2 MB 1.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 29.6/31.2 MB 1.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 29.9/31.2 MB 1.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 30.1/31.2 MB 1.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 30.4/31.2 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  30.9/31.2 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  31.2/31.2 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 31.2/31.2 MB 1.6 MB/s eta 0:00:00\n",
            "Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
            "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 0.5/2.6 MB 2.1 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 1.0/2.6 MB 1.9 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.3/2.6 MB 1.8 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 1.6/2.6 MB 1.7 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 2.1/2.6 MB 1.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.4/2.6 MB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.6/2.6 MB 1.6 MB/s eta 0:00:00\n",
            "Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, pillow, opencv-python, imageio_ffmpeg, proglog, imageio, moviepy\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "Successfully installed imageio-2.37.0 imageio_ffmpeg-0.6.0 moviepy-2.1.2 opencv-python-4.11.0.86 pillow-10.4.0 proglog-0.1.10 python-dotenv-1.0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Jaime\\Desktop\\MASTER\\EML_2\\.venv\\Lib\\site-packages\\~il'.\n",
            "  You can safely remove it manually.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@title Instalamos gym\n",
        "#! pip install 'gym[box2d]==0.20.0'\n",
        "! pip install tqdm\n",
        "! pip install gymnasium\n",
        "! pip install \"gymnasium[toy-text]\n",
        "! pip install \"gymnasium[other]\n",
        "## Instalación de algunos paquetes.\n",
        "#!apt-get update\n",
        "## Para usar gymnasium[box2d]\n",
        "#!pip install swig\n",
        "#!pip install gymnasium[box2d]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "o5s4pz9Hzk7r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['C:\\\\Users\\\\Jaime\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python312.zip', 'C:\\\\Users\\\\Jaime\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\DLLs', 'C:\\\\Users\\\\Jaime\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib', 'C:\\\\Users\\\\Jaime\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv', '', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\Jaime\\\\Desktop\\\\MASTER\\\\EML_2\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'src']\n"
          ]
        }
      ],
      "source": [
        "#@title Importamos librerias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import gymnasium as gym\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append('src')\n",
        "\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jaime\\Desktop\\MASTER\\EML_2\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\Jaime\\Desktop\\MASTER\\EML_2\\RL_FCPSSL\\videos\\FrozenLake-v1\\MonteCarloEpsilonGreedyAgent(gamma0.99_epsilon0.4_decay_rate1_min_epsilon0.01) folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n",
            "100%|██████████| 50000/50000 [01:09<00:00, 719.37it/s] \n"
          ]
        }
      ],
      "source": [
        "from agents import MonteCarloEpsilonSoftAgent, MonteCarloEpsilonGreedyAgent\n",
        "#env = gym.make(\"FrozenLake-v1\", is_slippery=True, render_mode=None)\n",
        "#n_episodes = 10000\n",
        "n_episodes = 50000\n",
        "env = gym.make('FrozenLake-v1', is_slippery=False, map_name=\"4x4\", render_mode=\"rgb_array\") # No resbaladizo para entender mejor los resultados.\n",
        "\n",
        "\n",
        "#agent = MonteCarloEpsilonSoftAgent(env, epsilon=0.4, decay_rate=1)\n",
        "agent = MonteCarloEpsilonGreedyAgent(env, epsilon=0.4, decay_rate=1)\n",
        "\n",
        "agent.train(n_episodes, render_interval=5000, video_path='videos')\n",
        "\n",
        "stats = agent.stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def pi_star_from_Q(env, Q):\n",
        "    \"\"\"\n",
        "    Calcula la política óptima π* a partir de la tabla de valores Q.\n",
        "\n",
        "    Parámetros:\n",
        "        env: el entorno de Gymnasium.\n",
        "        Q: la Q-table aprendida (matriz de tamaño [S, A]).\n",
        "\n",
        "    Retorna:\n",
        "        - pi_star: un array donde cada estado tiene la acción óptima.\n",
        "        - actions: una representación en texto de las acciones seguidas en un episodio.\n",
        "    \"\"\"\n",
        "    pi_star = np.zeros(env.observation_space.n, dtype=int)  # Política óptima para cada estado\n",
        "    actions = \"\"\n",
        "\n",
        "    # Recorrer todos los estados y seleccionar la mejor acción de Q\n",
        "    for state in range(env.observation_space.n):\n",
        "        best_action = np.argmax(Q[state, :])  # Acción con mayor valor Q\n",
        "        pi_star[state] = best_action\n",
        "\n",
        "    # Simular un episodio siguiendo la política óptima para ver la secuencia de acciones\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = pi_star[state]\n",
        "        actions += f\"{action}, \"\n",
        "        state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "    return pi_star, actions.strip(\", \")\n",
        "\n",
        "pi_star, actions = pi_star_from_Q(env, stats['Q-table'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1, 2, 1, 0, 1, 0, 1, 0, 2, 1, 1, 0, 0, 2, 2, 0]), '1, 1, 2, 1, 2, 2')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pi_star, actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "0ogCwKft-Ki9"
      },
      "outputs": [],
      "source": [
        "#@title Importamos el lago helado\n",
        "name = 'FrozenLake-v1'\n",
        "env4 = gym.make(name, is_slippery=False, map_name=\"4x4\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados.\n",
        "env8 = gym.make(name, is_slippery=False, map_name=\"8x8\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1ySdi2wdXdm"
      },
      "source": [
        "## **2. Diseño del Agente**\n",
        "\n",
        "El diseño del agente consta de dos partes, el algoritmo con el que aprende y las políticas (toma de decisiones) que realiza.\n",
        "\n",
        "- **Políticas del Agente**\n",
        "   - **Política epsilon-soft**: Se define una política donde todas las acciones tienen una probabilidad de ser elegida.\n",
        "   - **Política epsilon-greedy**: basada en la política epsilon-soft. De esta forma el agente tiene una pequeña probabilidad de explorar (tomar una acción aleatoria) y una mayor probabilidad de explotar (tomar la acción que considera mejor). Esto permite equilibrar la exploración y la explotación.\n",
        "   - **Política greedy**: Es la usada una vez que \"ha aprendido\".\n",
        "\n",
        "- **Algoritmo de Iteración de Valor**\n",
        "  - Se implementa el algoritmo de iteración de valor utilizando Monte Carlo.\n",
        "  - Se usa una versión \"on-policy\" de Monte Carlo con políticas epsilon greedy sobre una política epsilon-soft.\n",
        "  - Se basa en el criterio de todas las visitas.\n",
        "  - Otro aspecto es que la actualización de los retornos no se realiza en el orden inverso a las visitas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vDI1gmKfDPT"
      },
      "source": [
        "#### **Código de las políticas y algoritmo MC**\n",
        "----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "lVEIYzaJ4p8N"
      },
      "outputs": [],
      "source": [
        "# @title Políticas del agente\n",
        "\n",
        "# actions\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "\n",
        "# Política epsilon-soft. Se usa para el entrenamiento\n",
        "def random_epsilon_greedy_policy(Q, epsilon, state, nA):\n",
        "    pi_A = np.ones(nA, dtype=float) * epsilon / nA\n",
        "    best_action = np.argmax(Q[state])\n",
        "    pi_A[best_action] += (1.0 - epsilon)\n",
        "    return pi_A\n",
        "\n",
        "# Política epsilon-greedy a partir de una epsilon-soft\n",
        "def epsilon_greedy_policy(Q, epsilon, state, nA):\n",
        "    pi_A = random_epsilon_greedy_policy(Q, epsilon, state, nA)\n",
        "    return np.random.choice(np.arange(nA), p=pi_A)\n",
        "\n",
        "# Política Greedy a partir de los valones Q. Se usa para mostrar la solución.\n",
        "def pi_star_from_Q(env, Q):\n",
        "    done = False\n",
        "    pi_star = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "    state, info = env.reset() # start in top-left, = 0\n",
        "    actions = \"\"\n",
        "    while not done:\n",
        "        action = np.argmax(Q[state, :])\n",
        "        actions += f\"{action}, \"\n",
        "        pi_star[state,action] = action\n",
        "        state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "    return pi_star, actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RpUWKye-7YA1"
      },
      "outputs": [],
      "source": [
        "#@title Algoritmo de Iteración de Valor versión MC con Políticas epsilon-soft\n",
        "\n",
        "def on_policy_all_visit(env, num_episodes=5000, epsilon=0.4, decay=False, discount_factor=1):\n",
        "  # Matriz de valores  Q\n",
        "  nA = env.action_space.n\n",
        "  Q = np.zeros([env.observation_space.n, nA])\n",
        "\n",
        "  # Número de visitas. Vamoa a realizar la versión incremental.\n",
        "  n_visits = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "  # Para mostrar la evolución en el terminal y algún dato que mostrar\n",
        "  stats = 0.0\n",
        "  list_stats = [stats]\n",
        "  step_display = num_episodes / 10\n",
        "\n",
        "  for t in tqdm(range(num_episodes)):\n",
        "      state, info = env.reset(seed=100)\n",
        "      done = False\n",
        "      episode = []\n",
        "      result_sum = 0.0  # Retorno\n",
        "      factor = 1\n",
        "      while not done:\n",
        "          if decay:\n",
        "            epsilon = min(1.0, 1000.0/(t+1))\n",
        "\n",
        "          action = epsilon_greedy_policy(Q, epsilon, state, nA) # GET ACTION\n",
        "          new_state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "          done = terminated or truncated\n",
        "\n",
        "          episode.append((state, action))\n",
        "          result_sum += factor * reward\n",
        "          factor *= discount_factor\n",
        "          state = new_state\n",
        "\n",
        "      # UPDATE\n",
        "      for (state, action) in episode:\n",
        "          n_visits[state, action] += 1.0\n",
        "          alpha = 1.0 / n_visits[state, action]\n",
        "          Q[state, action] += alpha * (result_sum - Q[state, action])\n",
        "\n",
        "      # Guardamos datos sobre la evolución\n",
        "      stats += result_sum\n",
        "      list_stats.append(stats/(t+1))\n",
        "\n",
        "      # Para mostrar la evolución.  Comentar si no se quiere mostrar\n",
        "      if t % step_display == 0 and t != 0:\n",
        "          print(f\"success: {stats/t}, epsilon: {epsilon}\")\n",
        "\n",
        "  return Q, list_stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XxVyTFTfVkL"
      },
      "source": [
        "## **3. Experimentación**\n",
        "\n",
        "   - En esta sección, el algoritmo de Monte Carlo con la política epsilon-soft se ejecuta tanto para el entorno de 4x4 como al de 8x8 de FrozenLake sin resbalar.\n",
        "   \n",
        "   - En ambos casos se realiza un entrenamiento con un número determinado de episodios (5000 en concreto)\n",
        "\n",
        "   - Además en el escenario 8x8 el  epsilon tiene decaimiento de acuerdo a la expresión: $\\epsilon = min(1.0, 1000.0/(t+1))$\n",
        "\n",
        "   - Durante el entrenamiento hay una visualización de la proporción de recompensas obtenidas a lo largo del entrenamiento.\n",
        "\n",
        "   - Junto a dicho volcado se muestra gráficamente la proporcion de recompensas obtendias.\n",
        "\n",
        "   - También se hace un volcado de los valores Q de cada estado, donde se muestra cómo el agente valora diferentes acciones en distintos estados del entorno, lo que puede interpretarse como su conocimiento sobre las mejores estrategias para alcanzar la meta sin caer en los agujeros.\n",
        "\n",
        "   - Además, se muestra la política óptima derivada de los valores Q. Esta política es la que el agente seguiría si tuviera que elegir siempre la acción que maximiza su recompensa esperada.\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqdLUE8zQN2v"
      },
      "source": [
        "### **3.1 Repressentaciones Gráficas**\n",
        "\n",
        "Para comprobar el aprendizaje se mostrará la función $f(t)=\\frac{\\sum_{i=1}^t R_i}{t}$ para $t=1,2,\\ldots, NumeroEpisodios$. La justificación es la siguiente. Como sabemmos que el retorno en el estados inicial 1 (pues no hay descuento) o 9, si se divide por el número de episodios ejecutados se calcular el porcentaje de recompensas positivas obtenidas. Dicho de otra forma, nos dirá el porcentaje de veces que el agente ha llegado al estado terminal.\n",
        "\n",
        "*TODO:* Contruir una gráfica que muestre la longitud de los episodios en cada estado junto con la curva de tendencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "u42-YlgazukU"
      },
      "outputs": [],
      "source": [
        "# @title Funciones para mostrar los resultados\n",
        "\n",
        "def plot(list_stats):\n",
        "  # Creamos una lista de índices para el eje x\n",
        "  indices = list(range(len(list_stats)))\n",
        "\n",
        "  # Creamos el gráfico\n",
        "  plt.figure(figsize=(6, 3))\n",
        "  plt.plot(indices, list_stats)\n",
        "\n",
        "  # Añadimos título y etiquetas\n",
        "  plt.title('Proporción de recompensas')\n",
        "  plt.xlabel('Episodio')\n",
        "  plt.ylabel('Proporción')\n",
        "\n",
        "  # Mostramos el gráfico\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "# Define la función para mostrar el tamaño de los episodios\n",
        "# Pon aquí tu código."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvnGJVGF_j2j"
      },
      "source": [
        "### **3.2 Experimentación en el escenario 4x4**\n",
        "\n",
        "\n",
        "\n",
        "   - Se realizan 5000 epsisodios y se actualizan los valores Q (valor de acción) basándose en las recompensas obtenidas durante cada episodio completo (e.d. aplicamos Monte Carlo) Se apica una política $\\epsilon$ greedy sobre una política $\\epsilon$ soft con un valor $\\epsilon$ constante\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "j_Dronjr_mAN",
        "outputId": "1c0f7ad3-0686-494e-b7eb-1b4a49573329"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5237/50000 [00:07<00:37, 1201.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.3578, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 10099/50000 [00:11<00:37, 1064.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.445, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 15110/50000 [00:15<00:28, 1244.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.47626666666666667, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 20191/50000 [00:19<00:23, 1288.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.4897, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 25169/50000 [00:23<00:19, 1294.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.49592, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 30229/50000 [00:27<00:15, 1258.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.4997666666666667, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 35239/50000 [00:31<00:12, 1202.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.5050285714285714, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 40156/50000 [00:35<00:07, 1262.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.5092, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 45135/50000 [00:40<00:03, 1247.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.5134888888888889, epsilon: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:43<00:00, 1139.39it/s]\n"
          ]
        }
      ],
      "source": [
        "# @title Aprendizaje\n",
        "Q, list_stats = on_policy_all_visit(env, num_episodes=50000, epsilon=0.4, discount_factor=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 2., 0.],\n",
              "        [0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 2., 0.],\n",
              "        [0., 0., 2., 0.],\n",
              "        [0., 0., 0., 0.]]),\n",
              " '1, 1, 2, 1, 2, 2, ')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pi_star, actions = pi_star_from_Q(env, Q)\n",
        "pi_star, actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "KLhdk1SFtn8S",
        "outputId": "30d22b75-74ae-4735-99a7-0401d3a836ea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAE9CAYAAAC885C4AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPb5JREFUeJzt3Qd8k9X6B/CnI90D2kJboGXIBinKHoLMCly2V/RypSKiInBZinJVhsAfBC8gyFSGXhWuICAiqyBDsOwNUlahjLa0lBa61/v/PKe8IWnT0qRvmzfJ7/v5hCRv3r45OXlJnpzznHPsJEmSCAAAAKCU7Et7AAAAAACGoAIAAAAUgaACAAAAFIGgAgAAABSBoAIAAAAUgaACAAAAFIGgAgAAABSBoAIAAAAUgaACAAAAFIGgAsCKbdy4kb744gvKzc01d1EAwAYgqACwUG+88QbVqFGjyMf//PNPGjx4MDVs2JAcHBzKvDz79u0jOzs7cQ0AtglBBVi0NWvWiC8y+eLi4kJ169alUaNGUVxcHNmq+/fv06uvvkoLFy6knj17mrs4AGAjHM1dAAAlfPbZZ1SzZk3KyMiggwcP0tKlS2nbtm10/vx5cnNzI2v09ddfU15ensHHTp06RTNmzKAhQ4aUe7kAwHYhqACr0KNHD2revLm4/dZbb5Gvry/NmzePfvnlF3rttdcM/k1qaiq5u7uTmhhTJo1GU+RjXbt2JWvEQaOTkxPZ26ORFUCN8D8TrFLnzp3FdVRUlDb/wMPDg65duya6Azw9PUW+gfxFPmHCBAoKCiJnZ2eqV6+eSG6UJEnvmNy9wt0qP/zwg9iHu1qaNWtGBw4cMNhSwIGOl5eXeN4uXbrQ4cOHDXbd7N+/n9577z2qXLkyVatWTfv49u3bqWPHjqKsfJwWLVrQjz/+WGxOhbGvZfPmzdS4cWOxb6NGjWjHjh0lqt/bt29Tv379RADE5R43bhxlZmYa3PfIkSP00ksvkbe3t2g14td06NChEudorFu3jj755BOqWrWq+PuHDx8addw7d+7QsGHDqEqVKuJ1covWiBEjKCsrS7vP9evX6e9//zv5+PiIY7Vu3Zp+++03g+X56aefaNq0aaI8/N68/PLLlJycLF7/2LFjRX3wez506NBCdWLMOcTlfvPNN8nf31/7/qxatarIMs2cOVOcP3xMPt+uXr2qt++VK1do4MCBFBAQIPbhfbmLjMsuW716tfi/w6+Bn5PzcbjVr6Djx49TaGgo+fn5kaurq6hTLisAWirAKnHwwLjFQpaTkyM+CNu3by++aPnLg79s+/TpQ3v37hVfPE2bNqWdO3fSBx98ID7U58+fr3dcDgD+97//0b/+9S/xobtkyRLxxXb06FHx5cwuXLhAL7zwgggEJk6cKFoUli9fTi+++KL4+1atWukdkwOKSpUq0eTJk0VQIAcc/CHNXySTJk2iChUqiECFv/T/8Y9/GHzNxr4W7ibi0SH8/PzlyPkX/KUTHR2tV28Fpaeniy8t3o/rgb+s//vf/9Lvv/9eaF/exsEVf3FOmTJFtDDIX1x//PEHtWzZ8qnv5fTp00XrxPvvvy++pPl2SY979+5dcTspKYnefvttql+/vqiLDRs2UFpamjgW5960bdtW3OfXw6/922+/FXXJ+/Xv31+vPLNmzRJfpB999JH44l60aJF4j7kMDx48oKlTp4oAkt9D/rLl99XYc4jLxIGNHITw+cFBJr+vHFRx8KJr9uzZ4vm5jjhImDNnjgiaOfBiHEDxuc/1N3r0aBFYcD1s3bpV1A0HZowDCD7n+LU7OjrSr7/+Ks4P7mYbOXKk2OfevXvUvXt3USauAz43b9y4Ic4lAP4gArBYq1ev5p/g0u7du6X4+Hjp1q1b0rp16yRfX1/J1dVVun37ttgvLCxM7PfRRx/p/f3mzZvF9hkzZuhtf/nllyU7Ozvp6tWr2m28H1+OHz+u3Xbz5k3JxcVF6t+/v3Zbv379JCcnJ+natWvabXfv3pU8PT2lDh06FCp7+/btpZycHO32pKQksW+rVq2k9PR0vXLl5eVpb/Nrql69usmvhcuou+3MmTNi+6JFi4qt8wULFoj9fvrpJ+221NRUqXbt2mL73r17tWWtU6eOFBoaqlfutLQ0qWbNmlK3bt2KfR4+Dh+vVq1a4m9066Ckxx0yZIhkb28vHTt2rNDx5b8dO3aseJ4//vhD+9ijR4/EsWrUqCHl5ubqladx48ZSVlaWdt/XXntN1G+PHj30jt+mTRu998eYc2jYsGFSYGCglJCQoPf3r776quTt7a2tD7lMDRo0kDIzM7X7ffnll2L7uXPnxP1Tp06J++vXry+2znXrWcb1zO+BbNOmTeJYhuoUAN0fYBU4h4B/OXGzPzfpcvPzpk2bRBO1Lm721sXJnDzckn816uIuBP4O4F+Hutq0aSN+HcuCg4Opb9++okWA54Lgy65du0TXQK1atbT7BQYGihYGbh2Qm+9lw4cP1xvyGR4eTo8ePRK/ArmZWhf/ci2Ksa+F6+yZZ57R3m/SpIloXeGugOLw8/Dr4WZ/Gbf6cEuArtOnT4smd37dPBolISFBXLg1hls6uMm/qERTXWFhYaJlwNjj8oW7d3r37q3NtzFUl/x6uDWDW7BkfP7w6+Ff4BcvXtT7O05+1c1n4ZYnrt+Czf+8/datW6KFzJhziI/1888/i3Lzbfn18YVbG7gl4uTJk3rH5K4WbnWRcUsZk99LuSWCn4NbZIqiW8/8PPyc3K3Ex5G7SbhlgnErR3Z2dpHHAtuE7g+wCosXLxZDSbnJlvugub+6YDIfP6abs8Bu3rwpmu+5+V9XgwYNtI/rqlOnTqHn5uflD+r4+Hhxn2/z8xfEx+QvOv6i4SZmGTeRG+q6kZvCS8rY18JfZgVVrFhRNOE/7Xlq165dKMAp+Jr5i18OCorCX1T8nMUpWD8lPS43+XMA97R65NdTsEuqYL3pHqNgvclf2BzQFtzO7zeXRbc76WnnEJ+33CWxYsUKcTGEuyB0FSyTXKfye8l1OH78eJG8zPkcHHRwF8c///lPbfkZ56Rwd1JERESh4INfB+/LQQZ3k3FeCXepcbceB9Ec5HF3Dtg2BBVgFfiXpqFfo7r4A0+NowZ0fx2Wp6ImxCqY1GkquRVi7ty5Ir/DEG4RMLZ+SnrcxMREKs96U6o+5dfHX/hFBU7cqmTsc//nP/8Ryb08Iopb07hFi/NDOP+Dg20OZrmlh/NOOPjgIIlbP7glh4MHuVwcTHKuCf8d51xw6we30vDxeVtJ3lOwXggqwKZVr16ddu/eLbobdH/hX7p0Sfu4oV/Jui5fviya/7n7hfHtyMjIQvvxMTmoKfiLtiC5S4Ln2OAWgbJ6Labi43DZ+AtLt7Wi4GuWXwd3qSg5xLWkx+X3g/fhsj7t9RT1fsmPK6kk5xC/f9wVovTQ4GeffVZceDQNz7jarl07WrZsmZjThAMETuTcsmWLXssHJ/4awomkfOFRJzwqiRNDeaQOD+kG26W+n20A5YiHl/KH91dffaW3nX+Z8RcmjzDQxc3Cuv3Z3JXBv/w4G55/LfKFb/M27o+XcTY/f/Byvz1/0RWH/56/VPhXJM/LUNJfvca+FlPx8/CoCv61KuOm8oJN9Zw3wAEAj7RJSUkpdBy5u8hYJT0uB3DcLM9fljwEsiC5Lvn18MgLfm9lnJ/Br4eH7PKwSiWV5Bzi7gXOqzAUEJlSb9wNVDC3g4MLriN52Kvc2qF7jnGXB4+q0cVdKgXPQ7nFqKhhxWA70FIBNo2T4Tp16kQff/yxCAJCQkJE0zB/yPOwPd1ERsZ965wspzsckHH/sox/9XGyJQcQPByPczl4SCl/4PJQv6fhoIMDAf7Fx3NTcF8195GfOXNGfHnzcEclXoupOLGUAxdOWDxx4oRI2uQhpQVnLuUvrG+++UYEM5xDwsmEnDjLQxn51y+/Tv7CN5Yxx/2///s/UQecB8CJl5wnERMTQ+vXrxdJs5x0yAmxa9euFcfj95XnquA65jlO+Itd6S6zkpxDPESUXwvnenB9c2DD3TkcjHBrlLFdOzwEl4em8lwcnL/BAQa/Z3IAwzio4e4OPo/eeecdEbDxrK08ZwXXmYzrhsvMQ235nOKWMd6P6x1TwgOGlIJFk4dlPm14Gw+/dHd3N/gYDx8cN26cVKVKFUmj0YjhinPnztUbrsj4eUaOHCl9//33Yh9nZ2fpueee0w6h1HXy5EkxFM/Dw0Nyc3OTOnXqJP35559GlX3Lli1S27ZtxdBYLy8vqWXLltLatWv1XlPBIYvGvpaC+Hh83KfhYZB9+vQRr83Pz08aM2aMtGPHDr0hpTIezjhgwAAxzJfrjJ/jlVdekfbs2VPsc8jDJYsaBlnS43JZeWhppUqVxH48PJJfu+4QTB7+y0NvK1SoIIZ3cl1v3bq1ROUp6n2cMmWK2M5DnU05h+Li4sS+QUFB4r0MCAiQunTpIq1YseKpZYqKihLbuWzs+vXr0ptvvik988wz4vX5+PiIc5KHYhc855o0aSL24eG0n3/+ubRq1SpxLD6mfG7zMNrg4GBR/sqVK0t/+9vf9IbJgu2y43/MHdgAWALuQuAJgAp2LwCUFM4hsHbIqQAAAABFIKgAAAAARSCoAAAAAEUgpwIAAAAUgZYKAAAAUASCCgAAAFCE1U9+xfPV8+x/PENhcSs8AgAAgD7OkOAJznixwpJMBGf1QQUHFE9bawEAAACKxtPJF1zl2SaDCnlhJa6Qp625YIzs7Gwx/S9PbavRaBQ7rq1CfSoPdaos1KfyUKfqr09eN4Z/mOsuUmjTQYXc5cEBhdJBBa91wMfEf4bSQ30qD3WqLNSn8lCnllOfJU0fQKImAAAAKAJBBQAAACgCQQUAAAAoAkEFAAAAKAJBBQAAACgCQQUAAAAowuqHlAIAAFiyKb+cpyNRiSWa/fLhIwfyqZ9IL9TzJ3NAUAEAAKBSialZ9G3ETSP+wo5SMnPIXBBUAAAAqFRmTq64drC3o2+Htix235zcHDp65Cg9F1yBzAVBBQAAgEpl5eSJa2dHe2pfx++pM2omR0rk6+5UTqUrDEEFAABAGZAkiS7cfUgPM7JNPsbdpAxx7eRoGeMqEFQAAACUgZ9P3qH3159R5FjcUmEJEFQAAACUgaiEFHFdwU1DlT2dTT6OHdnR35s/fdlxNUBQAQAAUIb5EIOaB9Gkng3IFlhGewoAAICFyc6VxLXGwXa+atFSAQAAYKLY5AyauzPSYDLmXzEPLSrJUgkIKgAAAEz0y+k79PPJ28XuE+DlQrYCQQUAAICJUh/PXtm6lg/1bVq10OPerhrq2sA8U2abA4IKAAAAE2Xm5idjNqriTa+1DCZbh6ACAACgCBnZuRT/KLPIxx+kZtlc3kRxEFQAAAAUEVB0+mIfxSTnz2pZHFsa4VEcBBUAAAAG3HuYqQ0oXDRFBw2eLhrqWLdSOZZMvRBUAAAAGJCVm6udEfP05O7mLo5FQHsNAACAAZmPZ8RE10bJoaUCAABswqnoB7T1bAxJ+RNdPlVCSn6CphOCihJDUAEAADbh403n6eLjWS6Nwd0fUDIIKgAAwCYkp+dPpf1ys2olXjXUzo6oR+PAMi6Z9UBQAQAANiHr8URVb7arSQ2reJm7OFYJHUUAAGATsh8HFU6OduYuitVCSwUAAFg8SZLo9ZVH6dC1hGL2yb92cnAov4LZGFW1VMyePZvs7Oxo7Nix2m0ZGRk0cuRI8vX1JQ8PDxo4cCDFxcWZtZwAAKAuDzNy6ODVBBE4FHVhwT5u5O9dsnwKsOCWimPHjtHy5cupSZMmetvHjRtHv/32G61fv568vb1p1KhRNGDAADp06JDZygoAAOqS9XhOCXb04y5kR3ZFjuTAvBNWHlSkpKTQ4MGD6euvv6YZM2ZotycnJ9PKlSvpxx9/pM6dO4ttq1evpgYNGtDhw4epdevWZiw1AACoLQmT55So7Oli7uLYLFUEFdy90atXL+ratateUHHixAnKzs4W22X169en4OBgioiIQFABAGAhzt5OohM3H+hty83NpYsxdhQfcZMcSpnngNVC1cHsQcW6devo5MmTovujoNjYWHJycqIKFSrobff39xePGZKZmSkusocP8yc64eCEL0qRj6XkMW0Z6lN5qFNloT5Nl5ObR//4+gilZOYYeNSBNt6IVOy53J0cbPY9yi6Dc9TYY5k1qLh16xaNGTOGwsPDycVFmeaqWbNm0bRp0wpt37VrF7m5uZHSuOygHNSn8lCnykJ9Gi8jlyglM//rpqlPnphQqqw855tG27ZtI1sWruA5mpaWZtT+dhKPwzGTzZs3U//+/fWavbg5jEeA2Nvb086dO0XXx4MHD/RaK6pXry5GiHASZ0laKoKCgighIYG8vLwUjd74jevWrRtpNJjCtbRQn8pDnSoL9Wm6B2lZ1HLWPnH70rRu5GCfH1WgTpVVFvXJ36F+fn4ix7Ek36Fmbano0qULnTt3Tm/b0KFDRd7Ehx9+KIIBrpg9e/aIoaQsMjKSoqOjqU2bNgaP6ezsLC4F8XHK4qQtq+PaKtSn8lCnykJ9Gk+yy19CnIMJF2enQo+jTpWlZH0aexyzBhWenp7UuHFjvW3u7u5iTgp5+7Bhw2j8+PHk4+MjoqTRo0eLgAJJmgAAxjt4JYGm/XpBu6x3ecjNy28Q1zhgJktrZ/ZEzaeZP3++6Arhlgru1ggNDaUlS5aYu1gAABZp46nbdOVeilmeu3ZlD7M8L9hwULFvX36/m4wTOBcvXiwuAABQOnILxVvta1LPJuW7+maDACziZe1UF1QAAEDZzzxZq5IHPR9c0dzFASuDWUIAAGwED/Y7diNR3MYkUVAWcFYBANiIP64kUFJa/mRGLhp8/IPycFYBANiI6MQnExm9ULuSWcsC1glBBQCAjeVT9A6pQt5umBcClIegAgDAxlbyxHwRUFYw+gMAwIos2H1Zm4xZ0K3EdHHtjCRNKCMIKgAArAQv/71g95Wn7hfo7Vou5QHbg6ACAMBKpGc/WWNj3ishBvdx1ThQh7pI0oSygaACAMBKZD/OmXBxtKe+TauauzhggxBUAABY2ARWN++naZMudUXfzx8yiomtwFwQVAAAWJDFe6/SF7suF7uPxgFBBZgHggoAAAty4e5Dce3m5EAuGodCj/Ng0VdbBJmhZAAIKgAALHICqym9G9KgFsHmLg6AHrSRAQBYEDmXAnkToEZoqQAAULm7Sen0zR9RlJ6dQ5Gxj8Q25E2AGiGoAABQuW//vEGrDkXpbfNxdzJbeQCKgqACAEDlHmbkL1fevrYfta7lQ/5eLtS6pq+5iwVQCIIKAACVy8qRxHX7On70bsdnzF0cgCKhUw4AQOWjPTIeT7/thDwKUDm0VAAAqNS2czE0dt1pjPgAi4EzFABApQ5dTdAGFB7OjvR8cEVzFwmgWGipAABQ+URXY7vWoZGdamMYKagezlAAAJWvOsqtFAgowBKgpQIAQCWO3Uiko1GJ2vuXHk90hVwKsBQIKgAAVCA3T6Khq49RSmZOoce4pQLAEuBMBQBQSf6EHFAMeL4qOdrzeqNEvh7O1L1RgJlLB1AyCCoAAFSUlMk+H9gEORRgkXDWAgCoQGZu/gRXTG6lALA0aKkAADCj8ItxNHXLBUqXZ810tCc7OwQVYJkQVAAAmNGWM3fpTlK69n6DAE+zlgegNBBUAACYUVZOfgvFvzrXpp5NAqmmn7u5iwRgMgQVAAAqSNCs5uNG9QO8zF0cgFJBUAEAYAZJaVn057X7FJOcIe5jBVKwBggqAADM4P31Z2j3X/e09100DmYtD4ASzBoaL126lJo0aUJeXl7i0qZNG9q+fbv28YyMDBo5ciT5+vqSh4cHDRw4kOLi4sxZZAAARdxJym+haBDoRf2fq0rt6/iZu0gAlh1UVKtWjWbPnk0nTpyg48ePU+fOnalv37504cIF8fi4cePo119/pfXr19P+/fvp7t27NGDAAHMWGQBA0QTNKb0b0vxBTTEVN1gFs57FvXv31rs/c+ZM0Xpx+PBhEXCsXLmSfvzxRxFssNWrV1ODBg3E461btzZTqQEASi/r8QqkWCwMrEmpgoo9e/aIy7179ygv78kUs2zVqlVGHSs3N1e0SKSmpopuEG69yM7Opq5du2r3qV+/PgUHB1NERESRQUVmZqa4yB4+fCiu+Vh8UYp8LCWPactQn8pDnaqzPmfviKQT0UkU+zhB017Ks9n3COeo+uvT2GOZHFRMmzaNPvvsM2revDkFBgaaPAPcuXPnRBDB+ROcN7Fp0yZq2LAhnT59mpycnKhChQp6+/v7+1NsbGyRx5s1a5YoW0G7du0iNzc3Ulp4eLjix7RlqE/loU7VU5+PsolWHn/ysWtvJ9G5owfpphPZNJyj6q3PtLS08gkqli1bRmvWrKHXX3+dSqNevXoigEhOTqYNGzZQWFiYyJ8w1aRJk2j8+PF6LRVBQUHUvXt3kQyqZPTGb1y3bt1Io9EodlxbhfpUHupUffV5+0E60fE/SONgRwsHhVANXzeqXdmDbBXOUfXXp9zaX+ZBRVZWFrVt25ZKi1sjateuLW43a9aMjh07Rl9++SUNGjRIPEdSUpJeawWP/ggIKHoZYGdnZ3EpiCu4LE7asjqurUJ9Kg91qp76lOwytcNHezSpqnDJLBfOUfXWp7HHMTlD6K233hJJlErj3AzOieAAg18M52zIIiMjKTo6WnSXAACokSRJdCn2IZ2+lVTocu5OstjHGcmZYKVMbqngHIgVK1bQ7t27xVwTBaOZefPmlairokePHiL58tGjRyJI2bdvH+3cuZO8vb1p2LBhoivDx8dHdF2MHj1aBBQY+QEAarV0/zWasyOy2H0weyZYK5ODirNnz1LTpk3F7fPnz+s9VtKkTR41MmTIEIqJiRFBBAcnHFBwfxCbP38+2dvbi0mvuPUiNDSUlixZYmqRAQDK3JW4FHHt7aohT5fCH7H88fiPltXNUDIAFQcVe/fuLfWT8zwUxXFxcaHFixeLCwCAJc0/Ma5rHXqjXU1zFwegXCnSBnf79m1xAQCwdfKqo06OWMsDbI99aRIqeZ4K7raoXr26uPAojenTpxeaCAsAwNpdvZdCEzecobO3k8R9HjYKYGtK3P3BM2S2bNmSGjduLO5//PHHovuC1+5o166d2Hbw4EGaOnWqSOLkKbcBAGzFyoPX6afjT1psK3kWHtoOYO1KHFRwSwSP1Pj222/FWhx8/c0331CfPn20+3CiZdWqVem9995DUAEANiUtK3+BsO4N/al3SBV6oU4lcxcJQL3dH126dBFzRnz00UfifmJioliLoyDexo8BANiS3DxJXLd9xlcEFQ726P4A22NUTkXdunXpwIED4nZISAh99dVXhfbhbfwYAIAtBhUIJsCWGT2klId5sjlz5lCvXr3E5FfyDJe8euitW7do27ZtypcUAMAiggpMbAW2y+Szv2PHjnT58mXq37+/WJ+DLwMGDBBTab/wwgvKlhIAwGKCCnOXBMACJ79iVapUQUImAAAR5aClAsC4oIKn5uYhpTx1Nt8uDo8EAQCwFXkSWioAjAoqeK2P2NhYqly5srjNa3zwinwF8fbc3PzhVQAAluRy3CPaeuYuPW540MrNy6Vr0fZ0afcVcrAvPFvm9fhUcY2WCrBlRgUVUVFRVKlSJe1tAABr88nm83Q0qqhh8fZEd4r/7PN0LlWvMoBFM+rs5wmwDN0GALAWD1KzxPVLjQIowDt/tBvj5Qdu3LhBNWrUEF3Ahvh7uVC72n7lVlYAtTE5pJ41axb5+/vTm2++WWg67/j4ePrwww+VKB8AgFlWGR3eoSY1q+6j3Z6dnU3btl2nnj3rk0ajMWMJAdTL5M6/5cuXG5xRs1GjRrRs2bLSlgsAwCyy5VVGHbDKKEC5tVRwwmZgYGCh7ZxzERMTY+phAQDKzYytF2nt0Wi9bamP1/DQOGJmTIBya6kICgqiQ4cOFdrO23j+CgAAtdt46o4IInQvzNfdiapVdDN38QBsp6Vi+PDhNHbsWNHPyKuWMl5wbOLEiTRhwgQlywgAUCayHnd1/PhWK70ggpctd3VC9wdAuQUVH3zwAd2/f18sc56VlaVdF4QTNCdNmmTqYQEAyj0ps7qfO1Wt4Gru4gDYZlDBE1txNwcvg/7pp5/SX3/9Ra6urlSnTh1ydnZWvpQAACZIycyhPX/FUWZ2fvBQVEuFE6bBBDBfUOHg4EDdu3cXwUTNmjWpRYsWypQGAEBBX/1+lZbtv/bU/Vw0CCoAzNr9wWuAXL9+XQQVAABqFJucLq7rVPagYB/DiZeta/mSpwvmnQAwa1AxY8YMev/992n69OnUrFkzcnd313vcy8tLifIBAJgsOzd/AY9/tq5OYW1rmLs4AFbP5KCiZ8+e4rpPnz5iATEZLzCGBcUAQA0y5ZwJR3RvAKg6qNi7d6+yJQEAUNC1+BTa/VecuK1BIiaAuoOKjh07KlsSAAAFbT/3ZGbfGr6YyAqgPJRqjd6kpCRauXKlGAUir/vBC4x5e3srVT4AgFJ1fbSp5UvNazxZGAwAyo7JbYLHjx+nZ555hubPn0+JiYniMm/ePLHt5MmTypYSAMBI8hwUjasiaRxA9S0V48aNE0maX3/9NTk65h8mJyeH3nrrLTF994EDB5QsJwBYkav3HtG9R5ll+hzRiWniGkmaABYQVHBLhW5AIQ7m6CjW/mjevLlS5QMAK3Pi5gMauPTPcns+LGEOYAFBBc9DER0dTfXr19fbfuvWLfL09FSibABghaISUsW1m5MDVatYtutt8KRWPZ8NKNPnAAAFgopBgwbRsGHD6IsvvqC2bduKbbweCC809tprr5l6WACwctmPF/Fq+4wffROGVk0Aa2JyUMHBBE9yNWTIEJFLwTQaDY0YMYJmz56tZBkBwAqDCifHJ5PmAYCNBxVOTk705Zdf0qxZs+jatfwFe3jkh5sbxoMD2JIj1+/Tmj9vUE5e/pTYTxN9/3ECJSakArA6pZqngnEQUaFCBe1tALAtX+29Sn9cSTD67/y9XcqkPABggUEFd3lMmzaNFi5cSCkpKWKbh4cHjR49mqZMmSK6Qp6GWzk2btxIly5dIldXV5Gb8fnnn1O9evW0+2RkZNCECRNo3bp1lJmZSaGhobRkyRLy9/c3tegAoKDUzPzuz9dbV6eGVUo2JwQvNd6tIRIoAayNyUEFBw8cEMyZM4fatGkjtkVERNDUqVPp/v37tHTp0qceY//+/TRy5Ehq0aKFCFL+/e9/U/fu3enixYvaVU95PozffvuN1q9fL2bqHDVqFA0YMEAkhQKA+WU9zpHo3KAydapX2dzFAQBLDCp+/PFH0XrQo0cP7bYmTZpQUFCQGP1RkqBix44devfXrFlDlStXphMnTlCHDh0oOTlZTAPOz9W5c2exz+rVq6lBgwZ0+PBhat26tanFBwAjpWTm0IPUrELb0zLzVyRGjgQAmBxUODs7U40aNQptr1mzpkjiNAUHEczHJ3+efg4usrOzqWvXrtp9eF6M4OBg0SpiKKjgLhK+yB4+fCiu+Th8UYp8LCWPactQn+qu0ztJ6dRj4SFKz85vlTDEnvKs+v3DOao81Kn669PYY5kcVHA3xPTp00XLAQcYjL/MZ86cKR4zVl5enpjeu127dtS4cWOxLTY2VgQociKojPMp+LGi8jQ416OgXbt2lUkiaXh4uOLHtGWoT3XW6fkHdpSe7UB2JJGhWa8ruRDdOhtB9y6Q1cM5qjzUqXrrMy0tf7RWmQcVp06doj179lC1atUoJCREbDtz5gxlZWVRly5dRN6DjHMvnoZzK86fP08HDx6k0pg0aRKNHz9er6WCu2Q4V4NnAVUyeuM3rlu3biVKSoXioT7VXaf2F+KILp2hZtUr0tq3WpItwjmqPNSp+utTbu0v86CCWw8GDhyot42/vE3BLRtbt24Vi5BxkCILCAgQQQovsa7bWhEXFyceM4RbTeSWE11cwWVx0pbVcW0V6lOddZpH+RNVOTk62Pz7g3NUeahT9dansccxOajgbo/SkiRJjCLZtGkT7du3T+Rj6GrWrJl4QdwiIgcwkZGRYs0RecQJAJgmJjmdvj98k9Kzis6TkF2590hcY8VPACjTya/i4+PFFz3j+SUqVapU4r/lLg8e2fHLL7+IRcjkPAkeOsrzVvA1ry/C3RmcvMndFxyEcECBkR8ApfP1gShadSjKqL+p4IpfkwBQBkFFamqq+IL/7rvvRJIlc3BwEGuBLFq0qERJkfKw0xdffLFQK8gbb7whbs+fP5/s7e1FS4Xu5FcAUDpJ6fnDQ9s+40tNg/SToQ3RONjTy82edE8CACgWVHDrAU9e9euvv4oRG4yTLP/1r3+JGTBLMk8Fd388jYuLCy1evFhcAEA52bn5//+6NfSnoe30ux4BAMo1qPj5559pw4YNeq0MPXv2FN0Wr7zySomCCgAwn6ycXG0LBACAEuxLM3bV0PobPCOmseNaAaB85eZJtJOHiSL5EgAUZPKnCSdL8sJhvOCXLD09XUw8hZEZAOof+SF7tqq3WcsCANbD5O6PBQsW0EsvvVRo8ivOgdi5c6eSZQQAhWXl5CdXaxzsqEGgcpPCAYBtMzmoePbZZ+nKlSv0ww8/iKXLGS8kNnjwYJFXAQDqX1nUywVDRAHAzEEFTwXKC3vxLJjDhw9XsDgAoJQzt5Npf4wdxUfcFMO9dcUk53dbIp8CAMweVPAsl7q5FACgvu6NsNXHKTXLgTbeyJ+czhB351LPfwcAoGXyJwrPhvn555/TN998Q46O+GACUJO0rBxKzcofMtqzsb+YQK4gOzs7GvB8VTOUDgCslcnRwLFjx8SaHLykOOdXuLu76z1ekpVJAaBsEzF5qfIvB4VgsSYAKBeKrlIKAOqQ+TiocMxfXBQAQJ1BBa/zMXfuXLp8+bJYlrxz5840depUjPgAKCffRdygVQejKK+YWe5zHo/uQB4mAKg6qJg5c6YIIrp27SoCiYULF4qVSletWlU2JQQAPd9F3KQb90s2a21lxPoAoOagglcl5VVC33nnHXF/9+7d1KtXL5GwaSgZDADKJl9i9oBnqW6AZ5H75eTk0M3Tf5ZjyQDA1hkdVERHR4uFw2TcYsFZ5Hfv3hWzawJA+QQVjat6i0tx88nEnCvHggGAzTM6qOBfPzwVty7OLOcPMAAoOxnZuXQ0KpFSs3LEfUxcBQAWH1RIkkRvvPEGOTs7a7fxRFjvvvuu3rBSDCkFUNaM3y7S94ejtfddHPVnyQQAsLigIiwsrNC2f/7zn0qVBwCKEJ2Yv7JosI8bvVDHj4J8kIUJABYeVKxevbpsSgIAxcp+nEvxfmg96hNSxdzFAQAoBJ2yABa2sqiTA/7bAoA6YdEOABVJSMmkqVsu0IO0rEKPRcY+EtdOmCYTAFQKQQWAiuy6EEdbz8YUu0+VCsilAAB1QlABoLLVRVmz6hVpSJvqhR6vWsGV6gd4maFkAABPh6ACQIV5E7X83KlvUyxLDgCWBUEFgJnk5Ul0PSGV8qQnK4PFJmeIa0xsBQCWCEEFgJl8vPk8rT36ZDIrXRqM8AAAC4SgAsBMLt5NFtcezo56LRNuTg70UuMAM5YMAMA0CCoAzCTz8WRWSwY/Tx3qVjJ3cQAASg1trABmki1PZoX8CQCwEvg0AzCTa/Gp4hpBBQBYC3yaAZiBPMqD+bg5mbUsAABKQVABYAaPMrK1t2v4uZu1LAAASkFQAWDGSa78vZzNXRQAAMUgqAAoZ5k5uZSSkT8dN+ajAABrgiGlAOVo+f5rNHvHJZIn0USSJgBYE7N/oh04cIB69+5NVapUITs7O9q8ebPe45Ik0eTJkykwMJBcXV2pa9eudOXKFbOVF6A0DlyJ1wYUrEMdzE8BANbD7EFFamoqhYSE0OLFiw0+PmfOHFq4cCEtW7aMjhw5Qu7u7hQaGkoZGU+y5wEsRdbjCa8WDGpKFz8Lpal9Gpm7SAAA1tP90aNHD3ExhFspFixYQJ988gn17dtXbPvuu+/I399ftGi8+uqr5VxaAGWCCk8XR3JzMvt/PwAARan6Uy0qKopiY2NFl4fM29ubWrVqRREREQgqQDUu3E2mfZHxT90v5vH8FEjQBABrpOqgggMKxi0Tuvi+/FhBmZmZ4iJ7+PChuM7OzhYXpcjHUvKYtszS63PUDycp6n5aifd3dSz712rpdao2qE/loU7VX5/GHkvVQYUpZs2aRdOmTSu0fdeuXeTm5qb484WHhyt+TFtmqfUZm+RARHYU4pNHLnyzGH4uEt0++yfdPVc+ZbPUOlUr1KfyUKfqrc+0tJL/WFJ9UBEQkL/8c1xcnBj9IeP7TZs2Nfg3kyZNovHjx+u1VAQFBVH37t3Jy8tL0eiN37hu3bqRRqNR7Li2ytLr88Pju4ly82jBGx2pWkVXUgNLr1O1QX0qD3Wq/vqUW/utIqioWbOmCCz27NmjDSL4BfIokBEjRhj8G2dnZ3EpiCu4LE7asjqurbLU+pQTMN1cnFRXfkutU7VCfSoPdare+jT2OGYPKlJSUujq1at6yZmnT58mHx8fCg4OprFjx9KMGTOoTp06Isj49NNPxZwW/fr1M2u5ofyWBx+6+hhdin1EapYnT2aFBEwAsGFmDyqOHz9OnTp10t6Xuy7CwsJozZo1NHHiRDGXxdtvv01JSUnUvn172rFjB7m4uJix1FBersWn0MGrCWQJqlZwFUNFAQBsldk/AV988UUxH0VReJbNzz77TFzA9sjdCpU8nem/w1qSmgX7uJEjWioAwIaZPagAKElQ4e7kQPUDlEu0BQAA5SGoALO6eT+Vzt5OptzcXDqVYEfSuVhycHgyJvNKXH4uBRbeAgBQPwQVYDY5uXnUb/EhepAmT67iQN9eOWtwX1fNUyZ/AAAAs0NQAWaTkZOnDSha1qhIDxLvk6+vL9nZ6bdKONjb0ZA21c1USgAAKCkEFWD2fAn23dDmtHPHdurZswXGqwMAWCh0VINZ56CQWyL4AgAAlg0tFVBmAcPEDWfpxv3Up7ZUYMIoAADrgKACygSP6Nh06k6J9lXLWhkAAFA6CCqgTGRk52pnmZzSu2Gx+z4XXLGcSgUAAGUJQQWUiazH+RIV3TXUvVH+arNPW10PAAAsG4IKULyFghf/0k5ahXwJAACbgaACFDVk5VE6eiNRex8zYQIA2A4EFaCoy/fyWygCvFzIRWNPr7YINneRAACgnCCoAEXJw0T/905rqu7rbu7iAABAOULbNJTJhFbo9gAAsD1oqQCTSZJEi36/StfiU7TbsnMlcY0ETQAA24OgAkx2OS6F5oVfNriiqLszTi0AAFuDT34wWUpm/twSFd00NKpzHe32pkHe5IKlygEAbA6CCjBZVk5+V4evhzMNa1/T3MUBAAAzQ1BhpXJy8yg5vWxnqbyfmimukT8BAAAMQYUVyszJpW7zDlB0Ylq5PJ8GIz0AAABDSq1TTFJGuQUU9nZE3Rv6l8tzAQCAuqGlworniuAEypOfdivz57Ozsyvz5wAAAPVDUGGFMnOeTECFL3wAACgvCCoszJ/XEujPq/eL3SfuYYa41iCBEgAAyhGCCgubwfKd707Qo8ycEu3v7aop8zIBAADIEFRYkJw8SRtQ/KNVcLFDOe3t7OhvIYHlWDoAALB1CCosMAGTfdKrAbk54e0DAAD1QKe7BS4rzjDhFAAAqA1+6lqAB6lZ9MryCLr9IF3c5wEdDjxBBAAAgIogqLAAJ6Mf0JV7T5YXD6lWAUNFAQBAdRBUWFAuxbNVvWnxP56nKhVczF0kAACAQhBUWNBkVh7OjhTs62bu4gAAABiEoEJhNxJS6WhUoqLHPHHzgXaGTAAAALVCUKGwsNVH6eb9slnMy93ZoUyOCwAAYFNBxeLFi2nu3LkUGxtLISEhtGjRImrZsiWpTUxy/hTZ7Wr7koujckEAT7k9/IVaih0PAADAJoOK//3vfzR+/HhatmwZtWrVihYsWEChoaEUGRlJlStXJjVNoy3PJTF/UFOq7ImESgAAsB0W0Uk/b948Gj58OA0dOpQaNmwoggs3NzdatWoVqW0abZmzA7oqAADAtqi+pSIrK4tOnDhBkyZN0m6zt7enrl27UkRERKH9MzMzxUX28OFDcZ2dnS0uSvjhSDT9ePQWPUpxoMXXDmnnjMiTngQVJOWQQk9nE+T3Rqn3CFCnSkN9Kg91qv76NPZYqg8qEhISKDc3l/z9/fW28/1Lly4V2n/WrFk0bdq0Qtt37dolWjeUEHHLni7f40YeO4pJSy30uLdGot/DdxEmvTReeHi4uYtgdVCnykJ9Kg91qt76TEtLs66gwljcosH5F7otFUFBQdS9e3fy8vJS5DkaJabR3+Mf0ckTJ+n5Zs+To6N+NdYP8CRfdydFnstWcDTM/xG6detGGg2WbFcC6lRZqE/loU7VX59ya7/VBBV+fn7k4OBAcXFxetv5fkBAQKH9nZ2dxaUgrmClKrm2vzdV93Gj1GsSdaznj/8MClLyfYJ8qFNloT6VhzpVb30aexzVJ2o6OTlRs2bNaM+ePdpteXl54n6bNm3MWjYAAACwoJYKxt0ZYWFh1Lx5czE3BQ8pTU1NFaNBAAAAQB0sIqgYNGgQxcfH0+TJk8XkV02bNqUdO3YUSt4EAAAA87GIoIKNGjVKXAAAAECdVJ9TAQAAAJYBQQUAAAAoAkEFAAAA2FZORWkW+TJlAo+STDLCM43xcTG+uvRQn8pDnSoL9ak81Kn661P+7pS/S8nWg4pHjx6Ja55VEwAAAEz7LvX29n7qfnZSScMPC8UTZd29e5c8PT21C38pQZ7++9atW4pN/23LUJ/KQ50qC/WpPNSp+uuTQwQOKKpUqSIW8yRbb6ngSqhWrVqZHZ/fOPxnUA7qU3moU2WhPpWHOlV3fZakhUKGRE0AAABQBIIKAAAAUASCChPxSqhTpkwxuCIqGA/1qTzUqbJQn8pDnVpffVp9oiYAAACUD7RUAAAAgCIQVAAAAIAiEFQAAACAIhBUAAAAgCIQVJhg8eLFVKNGDXJxcaFWrVrR0aNHyRYdOHCAevfuLWZa49lKN2/erPc45wBPnjyZAgMDydXVlbp27UpXrlzR2ycxMZEGDx4sJmqpUKECDRs2jFJSUvT2OXv2LL3wwguivnm2uDlz5hQqy/r166l+/fpin2effZa2bdtGlmbWrFnUokULMftr5cqVqV+/fhQZGam3T0ZGBo0cOZJ8fX3Jw8ODBg4cSHFxcXr7REdHU69evcjNzU0c54MPPqCcnBy9ffbt20fPP/+8yBKvXbs2rVmzxurO86VLl1KTJk20EwG1adOGtm/frn0cdVl6s2fPFv/3x44dq92Gei25qVOnivrTvfDnmEXXJY/+gJJbt26d5OTkJK1atUq6cOGCNHz4cKlChQpSXFycZGu2bdsmffzxx9LGjRt5BJG0adMmvcdnz54teXt7S5s3b5bOnDkj9enTR6pZs6aUnp6u3eell16SQkJCpMOHD0t//PGHVLt2bem1117TPp6cnCz5+/tLgwcPls6fPy+tXbtWcnV1lZYvX67d59ChQ5KDg4M0Z84c6eLFi9Inn3wiaTQa6dy5c5IlCQ0NlVavXi1e5+nTp6WePXtKwcHBUkpKinafd999VwoKCpL27NkjHT9+XGrdurXUtm1b7eM5OTlS48aNpa5du0qnTp0S75Gfn580adIk7T7Xr1+X3NzcpPHjx4v6WrRokai/HTt2WNV5vmXLFum3336TLl++LEVGRkr//ve/xXnB9ctQl6Vz9OhRqUaNGlKTJk2kMWPGaLejXktuypQpUqNGjaSYmBjtJT4+3qLrEkGFkVq2bCmNHDlSez83N1eqUqWKNGvWLMmWFQwq8vLypICAAGnu3LnabUlJSZKzs7MIDBif4Px3x44d0+6zfft2yc7OTrpz5464v2TJEqlixYpSZmamdp8PP/xQqlevnvb+K6+8IvXq1UuvPK1atZLeeecdyZLdu3dP1M/+/fu19cdfiuvXr9fu89dff4l9IiIixH3+ULG3t5diY2O1+yxdulTy8vLS1uHEiRPFB5muQYMGiaDG2s9zPpe++eYb1GUpPXr0SKpTp44UHh4udezYURtUoF6NDyr4R5UhllqX6P4wQlZWFp04cUI04+uuLcL3IyIizFo2tYmKiqLY2Fi9uuL547lZTa4rvuYuj+bNm2v34f25To8cOaLdp0OHDuTk5KTdJzQ0VHQLPHjwQLuP7vPI+1j6e5KcnCyufXx8xDWfe7y0se5r5abS4OBgvTrl7h9/f3+9uuCFhi5cuFCi+rLG8zw3N5fWrVtHqampohsEdVk63CTPTe4FXzvq1XjcJcxdyLVq1RJdwdydYcl1iaDCCAkJCeLDSfcNZHyfv0DhCbk+iqsrvuY+QF2Ojo7iS1R3H0PH0H2Oovax5PeEV9flfup27dpR48aNxTZ+PRxccSBWXJ2aWl/8QZSenm5V5/m5c+dEXzT3Jb/77ru0adMmatiwIeqyFDg4O3nypMgBKgj1ahz+kcX5DTt27BA5QPxjjPPHeFVQS61Lq1+lFMBSfwmeP3+eDh48aO6iWLR69erR6dOnRavPhg0bKCwsjPbv32/uYlksXlJ7zJgxFB4eLhL6oHR69Oihvc1JxRxkVK9enX766SeR3G6J0FJhBD8/P3JwcCiUfcv3AwICzFYuNZLro7i64ut79+7pPc5ZyzwiRHcfQ8fQfY6i9rHU92TUqFG0detW2rt3L1WrVk27nV8PN1UmJSUVW6em1hePkOAPMms6z/mXHme7N2vWTPyyDgkJoS+//BJ1aSJuJuf/szySgFsV+cJB2sKFC8Vt/nWLejUdt0rUrVuXrl69arHnKIIKIz+g+MNpz549es3UfJ/7aeGJmjVrihNSt664uY1zJeS64mv+D8MfVLLff/9d1ClH7PI+PHSV+xZl/CuJf4FWrFhRu4/u88j7WNp7wvmuHFBwEz3XA9ehLj73NBqN3mvl3BLug9WtU27y1w3WuC74A4Sb/UtSX9Z8nvPryMzMRF2aqEuXLqJOuPVHvnBOFOcCyLdRr6bj4fTXrl0Tw/At9hw1OrXTxvHQGx7BsGbNGjF64e233xZDb3Szb20FZ4DzMCa+8Kk0b948cfvmzZvaIaVcN7/88ot09uxZqW/fvgaHlD733HPSkSNHpIMHD4qMct0hpZwBzUNKX3/9dTEUkOufh0cVHFLq6OgoffHFFyI7mjOqLXFI6YgRI8QQ3H379ukNMUtLS9MbYsbDTH///XcxxKxNmzbiUnCIWffu3cWwVB42VqlSJYNDzD744ANRX4sXLzY4xMzSz/OPPvpIjJyJiooS5x/f55FFu3btEo+jLpWhO/qDoV5LbsKECeL/O5+j/DnGQ0N5SCiP/LLUukRQYQIe58tvNI/r5aE4PMeCLdq7d68IJgpewsLCtMNKP/30UxEU8AnbpUsXMV+Arvv374sgwsPDQwyDGjp0qAhWdPEcF+3btxfHqFq1qghWCvrpp5+kunXriveEh0/x/ASWxlBd8oXnrpBxQPbee++JoZH8QdG/f38ReOi6ceOG1KNHDzGfB39A8QdXdnZ2ofeuadOmor5q1aql9xzWcp6/+eabUvXq1UX5+YOWzz85oGCoy7IJKlCvJcdDOwMDA0X5+bON71+9etWi6xJLnwMAAIAikFMBAAAAikBQAQAAAIpAUAEAAACKQFABAAAAikBQAQAAAIpAUAEAAACKQFABAAAAikBQAQCKu3HjBtnZ2Ympm8vKG2+8Qf369dPef/HFF8XKrgBgPggqAMDgFzYHBQUvL730Uon+PigoiGJiYrTLtpeHjRs30vTp08vt+QCgMCx9DgAGcQCxevVqvW3Ozs4l+lte9bC8V4v08fEp1+cDgMLQUgEABnEAwYGB7kVeGZZbLZYuXUo9evQQyyfXqlWLNmzYUGT3x4MHD8RKlpUqVRL716lTRy9g4ZUWO3fuLB7z9fWlt99+W6zYKMvNzaXx48eLpaH58YkTJ4pVXXUV7P7g5xwyZIgos5ubmyjrlStXyrTOAGwdggoAMMmnn35KAwcOpDNnzoiA4dVXX6W//vqryH0vXrxI27dvF/twQOLn5yceS01NpdDQUPHlf+zYMVq/fj3t3r1bLAMv+89//kNr1qyhVatW0cGDBykxMVEsEf+0Lpzjx4/Tli1bKCIiQgQhPXv2pOzsbIVrAgC0TFqGDACsGq80y8sju7u7611mzpwpHuePDl6WWVerVq3E8u2Ml3LmfU6dOiXu9+7dW6xAa8iKFSvEKowpKSnabbzKrL29vXbpZV7Jcc6cOdrHeRXGatWqSX379jW4Wubly5fF8/Ny0rKEhASxkiOvaAsAZQM5FQBgUKdOnUSLQlF5C23atNF7jO8XNdpjxIgRolXj5MmT1L17dzFqo23btuIxbrkICQkhd3d37f7t2rWjvLw8ioyMJBcXF5H02apVK+3jjo6O1Lx580JdIDI+Ju+j+zfcbVKvXr0iW1MAoPQQVACAQfwlX7t2bUWOxfkMN2/epG3btlF4eDh16dKFRo4cSV988YUixwcAdUBOBQCY5PDhw4XuN2jQoMj9OUkzLCyMvv/+e1qwYAGtWLFCbOe/4bwMzq2QHTp0iOzt7UXLgre3NwUGBtKRI0e0j+fk5NCJEyeKfC4+Ju+j+zf3798XLR8NGzY0+TUDQPHQUgEABmVmZlJsbKzeNu5SkBMsOaGSuyDat29PP/zwAx09epRWrlxp8FiTJ0+mZs2aUaNGjcRxt27dqg1AOMlzypQpIuCYOnUqxcfH0+jRo+n1118nf39/sc+YMWNo9uzZYtRI/fr1ad68eZSUlFRk2Xm/vn370vDhw2n58uXk6elJH330EVWtWlVsB4CygZYKADBox44dooVA98IBhGzatGm0bt06atKkCX333Xe0du3aIlsBnJycaNKkSWLfDh06iHks+G8ZD/fcuXOnGNHRokULevnll0X3yFdffaX9+wkTJogggwMPzt3gIKF///7Flp+HrHIg87e//U38DedfcPeLRqNRrI4AQJ8dZ2sW2AYAUCyeg4KHdOpOkw0AgJYKAAAAUASCCgAAAFAEEjUBwGjoNQUAQ9BSAQAAAIpAUAEAAACKQFABAAAAikBQAQAAAIpAUAEAAACKQFABAAAAikBQAQAAAIpAUAEAAACKQFABAAAApIT/B17pIE0nHOE2AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "NameError",
          "evalue": "name 'list_stats' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#@title Proporción de aciertos por número de episodios\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plot(np\u001b[38;5;241m.\u001b[39mcumsum(stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_rewards\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMáxima proporcion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlist_stats\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'list_stats' is not defined"
          ]
        }
      ],
      "source": [
        "#@title Proporción de aciertos por número de episodios\n",
        "\n",
        "plot(np.cumsum(stats['episode_rewards']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoP1jHL_StI9"
      },
      "source": [
        "####.\n",
        "Mostramos los valores Q para cada estado. Cada estado tienen 4 valores, que se corresponden con las 4 acciones que se pueden en cada estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "psRtMmxyFkFq",
        "outputId": "f9e44658-ea7b-49fe-affb-b1453c055dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores Q para cada estado:\n",
            " [[0.29589277 0.3994403  0.49264012 0.47290253]\n",
            " [0.35187396 0.         0.59760714 0.4847541 ]\n",
            " [0.50523343 0.62551897 0.52461677 0.59503106]\n",
            " [0.59880609 0.         0.49255952 0.53846154]\n",
            " [0.14051702 0.45153115 0.         0.45640172]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.80099237 0.         0.62467866]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.06582399 0.         0.60414585 0.22088353]\n",
            " [0.40533981 0.75925926 0.79355889 0.        ]\n",
            " [0.6935609  0.95633637 0.         0.62506329]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.78969957 0.96081606 0.68197279]\n",
            " [0.81329394 0.96070786 1.         0.80140804]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "# @title Tabla de valores Q\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "print(\"Valores Q para cada estado:\\n\", Q)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsJ-AgwcTgdO"
      },
      "source": [
        "- También se muestra la política óptima (greedy) obtenida a partir del aprendizaje anterior.\n",
        "\n",
        "- Cada estado tienen 4 valores, pero todos son 0 menos 1. Es decir, en cada estado se aplica de manera determinística una única acción.\n",
        "\n",
        "*TODO:* Mostrar de forma gráfica el escenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "dA0-q-woGYL2",
        "outputId": "b5cfb689-5329-49d1-8c47-b96de08a5105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Política óptima obtenida\n",
            " [[0. 0. 2. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 0.]] \n",
            " Acciones 2, 2, 1, 1, 1, 2,  \n",
            " Para el siguiente grid\n",
            "   (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Política final\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "pi, actions = pi_star_from_Q(env4, Q)\n",
        "\n",
        "print(\"Política óptima obtenida\\n\", pi, f\"\\n Acciones {actions} \\n Para el siguiente grid\\n\", env4.render())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tUyGCBuS41T"
      },
      "source": [
        "### **3.3 Experimentación en el escenario 8x8**\n",
        "\n",
        "  - Se realizan 5000 epsisodios y se actualizan los valores Q (valor de acción) basándose en las recompensas obtenidas durante cada episodio completo (e.d. aplicamos Monte Carlo) Se apica una política $\\epsilon$ greedy sobre una política $\\epsilon$ soft con un valor $\\epsilon$ decreciente\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "ttDsqDX16sSj",
        "outputId": "ea0da61a-0fd7-4fad-b75e-f92deaaf6551"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5046/50000 [00:12<02:27, 304.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.19996000799840033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 10052/50000 [00:30<02:15, 294.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.0999900009999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 15040/50000 [00:48<02:00, 290.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.06666222251849876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 20033/50000 [01:06<02:22, 210.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.04999750012499375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 25032/50000 [01:24<01:34, 264.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.03999840006399744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 30031/50000 [01:42<01:12, 276.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.033332222259258026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 35057/50000 [02:01<00:54, 272.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.02857061226822091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 40026/50000 [02:19<00:35, 281.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.02499937501562461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 45036/50000 [02:37<00:17, 280.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success: 0.0, epsilon: 0.02222172840603542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [02:55<00:00, 285.50it/s]\n"
          ]
        }
      ],
      "source": [
        "# @title Aprendizaje\n",
        "Q, list_stats = on_policy_all_visit(env8, num_episodes=50000, epsilon=0.4, decay=True, discount_factor=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Z_tbLcAq6yWR",
        "outputId": "bd14600f-00cd-4cc1-a5d0-81f972a3a295"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAE9CAYAAADH11J0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANSBJREFUeJzt3QmcTfX/+PH3DGMZQrZhrIns9I2MkVLZKUsrX0X48iV8FSlKltTPLmvKt+jbt0QjJGkiaxi7lF0hInuIYQzO7/H+/P7n/u+duTNmxpnlzLyej8cxc8/9nHPPed9j7vt+thNgWZYlAAAAGVxgeh8AAABAUpC0AAAAVyBpAQAArkDSAgAAXIGkBQAAuAJJCwAAcAWSFgAA4AokLQAAwBVIWgAAgCuQtABIsfnz58u4cePkxo0b6X0oALIAkhYAfr3wwgtStmzZBJ9fv369dOjQQapUqSLZsmVL9eNZtWqVBAQEmJ8AsiaSFiARH3/8sfmgtJdcuXLJPffcI71795aTJ09KVnX27Flp166dTJ48WVq0aJHehwMgi8ie3gcAuMFbb70ld911l1y9elXWrl0r06dPlyVLlsjOnTslODhYMqN///vfcvPmTb/Pbd++Xd5++23p2LFjmh8XgKyLpAVIgubNm0vt2rXN7//4xz+kUKFCMmHCBPnqq6+kffv2fre5fPmy5MmTRzKS5BxTUFBQgs81atRIMiNNSnPkyCGBgVRCAxkR/zOBFHj00UfNz0OHDnn6f+TNm1d+/fVX01xyxx13mP4edqLQv39/KVWqlOTMmVMqVqxoOq9aluWzT21+0manzz77zJTRpqhatWrJmjVr/NZ0aCKVL18+87oNGzaUDRs2+G3aWr16tbz44otStGhRKVmypOf5b7/9Vho0aGCOVfdz//33y+zZsxPt05Lcc1m4cKFUq1bNlK1atapERkYmKb6///67tGnTxiRYetwvv/yyxMTE+C27ceNGadasmeTPn9/Ueuk5rVu3Lsl9ZObMmSODBw+WEiVKmO0vXryYrP0eO3ZMunbtKqGhoeY8tUauZ8+ecu3aNU+ZgwcPytNPPy0FCxY0+6pbt6588803fo/niy++kOHDh5vj0ffmqaeekgsXLpjzf+mll0w89D3v3LlzvJgk5xrS4+7SpYuEhIR43p+ZM2cmeEzvvPOOuX50n3q9/fLLLz5lDxw4IE8++aQUK1bMlNGy2oSox26bNWuW+b+j56Cvqf2htNYyri1btkjTpk2lcOHCkjt3bhNTPVaAmhYgBTQ5UVrjYrt+/br5Q1u/fn3zQa4fTvph3qpVK1m5cqX5YLv33nvlu+++kwEDBpgPjXfffddnv5pgzJ07V/71r3+ZP+rvvfee+eDctGmT+fBXu3btkgcffNAkGq+++qqpEfnggw/k4YcfNtuHhYX57FMTliJFisiQIUNM0mEnNPohoB9UgwYNkgIFCphESJOKv//9737PObnnos1oOrpIX18/fLX/i36oHTlyxCducV25csV8KGo5jYMmA//9739lxYoV8crqOk3e9IN56NChpobE/mD84YcfpE6dOrd8L0eMGGFqV1555RWTBOjvSd3v8ePHze/nz5+X7t27S6VKlUws5s2bJ9HR0WZf2vepXr165rGej577f/7zHxNLLde2bVuf4xk5cqT5oB44cKBJDKZMmWLeYz2GP//8U4YNG2YSVH0P9cNc39fkXkN6TJo42UmOXh+axOr7qkmbJkfeRo0aZV5fY6RJyJgxY0xSromd0gRNr32NX58+fUzionFYvHixiY0mfkoTFL3m9NyzZ88uX3/9tbk+tBmyV69epsypU6ekSZMm5pg0BnptHj582FxLgP4hApCAWbNmaRWC9f3331unT5+2jh49as2ZM8cqVKiQlTt3buv333835Tp16mTKDRw40Gf7hQsXmvVvv/22z/qnnnrKCggIsH755RfPOi2ny5YtWzzrfvvtNytXrlxW27ZtPevatGlj5ciRw/r11189644fP27dcccd1kMPPRTv2OvXr29dv37ds/78+fOmbFhYmHXlyhWf47p586bndz2nMmXKpPhc9Bi91+3YscOsnzJlSqIxnzhxoin3xRdfeNZdvnzZKl++vFm/cuVKz7FWqFDBatq0qc9xR0dHW3fddZfVuHHjRF9H96P7K1eunNnGOwZJ3W/Hjh2twMBAa/PmzfH2b2/70ksvmdf54YcfPM/99ddfZl9ly5a1bty44XM81apVs65du+Yp2759exPf5s2b++w/PDzc5/1JzjXUtWtXq3jx4taZM2d8tm/Xrp2VP39+TzzsY6pcubIVExPjKTdp0iSz/ueffzaPt2/fbh5HREQkGnPvONs0zvoe2BYsWGD25S+mAM1DQBJoHw795qfNIlrlrdXzCxYsMFX43rRZwJt21tXhwPqt15s2sehnjH679RYeHm6+3dtKly4trVu3NjUaOheKLkuXLjVNJ+XKlfOUK168uKkh0doNu3nD1q1bN58hycuWLZO//vrLfIvVanxv+s07Ick9F43Z3Xff7Xlco0YNUzukTSWJ0dfR89FmEZvWWmlNhrcff/zRNEnoeetopjNnzphFa5O0pkabRBLqSOytU6dOpmYjufvVRZu/Hn/8cU9/J3+x1PPR2hitgbPp9aPnozUIu3fv9tlOOzd79yfSmjONb9zmEV1/9OhRU8OXnGtI9/Xll1+a49bf7fPTRWtLtCZl27ZtPvvUpiitNbJpTZ+y30u7JkVfQ2uUEuIdZ30dfU1tdtP92M1IWrOitJYmNjY2wX0ha6J5CEiCadOmmaHOWqWtfQC0v0Dczpr6nHefEfXbb7+Z5g1tHvFWuXJlz/PeKlSoEO+19XX1g+D06dPmsf6urx+X7lM/SPWDTKvgbdqE4K9py24qSKrknot+WMZ15513miaOW71O+fLl4yVQcc9ZEws76UiIfhDqayYmbnySul9tEtEE8VZx1POJ22QXN27e+4gbNzsh0IQ57np9v/VYvJvbbnUN6XWrTTYzZswwiz/aROMt7jHZMbXfS41hv379TOd07U+jSY02AT333HOe41faJ0ib26KiouIlN3oeWlaTGG1G1H492uSozZ6apGsSqc1dyNpIWoAk0G/K/r5Ne9M/qBlx1In3t9u0lNCEc3E77aaUXYsyduxY07/GH63RSG58krrfc+fOSVrGzal42uenCUVCiZnWiiX3tcePH286b+uIOq0N1Bo57Z+j/W80mddkWWuqtN+PJjeahGntjdZEaXJiH5cmq9rXR7fTPi9ae6O1TLp/XZeU9xSZF0kLkIrKlCkj33//vWmO8a6h2Lt3r+d5f9/yve3fv980j2jzlNLf9+3bF6+c7lOTprjfyOOym2x0jhmt0Uitc0kp3Y8em34gete2xD1n+zy0ycnJIdhJ3a++H1pGj/VW55PQ+2U/76SkXEP6/mlTkdND16tXr24WHY2lMyY/8MAD8v7775s5fTQB0Y66ixYt8qm50Y7d/mhHYV101JKOatOOvzrSS6ccQNaV8b4WApmIDn/WD4epU6f6rNdvlvqBrCNUvGm1uXd/Am3q0W+uOppCv+3qor/rOu0PYdPRIPqHXftN6AdpYnR7/dDSb8E6L0lSv7Un91xSSl9HR+Xot22bNiXEbcrQfhuaYOhIrUuXLsXbj92cllxJ3a8miNpsoR/GOkQ3LjuWej46ckffW5v2j9Hz0SHlOuzXSUm5hrT5Rfu1+Eu4UhI3bSaL27dGkxeNkT0s266t8b7GtElIR2V50yanuNehXeOV0LB3ZB3UtACpSDs7PvLII/LGG2+YJKNmzZqm6lw/RHRYqXdHVaV9G7QzpPdwVaXt+zb91qqdaTVB0eGi2pdGhzzrH3QdinormtRooqHfWHVuFu0roH0UduzYYZIDHY7rxLmklHYc1sRIO6Ru3brVdMrVIc9xZx7WD8QPP/zQJEvah0c7i2rHaB1qq9/e9Tw1oUiu5Oz3f/7nf0wMtB+GdqzVfip//PGHREREmE7R2qlUOzx//vnnZn/6vupcLRpjneNHEwenmxSTcg3pEGY9F+1ro/HWxEmbuzTZ0dq05DZ96RBxHTqtc9Fo/xlNYPQ9sxMkpUmTNgfpdfTPf/7TJIQ667LO2aIxs2ls9Jh1KLheU1qzp+U07twyAgx5BhJhDxu+1fBLHR6cJ08ev8/p8NaXX37ZCg0NtYKCgsxw2rFjx/oMp1X6Or169bI+/fRTUyZnzpzW3/72N88QX2/btm0zQ0Xz5s1rBQcHW4888oi1fv36ZB37okWLrHr16pmh2/ny5bPq1Kljff755z7nFHdIbXLPJS7dn+73VnSYbqtWrcy5FS5c2Orbt68VGRnpM+TZpsNtn3jiCTMMXWOmr/HMM89Yy5cvT/Q17OG8CQ3TTep+9Vh16HORIkVMOR2+q+fuPURYh6fr0PACBQqY4cca68WLFyfpeBJ6H4cOHWrW61D8lFxDJ0+eNGVLlSpl3stixYpZDRs2tGbMmHHLYzp06JBZr8emDh48aHXp0sW6++67zfkVLFjQXJM6VUDca65GjRqmjA73Hj16tDVz5kyzL92nfW3rMO/SpUub4y9atKj12GOP+QzjRtYVoP+kd+IE4P86IOoEW3GbX4Ck4hpCZkefFgAA4AokLQAAwBVIWgAAgCvQpwUAALgCNS0AAMAVSFoAAIArMLmcA/SeGTqDp84ymthdcgEAgC/tpaKTCOoNWW812SJJiwM0YbnV/V4AAEDC9JYTenPNxJC0OMC+eZwG/Fb3fUmq2NhYMz24Tn0dFBTkyD6zOmLqLOLpPGLqLOLpjpjqvav0i7/3jVgTQtLiALtJSBMWJ5MWvdeK7o//bM4gps4ins4jps4inu6KaVK6V9ARFwAAuAJJCwAAcAWSFgAA4AokLQAAwBVIWgAAgCuQtAAAAFcgaQEAAK5A0gIAAFyBpAUAALgCSQsAAHAFkhYAAOAKJC0AAMAVSFoAAIArkLQAAABXIGkBAACuQNICAABcgaQFAAC4AkkLAABwBZIWAADgCiQtAADAFUhaAACAK5C0AAAAVyBpAQAArkDSAgAAXMGVScu0adOkbNmykitXLgkLC5NNmzYlWj4iIkIqVapkylevXl2WLFmSYNkePXpIQECATJw4MRWOHAAAZJmkZe7cudKvXz8ZOnSobNu2TWrWrClNmzaVU6dO+S2/fv16ad++vXTt2lW2b98ubdq0McvOnTvjlV2wYIFs2LBBQkND0+BMAABApk5aJkyYIN26dZPOnTtLlSpV5P3335fg4GCZOXOm3/KTJk2SZs2ayYABA6Ry5coyYsQIue+++2Tq1Kk+5Y4dOyZ9+vSRzz77TIKCgtLobAAAQFJlFxe5du2abN26VQYNGuRZFxgYKI0aNZKoqCi/2+h6rZnxpjUzCxcu9Dy+efOmPP/88yaxqVq16i2PIyYmxiy2ixcvmp+xsbFmcYK9H6f2B2LqNOLpPGLqLOLpjpgmZ1+uSlrOnDkjN27ckJCQEJ/1+njv3r1+tzlx4oTf8rreNnr0aMmePbv861//StJxjBw5UoYPHx5v/dKlS02tj5OWLVvm6P5ATJ1GPJ1HTJ1FPDN2TKOjozNn0pIatOZGm5C0f4x2wE0Krenxrr3RmpZSpUpJkyZNJF++fI5lnnpRNG7cmOYqhxBTZxFP5xFTZxFPd8TUbq3IdElL4cKFJVu2bHLy5Emf9fq4WLFifrfR9YmV/+GHH0wn3tKlS3ue19qc/v37mxFEhw8fjrfPnDlzmiUufQOd/o+RGvvM6oips4in84ips4hnxo5pcvbjqo64OXLkkFq1asny5ct9+qPo4/DwcL/b6Hrv8kqzRLu89mX56aef5Mcff/QsOnpI+7d89913qXxGAAAgU9a0KG2W6dSpk9SuXVvq1KljakMuX75sRhOpjh07SokSJUy/E9W3b19p0KCBjB8/Xlq2bClz5syRLVu2yIwZM8zzhQoVMkvcrE9rYipWrJgOZwgAADJF0vLss8/K6dOnZciQIaYz7b333iuRkZGezrZHjhwxI4ps9erVk9mzZ8vgwYPl9ddflwoVKpiRQ9WqVUvHswAAAJk+aVG9e/c2iz+rVq2Kt+7pp582S1L568cCAADSl6v6tAAAgKyLpAUAALgCSQsAAHAFkhYAAOAKJC0AAMAVSFoAAIArkLQAAABXIGkBAACuQNICAABcgaQFAAC4AkkLAABwBZIWAADgCiQtAADAFUhaAACAK5C0AAAAVyBpAQAArkDSAgAAXIGkBQAAuAJJCwAAcAWSFgAA4AokLQAAwBVIWgAAgCuQtAAAAFcgaQEAAK5A0gIAAFyBpAUAALgCSQsAAHAFkhYAAOAKJC0AAMAVSFoAAIArkLQAAABXcGXSMm3aNClbtqzkypVLwsLCZNOmTYmWj4iIkEqVKpny1atXlyVLlniei42Nlddee82sz5Mnj4SGhkrHjh3l+PHjaXAmAAAg0yYtc+fOlX79+snQoUNl27ZtUrNmTWnatKmcOnXKb/n169dL+/btpWvXrrJ9+3Zp06aNWXbu3Gmej46ONvt58803zc/58+fLvn37pFWrVml8ZgAAIFMlLRMmTJBu3bpJ586dpUqVKvL+++9LcHCwzJw502/5SZMmSbNmzWTAgAFSuXJlGTFihNx3330ydepU83z+/Pll2bJl8swzz0jFihWlbt265rmtW7fKkSNH0vjsAABAQrKLi1y7ds0kE4MGDfKsCwwMlEaNGklUVJTfbXS91sx405qZhQsXJvg6Fy5ckICAAClQoIDf52NiYsxiu3jxoqepSRcn2Ptxan8gpk4jns4jps4inu6IaXL25aqk5cyZM3Ljxg0JCQnxWa+P9+7d63ebEydO+C2v6/25evWq6eOiTUr58uXzW2bkyJEyfPjweOuXLl1qan2cpLVAcBYxdRbxdB4xdRbxzNgx1W4amTJpSW2a7WkzkWVZMn369ATLaU2Pd+2N1rSUKlVKmjRpkmCik5Jj0YuicePGEhQU5Mg+szpi6izi6Txi6izi6Y6Y2q0VmS5pKVy4sGTLlk1Onjzps14fFytWzO82uj4p5e2E5bfffpMVK1YkmnzkzJnTLHHpG+j0f4zU2GdWR0ydRTydR0ydRTwzdkyTsx9XdcTNkSOH1KpVS5YvX+5Zd/PmTfM4PDzc7za63ru80izRu7ydsBw4cEC+//57KVSoUCqeBQAASAlX1bQobZbp1KmT1K5dW+rUqSMTJ06Uy5cvm9FESudYKVGihOl3ovr27SsNGjSQ8ePHS8uWLWXOnDmyZcsWmTFjhidheeqpp8xw58WLF5s+M3Z/l4IFC5pECQAApD/XJS3PPvusnD59WoYMGWKSi3vvvVciIyM9nW11mLKOKLLVq1dPZs+eLYMHD5bXX39dKlSoYEYOVatWzTx/7NgxWbRokfld9+Vt5cqV8vDDD6fp+QEAgEyStKjevXubxZ9Vq1bFW/f000+bxR+dWVc73gIAgIzNVX1aAABA1kXSAgAAMn/zkI7K0UXv+6OjeLwlNK0+AABAmiYtOiPsW2+9ZUbxFC9e3Ex7DwAAkOGSFr1R4ccffyzPP/+8s0cEAADgZJ8WvXmhDicGAADI0EnLP/7xDzP/CQAAQIZuHtK7IeussjrtfY0aNeLdO2DChAlOHB8AAMDtJS0//fSTZwbZnTt3+jxHp1wAAJBhkhad4h4AAMBVk8v9/vvvZgEAAMhwSYtOJqfztOTPn1/KlCljlgIFCsiIESPiTTQHAACQZs1DOsNtnTp1PHdHfuONN+Sjjz6SUaNGyQMPPGDWrV27VoYNG2Y66b7zzju3fXAAAADJTlq0JqV58+byn//8Rx599FHz88MPP5RWrVp5yugoohIlSsiLL75I0gIAANKneahhw4bmPkMDBw40j8+dOyeVKlWKV07X6XMAAADp1qflnnvukTVr1pjfa9asKVOnTo1XRtfpcwAAAOk65DlXrlzm55gxY6Rly5Zmcrnw8HCzLioqSo4ePSpLlixx9CABAABSPHqoQYMGsn//fmnbtq2cP3/eLE888YTs27dPHnzwQWePEgAAZHkpnlxOhYaG0uEWAABkvKRFp+7XIc+BgYHm98ToSCIAAIB0SVr0XkMnTpyQokWLmt/1HkOWZcUrp+tv3Ljh2EECAAAkK2k5dOiQFClSxPM7AABAhkxadII5f78DAABk2NFDI0eONFP7x6XrRo8efbvHBQAA4EzS8sEHH/idEbdq1ary/vvvp3S3AAAAziYt2iG3ePHi8dZrn5c//vgjpbsFAABwNmkpVaqUrFu3Lt56XafztwAAAGSIyeW6desmL730ksTGxpq7Piu9oeKrr74q/fv3d/IYAQAAUp60DBgwQM6ePSsvvviiXLt2zXNfotdee00GDRrk5DECAACkLGnRieO0GWjgwIHy5ptvyp49eyR37txSoUIFyZkzp/NHCQAAsrwUJS3ZsmWTJk2amGTlrrvukvvvv9/5IwMAAHCiI67eg+jgwYOSHqZNmyZly5Y1zVFhYWGyadOmRMtHRESY4dlavnr16rJkyRKf5/VWBEOGDDGjobTGqFGjRnLgwIFUPgsAAJAmScvbb78tr7zyiixevNgMcb548aLPklrmzp0r/fr1k6FDh8q2bdukZs2a0rRpUzl16pTf8uvXr5f27dtL165dZfv27dKmTRuz7Ny501NmzJgxMnnyZDO/zMaNGyVPnjxmn1evXk218wAAAGmUtLRo0UJ27NghrVq1kpIlS8qdd95plgIFCpifqWXChAlm5FLnzp2lSpUqJtEIDg72OzuvmjRpkjRr1sx0HK5cubKMGDFC7rvvPpk6daqnlmXixIkyePBgad26tbk79SeffCLHjx+XhQsXptp5AACANBo9tHLlSklrOkpp69atPqOTAgMDTXNOVFSU3210vdbMeNNaFDsh0Rs/6kR5ug9b/vz5TbOTbtuuXbt4+4yJiTGLza5Z0uHfujjhhVmb5eCJbDLt13Xmrtm4fZqg/nWJmDqFeDqPmDqLeKZOTGOvZJPGjZ35rFPJ+dxMcdLSoEEDSWtnzpwxI5dCQkJ81uvjvXv3+t1GExJ/5XW9/by9LqEy/u67NHz48Hjrly5damp9nLD792zy57UA+SP6siP7g42YOot4Oo+YOot4Oi13NpFly5Y5tr/o6OjUT1rU+fPn5aOPPjKjiOz7DnXp0sXUVGRmWtPjXXujNS06Q7COqMqXL58jr1Gw4mmJ2rhF7qt1n2TPfltvE/6f69evy7at24ipQ4in84ips4hn6sT0x23bpHHjxhIUFOTIPpPTDzbF7+KWLVtMM4uOtqlTp46nv8k777xjahy034jTChcubIZbnzx50me9Pi5WrJjfbXR9YuXtn7rO+15K+vjee+/1u0+di8bffDT6Bjr1Jta9u4ic22dJg4ohju0zq9MqyMu/ElOnEE/nEVNnEc/Ui6mTn3fJ2U+KO+K+/PLLphPu4cOHZf78+WbR/iGPPfaYmd4/NeTIkUNq1aplbhdgu3nzpnkcHh7udxtd711eabWWXV7nmdHExbuMZn06iiihfQIAgLR3WzUt//73v32q3PR3vfdQ7dq1JbVos0ynTp3Ma2gNj478uXz5shlNpDp27CglSpQw/U5U3759Tf+b8ePHS8uWLWXOnDnm2GfMmGGe185ZmmTpEG6d0VeTGJ3lV2/6qEOjAQCAy5MW7btx5MgRM2mbt6NHj8odd9whqeXZZ5+V06dPm8ngtKOsNuFERkZ6OtLqMemIIlu9evVk9uzZZkjz66+/bhITHTmkk+PZNNHSxKd79+6mn079+vXNPnUyOgAA4PKkRZMHnbBt3LhxJjFQej8inQ9FJ3NLTb179zaLP6tWrYq37umnnzZLQrS25a233jILAADIZEmLJiv6Ya/NMdqb2O5M07NnTxk1apSTxwgAAJDypEU7xepss9p35NdffzXr7r77bsfmKQEAAPB22wPXNUnRqfvt3wEAAFJDioc8a5OQjrLRieT0jsu66O/a4dWpqewBAABuu6alT58+Zm4WvUOyPZ+J3qtn2LBhcvbsWZk+fXpKdw0AAOBc0qLDiHXOk+bNm3vW6R2SdTp7HT1E0gIAADJE85BOY69NQnHp5GzaSRcAACBDJC06T8qIESMkJibGs05/13sPJTSHCgAAQJo3D23fvt3cr6dkyZJSs2ZNs27Hjh1y7do1adiwoTzxxBOestr3BQAAIF2SFh3m/OSTT/qs0/4sAAAAGSppmTVrlrNHAgAAkJqTy+nNC/ft22d+r1ixohQpUuR2dwkAAOBcR1y9K3KXLl2kePHi8tBDD5klNDTU3EQxOjo6pbsFAABwNmnp16+frF69Wr7++ms5f/68Wb766iuzrn///indLQAAgLPNQ19++aXMmzdPHn74Yc+6Fi1aSO7cueWZZ55hcjkAAJAxalq0CSgkJCTe+qJFi9I8BAAAMk7SovcbGjp0qFy9etWz7sqVKzJ8+HDPvYgAAADSvXlo4sSJ0qxZs3iTy+XKlUu+++47xw4QAADgtpKW6tWry4EDB+Szzz6TvXv3mnV6o8QOHTqYfi0AAADpnrTExsZKpUqVZPHixdKtWzdHDwgAAMCxPi1BQUE+fVkAAAAybEfcXr16yejRo+X69evOHhEAAICTfVo2b95s7vK8dOlS078lT548Ps9zZ2cAAJBh7/IMAACQYZKWmzdvytixY2X//v1y7do1efTRR2XYsGGMGAIAABmrT8s777wjr7/+uuTNm1dKlCghkydPNv1bAAAAMlTS8sknn8h7771nJpBbuHChuWGiztWiNTAAAAAZJmk5cuSIuTGirVGjRhIQECDHjx93+tgAAABSnrToEGedqj/uvC064RwAAECG6YhrWZa88MILkjNnTs86nWiuR48ePsOeGfIMAADSNWnp1KlTvHXPPfecU8cDAADgTNIya9YsSS/nzp2TPn36mM6/gYGBZp6YSZMmmZFMCdFaoP79+8ucOXMkJiZGmjZtajoSh4SEeO5MPWrUKFm7dq2cOXNGypYta2qN+vbtm4ZnBgAAUm0a//Sgd5DetWuXLFu2zNyscc2aNdK9e/dEt3n55ZdNkhMRESGrV682HYafeOIJz/Nbt26VokWLyqeffmr2/cYbb8igQYNk6tSpaXBGAAAg1WfETWt79uyRyMhIc/uA2rVrm3VTpkwxI5nGjRsnoaGh8ba5cOGCfPTRRzJ79mwzCZ5dU1S5cmXZsGGD1K1bV7p06eKzTbly5SQqKsr0yendu3canR0AAMg0SYsmEnrrADthsYdbazPRxo0bpW3btvG20VoUHdWk5WyVKlWS0qVLm/1p0uKPJjsFCxZM8Fi0mUkX28WLF81PfS2nRlHZ+2FUlnOIqbOIp/OIqbOIpztimpx9uSZpOXHihGnG8ZY9e3aTXOhzCW2TI0cOk+x40/4sCW2zfv16mTt3rnzzzTcJHsvIkSNl+PDh8dbrzSODg4PFSdoUBmcRU2cRT+cRU2cRz4wd0+jo6CSXTfekZeDAgTJ69OhbNg2lhZ07d0rr1q1l6NCh0qRJkwTLaZ+Xfv36+dS0lCpVymyTL18+xzJPvSgaN25s5sHB7SOmziKeziOmziKe7oip3VrhiqRFR/bovC+J0X4mxYoVk1OnTsWb6E5HFOlz/uh6vanj+fPnfWpbTp48GW+b3bt3S8OGDU3H3sGDByd6PDpHjfc8NTZ9A53+j5Ea+8zqiKmziKfziKmziGfGjmly9pPuSUuRIkXMcivh4eEm+dB+KrVq1TLrVqxYYe55FBYW5ncbLafBWL58uRkerfbt22duRaD7s+moIe2oq3PQ6A0hAQBAxuOaIc864qdZs2bSrVs32bRpk6xbt86M7mnXrp1n5NCxY8dMR1t9XuXPn1+6du1qmnJWrlxpEp7OnTubhMXuhKtNQo888ohp2tFy2tdFl9OnT6fr+QIAgAxW05IcejdpTVS0GceeXG7y5Mk+bW1ak+Ldqefdd9/1lPWeXM42b948k6DoPC262MqUKSOHDx9Ow7MDAACZJmnRkUI650pCdDZbvTeSN72547Rp08ziz7Bhw8wCAAAyNtc0DwEAgKyNpAUAALgCSQsAAHAFkhYAAOAKJC0AAMAVSFoAAIArkLQAAABXIGkBAACuQNICAABcgaQFAAC4AkkLAABwBZIWAADgCiQtAADAFUhaAACAK5C0AAAAVyBpAQAArkDSAgAAXIGkBQAAuAJJCwAAcAWSFgAA4AokLQAAwBVIWgAAgCuQtAAAAFcgaQEAAK5A0gIAAFyBpAUAALgCSQsAAHAFkhYAAOAKJC0AAMAVSFoAAIArkLQAAABXcFXScu7cOenQoYPky5dPChQoIF27dpVLly4lus3Vq1elV69eUqhQIcmbN688+eSTcvLkSb9lz549KyVLlpSAgAA5f/58Kp0FAADI9EmLJiy7du2SZcuWyeLFi2XNmjXSvXv3RLd5+eWX5euvv5aIiAhZvXq1HD9+XJ544gm/ZTUJqlGjRiodPQAAyBJJy549eyQyMlI+/PBDCQsLk/r168uUKVNkzpw5JhHx58KFC/LRRx/JhAkT5NFHH5VatWrJrFmzZP369bJhwwafstOnTze1K6+88koanREAAEiO7OISUVFRpkmodu3annWNGjWSwMBA2bhxo7Rt2zbeNlu3bpXY2FhTzlapUiUpXbq02V/dunXNut27d8tbb71l9nPw4MFbHktMTIxZbBcvXjQ/9bV0cYK9H6f2B2LqNOLpPGLqLOLpjpgmZ1+uSVpOnDghRYsW9VmXPXt2KViwoHkuoW1y5Mhhkh1vISEhnm00+Wjfvr2MHTvWJDNJSVpGjhwpw4cPj7d+6dKlEhwcLE7SpjA4i5g6i3g6j5g6i3hm7JhGR0e7J2kZOHCgjB49+pZNQ6ll0KBBUrlyZXnuueeStU2/fv18alpKlSolTZo0MZ2Enco89aJo3LixBAUFObLPrI6YOot4Oo+YOot4uiOmdmuFK5KW/v37ywsvvJBomXLlykmxYsXk1KlTPuuvX79uRhTpc/7o+mvXrpm+Kt61LTp6yN5mxYoV8vPPP8u8efPMY8uyzM/ChQvLG2+84bdGJWfOnGaJS99Ap/9jpMY+szpi6izi6Txi6izimbFjmpz9pHvSUqRIEbPcSnh4uEk+tJ+Kdqi1E46bN2+ajrn+aDkNxvLly81QZ7Vv3z45cuSI2Z/68ssv5cqVK55tNm/eLF26dJEffvhB7r77bofOEgAA3K50T1qSSptwmjVrJt26dZP333/fVFH17t1b2rVrJ6GhoabMsWPHpGHDhvLJJ59InTp1JH/+/GYYszblaN8Xbbrp06ePSVjsTrhxE5MzZ854Xi9uXxgAAJB+XJO0qM8++8wkKpqY6KghrT2ZPHmy53lNZLQmxbtTz7vvvuspq51umzZtKu+99146nQEAAMgSSYvWlsyePTvB58uWLevpk2LLlSuXTJs2zSxJ8fDDD8fbBwAASH+umVwOAABkbSQtAADAFUhaAACAK5C0AAAAVyBpAQAArkDSAgAAXIGkBQAAuAJJCwAAcAWSFgAA4AokLQAAwBVIWgAAgCuQtAAAAFcgaQEAAK5A0gIAAFyBpAUAALgCSQsAAHAFkhYAAOAKJC0AAMAVSFoAAIArkLQAAABXIGkBAACuQNICAABcgaQFAAC4AkkLAABwhezpfQCZgWVZ5ufFixcd22dsbKxER0ebfQYFBTm236yMmDqLeDqPmDqLeLojpvZnp/1ZmhiSFgf89ddf5mepUqXS+1AAAHDtZ2n+/PkTLRNgJSW1QaJu3rwpx48flzvuuEMCAgIcyzw1CTp69Kjky5fPkX1mdcTUWcTTecTUWcTTHTHVNEQTltDQUAkMTLzXCjUtDtAglyxZMlX2rRcF/9mcRUydRTydR0ydRTwzfkxvVcNioyMuAABwBZIWAADgCiQtGVTOnDll6NCh5iecQUydRTydR0ydRTwzX0zpiAsAAFyBmhYAAOAKJC0AAMAVSFoAAIArkLQAAABXIGnJoKZNmyZly5aVXLlySVhYmGzatEmymjVr1sjjjz9uZknUmYYXLlzo87z2IR8yZIgUL15ccufOLY0aNZIDBw74lDl37px06NDBTIJUoEAB6dq1q1y6dMmnzE8//SQPPvigibXO9DhmzJh4xxIRESGVKlUyZapXry5LliwRtxk5cqTcf//9ZubmokWLSps2bWTfvn0+Za5evSq9evWSQoUKSd68eeXJJ5+UkydP+pQ5cuSItGzZUoKDg81+BgwYINevX/cps2rVKrnvvvvMCIPy5cvLxx9/nCmv8enTp0uNGjU8E22Fh4fLt99+63meeN6eUaNGmf/7L730kmcdMU2eYcOGmRh6L/q3zLXx1NFDyFjmzJlj5ciRw5o5c6a1a9cuq1u3blaBAgWskydPWlnJkiVLrDfeeMOaP3++jnCzFixY4PP8qFGjrPz581sLFy60duzYYbVq1cq66667rCtXrnjKNGvWzKpZs6a1YcMG64cffrDKly9vtW/f3vP8hQsXrJCQEKtDhw7Wzp07rc8//9zKnTu39cEHH3jKrFu3zsqWLZs1ZswYa/fu3dbgwYOtoKAg6+eff7bcpGnTptasWbPMef74449WixYtrNKlS1uXLl3ylOnRo4dVqlQpa/ny5daWLVusunXrWvXq1fM8f/36datatWpWo0aNrO3bt5v3qHDhwtagQYM8ZQ4ePGgFBwdb/fr1M/GaMmWKiV9kZGSmu8YXLVpkffPNN9b+/futffv2Wa+//rq5NjTGinim3KZNm6yyZctaNWrUsPr27etZT0yTZ+jQoVbVqlWtP/74w7OcPn3atfEkacmA6tSpY/Xq1cvz+MaNG1ZoaKg1cuRIK6uKm7TcvHnTKlasmDV27FjPuvPnz1s5c+Y0iYfS/zy63ebNmz1lvv32WysgIMA6duyYefzee+9Zd955pxUTE+Mp89prr1kVK1b0PH7mmWesli1b+hxPWFiY9c9//tNys1OnTpn4rF692hM//cCNiIjwlNmzZ48pExUVZR7rH6zAwEDrxIkTnjLTp0+38uXL54nhq6++av5Ienv22WdN0pQVrnG9nj788EPieRv++usvq0KFCtayZcusBg0aeJIWYpqypEW/uPnjxnjSPJTBXLt2TbZu3WqaOrzvbaSPo6Ki0vXYMpJDhw7JiRMnfOKk967QKkc7TvpTm4Rq167tKaPlNZ4bN270lHnooYckR44cnjJNmzY1zSZ//vmnp4z369hl3P5+XLhwwfwsWLCg+anXnd523vtctRq5dOnSPjHV5rGQkBCfWOhN1Hbt2pWkeGXWa/zGjRsyZ84cuXz5smkmIp4pp80V2hwR97yJacpos7k2s5crV840l2tzj1vjSdKSwZw5c8b88fO+QJQ+1g9p/B87FonFSX9q+6u37Nmzmw9p7zL+9uH9GgmVcfP7oXcm134CDzzwgFSrVs2s0/PR5E0TvcRimtJ46R+5K1euZLpr/OeffzZ9AbQtv0ePHrJgwQKpUqUK8UwhTfy2bdtm+mDFRUyTT7/Iaf+SyMhI0wdLv/BpHz69q7Ib48ldnoEsSL/J7ty5U9auXZveh+J6FStWlB9//NHUXM2bN086deokq1evTu/DcqWjR49K3759ZdmyZaazJm5f8+bNPb9rp3FNYsqUKSNffPGFGcDgNtS0ZDCFCxeWbNmyxeu9rY+LFSuWbseV0dixSCxO+vPUqVM+z2uPdx1R5F3G3z68XyOhMm59P3r37i2LFy+WlStXSsmSJT3r9Xy0Gvf8+fOJxjSl8dLRNfpHMrNd4/pNVUdL1KpVy9QO1KxZUyZNmkQ8U0CbEPT/rI5C0VpRXTQBnDx5svldv5kT09ujtSr33HOP/PLLL668RklaMuAfQP3jt3z5cp+qfH2s7eT4P3fddZe52L3jpFWR2lfFjpP+1P+M+ofQtmLFChNP/bZhl9Gh1dqua9Nvefrt+c477/SU8X4du4zb3g/tz6wJizZfaBw0ht70ugsKCvI5V+3bo+3f3jHV5hDvZFBjoX+ctEkkKfHK7Ne4nktMTAzxTIGGDRuaeGjNlb1onzTth2H/Tkxvj0758Ouvv5qpIlx5jSar2y7ShA4N01EwH3/8sRkB0717dzM0zLv3dlagIwh0iJ0ueqlOmDDB/P7bb795hjxrXL766ivrp59+slq3bu13yPPf/vY3a+PGjdbatWvNiATvIc/ae16HPD///PNmmKrGXofuxR3ynD17dmvcuHGmZ732xnfjkOeePXuaIeKrVq3yGf4YHR3tM/xRh0GvWLHCDH8MDw83S9zhj02aNDHDpnVIY5EiRfwOfxwwYICJ17Rp0/wOf8wM1/jAgQPN6KtDhw6Za1Af6+i0pUuXmueJ5+3zHj2kiGny9O/f3/yf12tU/5bp0GUdsqyjB90YT5KWDErHueuFpOPadaiYzjOS1axcudIkK3GXTp06eYY9v/nmmybp0P8MDRs2NHNleDt79qxJUvLmzWuG6HXu3NkkQ950jpf69eubfZQoUcIkQ3F98cUX1j333GPeDx3ap3NzuI2/WOqic7fYNOF78cUXzbBd/SPUtm1bk9h4O3z4sNW8eXMzn43+8dM/irGxsfHeu3vvvdfEq1y5cj6vkZmu8S5dulhlypQx56B/yPUatBMWRTydT1qIafLo0OPixYubc9C/b/r4l19+cW08A/SflFUyAQAApB36tAAAAFcgaQEAAK5A0gIAAFyBpAUAALgCSQsAAHAFkhYAAOAKJC0AAMAVSFoAuNLhw4clICDATO+eWl544QVp06aN5/HDDz9s7o4NIH2QtABIF5oQaNIRd2nWrFmSti9VqpT88ccfUq1aNUkr8+fPlxEjRqTZ6wHwlT3OYwBIM5qgzJo1y2ddzpw5k7St3jU2re+4W7BgwTR9PQC+qGkBkG40QdHEw3ux766ttS7Tp0+X5s2bm9vblytXTubNm5dg89Cff/5p7gZcpEgRU75ChQo+CZHeqfbRRx81zxUqVEi6d+9u7nhru3HjhvTr108KFChgnn/11VfNnbG9xW0e0tfs2LGjOebg4GBzrAcOHEjVmAFZGUkLgAzrzTfflCeffFJ27NhhEpJ27drJnj17Eiy7e/du+fbbb00ZTXgKFy5snrt8+bI0bdrUJBebN2+WiIgI+f7776V3796e7cePHy8ff/yxzJw5U9auXSvnzp2TBQsW3LKJa8uWLbJo0SKJiooySU6LFi0kNjbW4UgAMJJ9i0UAcIDerVtvX58nTx6f5Z133jHP65+nHj16+GwTFhZm9ezZ0/x+6NAhU2b79u3m8eOPP27u4u3PjBkzzF1sL1265Fmnd+oODAy0Tpw4YR7rnXDHjBnjeV7vYluyZEmrdevWfu84vH//fvP669at8zx/5swZcydcvSs4AOfRpwVAunnkkUdMjUhC/UbCw8N9ntPHCY0W6tmzp6mV2bZtmzRp0sSM+qlXr555TmteatasKXny5PGUf+CBB+TmzZuyb98+yZUrl+nUGxYW5nk+e/bsUrt27XhNRDbdp5bx3kablSpWrJhgbRCA20PSAiDdaBJRvnx5R/al/Ul+++03WbJkiSxbtkwaNmwovXr1knHjxjmyfwDpjz4tADKsDRs2xHtcuXLlBMtrJ9xOnTrJp59+KhMnTpQZM2aY9bqN9ovRvi22devWSWBgoKkZyZ8/vxQvXlw2btzoef769euydevWBF9L96llvLc5e/asqbmpUqVKis8ZQMKoaQGQbmJiYuTEiRM+67TJxe5Aqx1mtYmmfv368tlnn8mmTZvko48+8ruvIUOGSK1ataRq1apmv4sXL/YkONqJd+jQoSahGTZsmJw+fVr69Okjzz//vISEhJgyffv2lVGjRplRR5UqVZIJEybI+fPnEzx2Lde6dWvp1q2bfPDBB3LHHXfIwIEDpUSJEmY9AOdR0wIg3URGRpoaDu9FExTb8OHDZc6cOVKjRg355JNP5PPPP0+wFiNHjhwyaNAgU/ahhx4y87jotkqHI3/33XdmRND9998vTz31lGk+mjp1qmf7/v37myRGExvtO6NJSNu2bRM9fh1SrYnSY489ZrbR/i/aPBUUFORYjAD8fwHaG9frMQBkCDoHiw459p5GH0DWRk0LAABwBZIWAADgCnTEBZAh0XINIC5qWgAAgCuQtAAAAFcgaQEAAK5A0gIAAFyBpAUAALgCSQsAAHAFkhYAAOAKJC0AAMAVSFoAAIC4wf8Cr3xSyezD4Z4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Máxima proporcion: 0.0\n"
          ]
        }
      ],
      "source": [
        "#@title Proporción de aciertos por número de episodios\n",
        "\n",
        "plot(list_stats)\n",
        "print(f\"Máxima proporcion: {list_stats[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dptS3Xv8v8H7"
      },
      "source": [
        "####.\n",
        "Mostramos los valores Q para cada estado. Cada estado tienen 4 valores, que se corresponden con las 4 acciones que se pueden en cada estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "scmn1mwlwBam",
        "outputId": "f2597e0f-bcd0-4daa-e4a3-0e939279f24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores Q para cada estado:\n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# @title Tabla de valores Q\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "print(\"Valores Q para cada estado:\\n\", Q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWQWD7UqwH2Y"
      },
      "source": [
        "- También se muestra la política óptima (greedy) obtenida a partir del aprendizaje anterior.\n",
        "\n",
        "- Cada estado tienen 4 valores, pero todos son 0 menos 1. Es decir, en cada estado se aplica de manera determinística una única acción.\n",
        "\n",
        "*TODO:* Mostrar de forma gráfica el escenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1n6i3oMzwSG3",
        "outputId": "0dd2772e-e096-41d8-e2ae-18d809e2b098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Política óptima obtenida\n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]] \n",
            " Acciones 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,  \n",
            " Para el siguiente grid\n",
            "   (Left)\n",
            "\u001b[41mS\u001b[0mFFFFFFF\n",
            "FFFFFFFF\n",
            "FFFHFFFF\n",
            "FFFFFHFF\n",
            "FFFHFFFF\n",
            "FHHFFFHF\n",
            "FHFFHFHF\n",
            "FFFHFFFG\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Política final\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "pi, actions = pi_star_from_Q(env8, Q)\n",
        "\n",
        "print(\"Política óptima obtenida\\n\", pi, f\"\\n Acciones {actions} \\n Para el siguiente grid\\n\", env8.render())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG0Z813yhKz7"
      },
      "source": [
        "## **4. Análisis y Estudios Futuros**\n",
        "\n",
        "### **4.1 Análisis de Resultados**\n",
        "\n",
        "- En los dos entornos (4x4 y 8x8), el agente comienza con un conocimiento muy limitado, pero gradualmente mejora su desempeño a medida que avanza en los episodios. Este comportamiento se puede observar en el gráfico de la proporción de recompensas, que aumenta con el tiempo.\n",
        "- En el entorno 4x4, la máxima proporción de éxito alcanzada fue 0.522, mientras que en el entorno 8x8, la máxima alcanzada fue 0.914. Esto refleja que el agente aprendió a optimizar su estrategia en un entorno más complejo.\n",
        "- La política óptima obtenida muestra las acciones recomendadas por el agente en cada estado del entorno. En el entorno 8x8, la política es más compleja debido a la mayor cantidad de estados y la dificultad del entorno.\n",
        "\n",
        "### **4.2 Propuestas para Estudios Futuros**\n",
        "\n",
        "1. **Evaluar con Otros Entornos**: Sería interesante aplicar este algoritmo a otros entornos más complejos de `gym`, como \"Taxi-v3\" o \"MountainCar\", para analizar cómo se comporta el agente en situaciones con dinámicas más complicadas.\n",
        "   \n",
        "2. **Optimización del Decaimiento de Epsilon**: Aunque se utilizó un decaimiento de epsilon en el segundo experimento, se podría investigar la efectividad de diferentes tasas de decaimiento o incluso explorar algoritmos como `Q-learning` para comparar su desempeño. Graficamente se trataría de mostrar la curva de la tasa de aciertos para distintas funciones de decaimientos\n",
        "\n",
        "3. **Análisis del Impacto de los descuentos en las Recompensas**: El estudio se ha hecho para $\\gamma = 1$; pero no se ha probado qué pasa cuando  $0 \\leq \\gamma < 1$. Se trataría de estudiar la curva para distintos valores de $\\gamma$\n",
        "\n",
        "4. **Nuevas gráficas**: Aquí solo se ha usado la proporción de aciertos, pero sería interesante qué relación entre dicha tasa y las tamaños de los episodios.\n",
        "\n",
        "4. **Ampliación del Algoritmo**: Explorar otros enfoques de Monte Carlo o incluso combinar Monte Carlo con otros algoritmos de aprendizaje por refuerzo, como el Deep Q-Network (DQN), podría mejorar aún más los resultados en entornos más complejos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNjZJK7Hx6/LtHVZ0/ulFcl",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

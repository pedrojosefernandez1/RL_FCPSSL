{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldaniel-hm/eml_k_bandit/blob/main/MonteCarloTodasLasVisitas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SipaVo-gz1ey"
      },
      "source": [
        "# **Monte Carlo con Políticas epsilon-soft**\n",
        "\n",
        "_Esto es un ejemplo de uso de Gymnasium e informe sobre un experimento de aprendizaje por refuerzo_\n",
        "\n",
        "````\n",
        "Luis D. Hernández.\n",
        "<ldaniel at um.es>\n",
        "````\n",
        "\n",
        "Este notebook describe un experimento de aprendizaje por refuerzo utilizando el algoritmo de Monte Carlo con políticas epsilon-soft. El propósito de este análisis es entrenar un agente en un entorno de gym con el juego \"FrozenLake\", un entorno estándar en el que el agente debe aprender a moverse a través de un mapa en busca de una meta, evitando caer en agujeros. A continuación, se presenta una descripción de las diferentes partes del código y el proceso utilizado en el experimento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loCIjd-T0AVg"
      },
      "source": [
        "## **1. Preparación del Entorno**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2MTvyPWcU2q"
      },
      "source": [
        "La preparación consta de las siguientes partes:\n",
        "- **Instalación de Dependencias**: Se instalan las librerías necesarias para utilizar el entorno `gymnasium` para la simulación, con el objetivo de crear un ambiente controlado para que el agente pueda interactuar.\n",
        "- **Importación de Librerías**: Se importan las bibliotecas necesarias como `numpy` para el manejo de matrices y `matplotlib` para la visualización de los resultados.\n",
        "\n",
        "- **Importación del Entorno \"FrozenLake\"**:\n",
        "Se cargan dos versiones del entorno \"FrozenLake\": una de 4x4 y otra de 8x8. Ambas versiones no son resbaladizas, lo que facilita la comprensión de los resultados, dado que el entorno resbaladizo podría dificultar la comprensión inicial del aprendizaje.\n",
        "\n",
        "#### 3. **Funciones para Mostrar los Resultados**\n",
        "   - Se define una función para graficar la proporción de recompensas obtenidas en cada episodio del entrenamiento. Esto ayuda a visualizar el progreso del agente en términos de su desempeño durante el entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P7_98YrcsZw"
      },
      "source": [
        "##### _________ **Código de la Instalación e Importación**\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "s-wSiHxNyuBH"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Instalamos gym\n",
        "#! pip install 'gym[box2d]==0.20.0'\n",
        "#! pip install tqdm\n",
        "#! pip install gymnasium\n",
        "#! pip install \"gymnasium[toy-text]\n",
        "#! pip install \"gymnasium[other]\n",
        "#!pip install tiles3\n",
        "## Instalación de algunos paquetes.\n",
        "#!apt-get update\n",
        "## Para usar gymnasium[box2d]\n",
        "#!pip install swig\n",
        "\n",
        "#! pip install Box2D gym ----> solucion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "o5s4pz9Hzk7r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python313.zip', 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\DLLs', 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib', 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313', 'e:\\\\Proyectos personales Y cosiscas mias\\\\Trabajo-Uni\\\\MASTER\\\\EML\\\\RL_FCPSSL\\\\.venv', '', 'e:\\\\Proyectos personales Y cosiscas mias\\\\Trabajo-Uni\\\\MASTER\\\\EML\\\\RL_FCPSSL\\\\.venv\\\\Lib\\\\site-packages', 'e:\\\\Proyectos personales Y cosiscas mias\\\\Trabajo-Uni\\\\MASTER\\\\EML\\\\RL_FCPSSL\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'e:\\\\Proyectos personales Y cosiscas mias\\\\Trabajo-Uni\\\\MASTER\\\\EML\\\\RL_FCPSSL\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'e:\\\\Proyectos personales Y cosiscas mias\\\\Trabajo-Uni\\\\MASTER\\\\EML\\\\RL_FCPSSL\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'src']\n"
          ]
        }
      ],
      "source": [
        "#@title Importamos librerias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import gymnasium as gym\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append('src')\n",
        "\n",
        "print(sys.path)\n",
        "\n",
        "from plotting import plot_episode_rewards, plot_len_episodes, render_episode, show_images_grid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def id_ft_ext(state):\n",
        "    return np.array(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Proyectos personales Y cosiscas mias\\Trabajo-Uni\\MASTER\\EML\\RL_FCPSSL\\.venv\\Lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at e:\\Proyectos personales Y cosiscas mias\\Trabajo-Uni\\MASTER\\EML\\RL_FCPSSL\\videos\\CartPole-v1\\SarsaSemiGradientEpsilonGreedyAgent(gamma0.99_alpha0.5_alpha_decay0.9995_min_alpha0.001_epsilon1_epsilon_decay0.9995_min_epsilon0.01) folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "arrays used as indices must be of integer (or boolean) type",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# agent = MonteCarloEpsilonGreedyAgent(env, epsilon=0.4, epsilon_decay=1)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# agent = QLearningEpsilonGreedyAgent(env, epsilon=1, gamma=0.99, alpha=1, epsilon_decay=0.995, min_epsilon=0.01)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# agent = SarsaEpsilonGreedyAgent(env, epsilon=1, gamma=0.99, alpha=1, epsilon_decay=0.995, min_epsilon=0.01)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m agent \u001b[38;5;241m=\u001b[39m SarsaSemiGradientEpsilonGreedyAgent(env_cart, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, epsilon_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9995\u001b[39m, alpha_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9995\u001b[39m, min_epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m stats \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mstats()\n",
            "File \u001b[1;32me:\\Proyectos personales Y cosiscas mias\\Trabajo-Uni\\MASTER\\EML\\RL_FCPSSL\\src\\agents\\approximation_methods\\sarsa\\sarsa_semi_gradient.py:84\u001b[0m, in \u001b[0;36mSarsaSemiGradientAgent.train\u001b[1;34m(self, num_episodes, render_interval, video_path)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtrain(num_episodes, render_interval, video_path)  \u001b[38;5;66;03m# Configuración de video\u001b[39;00m\n\u001b[0;32m     83\u001b[0m state, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 84\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_episodes)):\n\u001b[0;32m     86\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32me:\\Proyectos personales Y cosiscas mias\\Trabajo-Uni\\MASTER\\EML\\RL_FCPSSL\\src\\agents\\approximation_methods\\sarsa\\sarsa_semi_gradient_epsilongreedy.py:40\u001b[0m, in \u001b[0;36mSarsaSemiGradientEpsilonGreedyAgent.get_action\u001b[1;34m(self, state, info)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, info):\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    Selecciona una acción usando la política ε-greedy con función de aproximación.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EpsilonGreedy\u001b[38;5;241m.\u001b[39mget_action(\u001b[38;5;28mself\u001b[39m, state, info, Q_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m s: np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[a, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(s)]) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnA)]), action_space\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnA)\n",
            "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ],
      "source": [
        "from agents import MonteCarloEpsilonGreedyAgent, SarsaEpsilonGreedyAgent, QLearningEpsilonGreedyAgent, SarsaSemiGradientEpsilonGreedyAgent\n",
        "#env = gym.make(\"FrozenLake-v1\", is_slippery=True, render_mode=None)\n",
        "#n_episodes = 10000\n",
        "np.random.seed(32) \n",
        "n_episodes = 30000\n",
        "#env = gym.make('FrozenLake-v1', is_slippery=False, map_name=\"4x4\", render_mode=\"rgb_array\", max_episode_steps=500) # No resbaladizo para entender mejor los resultados.\n",
        "#env = gym.make('Taxi-v3', render_mode=\"rgb_array\", max_episode_steps=500) # No resbaladizo para entender mejor los resultados.\n",
        "#env_lunar = gym.make('LunarLander-v3', render_mode=\"rgb_array\", continuous=False)\n",
        "env_cart = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
        "#env = gym.make('FrozenLake-v1', is_slippery=False, map_name=\"4x4\", render_mode=\"rgb_array\") # No resbaladizo para entender mejor los resultados.\n",
        "env2 = gym.make('FrozenLake-v1', is_slippery=False, map_name=\"4x4\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados.\n",
        "\n",
        "# agent = MonteCarloEpsilonGreedyAgent(env, epsilon=0.4, epsilon_decay=1)\n",
        "# agent = QLearningEpsilonGreedyAgent(env, epsilon=1, gamma=0.99, alpha=1, epsilon_decay=0.995, min_epsilon=0.01)\n",
        "# agent = SarsaEpsilonGreedyAgent(env, epsilon=1, gamma=0.99, alpha=1, epsilon_decay=0.995, min_epsilon=0.01)\n",
        "agent = SarsaSemiGradientEpsilonGreedyAgent(env_cart, epsilon=1, gamma=0.99, alpha=0.5, min_alpha=0.001, epsilon_decay=0.9995, alpha_decay=0.9995, min_epsilon=0.01)\n",
        "\n",
        "agent.train(n_episodes, render_interval=1000, video_path='videos')\n",
        "\n",
        "stats = agent.stats()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "identity_feature_extraction(env_lunar.observation_space.sample()).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "cumsum = np.cumsum(stats['episode_rewards'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'numpy.int64' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      2\u001b[0m array2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m sum2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43marray2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m sum2\n",
            "\u001b[1;31mTypeError\u001b[0m: 'numpy.int64' object is not callable"
          ]
        }
      ],
      "source": [
        "array = np.array([1, 2, 3, 4, 5])\n",
        "array2 = np.array([-1, -2, -3, -4, -5])\n",
        "sum2 = sum(np.array([array,array2]))\n",
        "sum2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.70000e+01 3.60000e+01 6.40000e+01 ... 3.04069e+05 3.04079e+05\n",
            " 3.04089e+05]\n"
          ]
        }
      ],
      "source": [
        "print(cumsum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAE9CAYAAAAGUBjYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZgpJREFUeJzt3XlYlGX3B/DvzDAzrMO+CiKLgihooeC4oiAj+rMoKjVT3FPBUsqtzK16LSvNEjUzl95XM+11KcUFEXBDTcIFFxJEcRtwAxRkGGbu3x/E8zoyKODAwHA+18V1Oc9z5p4zhwGOz3LfPMYYAyGEEEKIAeHrOwFCCCGEEF2jBocQQgghBocaHEIIIYQYHGpwCCGEEGJwqMEhhBBCiMGhBocQQgghBocaHEIIIYQYHGpwCCGEEGJwqMEhhBBCiMGhBocQ0ii2bduGr7/+GiqVSt+pEEJaAGpwCCEvbNSoUWjTpk2N+48dO4bhw4fDz88PAoGgwfNJSUkBj8dDSkpKg78WIaRpogaHEB1Zv349eDwe92VsbIx27dohNjYW+fn5+k5Pb+7du4ehQ4fiu+++w8CBA/WdDiGkhTDSdwKEGJqFCxfCw8MDZWVlOHLkCFauXImEhARkZmbC1NRU3+k1iB9//BFqtVrrvoyMDHz22WcYOXJkI2dFCGnJqMEhRMciIiLQpUsXAMC4ceNga2uLJUuWYOfOnRg2bJjW55SUlMDMzKwx03yuuuQkFApr3BcWFqarlJqUsrIyiEQi8Pl0IJyQpoh+MglpYP369QMA5ObmAqi8XsXc3Bw5OTkYOHAgLCwsMHz4cACVTcUHH3wANzc3iMVi+Pj44OuvvwZjTGNMHo+H2NhYbNy4ET4+PjA2NkZgYCAOHTpU7fUzMjIQEREBiUQCc3NzhIaG4vjx4xoxVafXUlNTMXnyZDg4OMDV1ZXbv2fPHvTp0wcWFhaQSCTo2rUrNm3axO3Xdg1OXd/Ljh070LFjR4jFYnTo0AF79+6tVX1v3LiByMhImJmZwcHBAdOmTYNCodAae+LECQwYMACWlpYwNTVFnz59cPTo0ee+RtU1PZs3b8acOXPQqlUrmJqaori4uE7j3rx5E2PHjoWLiwvEYjE8PDwwadIklJeXczFXrlzBm2++CRsbG5iamqJbt27YvXu31ny2bNmCBQsWoFWrVrCwsMAbb7yBoqIiKBQKTJ06FQ4ODjA3N8fo0aOr1aQun6GbN29izJgxcHR05L4/a9eurTGnzz//HK6urjA2NkZoaCiys7M1Yi9fvoyoqCg4OTnB2NgYrq6uGDp0KIqKiriYdevWoV+/fnBwcIBYLIafnx9WrlxZLbdTp05BJpPBzs4OJiYm8PDwwJgxY2r6VpIWhI7gENLAcnJyAAC2trbctoqKCshkMvTs2RNff/01TE1NwRjDK6+8guTkZIwdOxadO3fGvn37MH36dNy8eRNLly7VGDc1NRW//vor3nvvPYjFYqxYsQIDBgzAyZMn0bFjRwDA+fPn0atXL0gkEsyYMQNCoRA//PADQkJCkJqaiuDgYI0xJ0+eDHt7e8ydOxclJSUAKpufMWPGoEOHDpg9ezasrKyQkZGBvXv34u2339b6nuv6Xo4cOYJt27Zh8uTJsLCwwHfffYeoqCjk5eVp1O1pjx8/RmhoKPLy8vDee+/BxcUF//73v3Hw4MFqsQcPHkRERAQCAwMxb9488Pl87o/o4cOHERQUVOPrVPn0008hEonw4YcfQqFQQCQS1XrcW7duISgoCIWFhZgwYQJ8fX1x8+ZN/PbbbygtLYVIJEJ+fj66d++O0tJSvPfee7C1tcWGDRvwyiuv4LfffsNrr72mkc+iRYtgYmKCWbNmITs7G99//z2EQiH4fD4ePHiA+fPn4/jx41i/fj08PDwwd+5cjefX5jOUn5+Pbt26cQ2Rvb099uzZg7Fjx6K4uBhTp07VGPOLL74An8/Hhx9+iKKiIixevBjDhw/HiRMnAADl5eWQyWRQKBSYMmUKnJyccPPmTezatQuFhYWwtLQEAKxcuRIdOnTAK6+8AiMjI/zxxx+YPHky1Go1YmJiAAAFBQUIDw+Hvb09Zs2aBSsrK1y9ehXbtm177veStACMEKIT69atYwDYgQMH2J07d9j169fZ5s2bma2tLTMxMWE3btxgjDEWHR3NALBZs2ZpPH/Hjh0MAPvss880tr/xxhuMx+Ox7OxsbhsABoCdOnWK23bt2jVmbGzMXnvtNW5bZGQkE4lELCcnh9t269YtZmFhwXr37l0t9549e7KKigpue2FhIbOwsGDBwcHs8ePHGnmp1Wru39HR0czd3b3e70UkEmlsO3PmDAPAvv/+e/Ys3377LQPAtmzZwm0rKSlh3t7eDABLTk7mcm3bti2TyWQaeZeWljIPDw/Wv3//Z75OcnIyA8A8PT1ZaWmpRg1qO+7IkSMZn89nf/75Z7Xxq547depUBoAdPnyY2/fw4UPm4eHB2rRpw1QqlUY+HTt2ZOXl5VzssGHDGI/HYxERERrjS6VSje8PY7X/DI0dO5Y5Ozuzu3fvajx/6NChzNLSkqtHVU7t27dnCoWCi1u2bBkDwM6dO8cYYywjI4MBYFu3bq1Whyc9WecqMpmMeXp6co+3b9/OAGitKSF0iooQHQsLC4O9vT3c3NwwdOhQmJubY/v27WjVqpVG3KRJkzQeJyQkQCAQ4L333tPY/sEHH4Axhj179mhsl0qlCAwM5B63bt0ar776Kvbt2weVSgWVSoX9+/cjMjISnp6eXJyzszPefvttHDlyhDvFUmX8+PEat3EnJibi4cOHmDVrFoyNjTVieTxejTWo63sJCwuDl5cX9zggIAASiQRXrlyp8TWqXsfZ2RlvvPEGt83U1BQTJkzQiDt9+jQuX76Mt99+G/fu3cPdu3dx9+5dlJSUIDQ0FIcOHarxIuknRUdHw8TEpM7jqtVq7NixA4MHD+auz3pSVS0TEhIQFBSEnj17cvvMzc0xYcIEXL16FRcuXNB43siRIzWufwoODgZjrNopmuDgYFy/fh0VFRUa25/3GWKM4b///S8GDx4Mxhj3/u7evQuZTIaioiL89ddfGmOOHj0aIpGIe9yrVy8A4L6XVUdo9u3bh9LS0ppKrVHnoqIi3L17F3369MGVK1e4U1lWVlYAgF27dkGpVNY4FmmZ6BQVIToWHx+Pdu3awcjICI6OjvDx8al2IaqRkZHGNS4AcO3aNbi4uMDCwkJje/v27bn9T2rbtm21127Xrh1KS0tx584dAEBpaSl8fHyqxbVv3x5qtRrXr19Hhw4duO0eHh4acVWn16pOV9RWXd9L69atq41hbW2NBw8ePPd1vL29qzVbT7/ny5cvA6hsUGpSVFQEa2vrZ77e0/Wp7bjl5eUoLi5+bh2vXbtW7bQhoFm3J8d4um5VzYObm1u17Wq1GkVFRRqn/J73GeLz+SgsLMTq1auxevVqrTkXFBRoPH46p6qaVn0vPTw8EBcXhyVLlmDjxo3o1asXXnnlFbzzzjtc/gBw9OhRzJs3D2lpadUaoaKiIlhaWqJPnz6IiorCggULsHTpUoSEhCAyMhJvv/02xGKx1nxJy0ENDiE6FhQUpPV/6U8Si8VN8u6bJ//X3JhqmvyPPXVBcn1VHZ356quv0LlzZ60x5ubmzx3n6frUdtz79+/XPtk6qKluuqpn1ft75513amziAgIC6vza33zzDUaNGoWdO3di//79eO+997Bo0SIcP34crq6uyMnJQWhoKHx9fbFkyRK4ublBJBIhISEBS5cu5fLi8Xj47bffcPz4cfzxxx/Yt28fxowZg2+++QbHjx+v1feUGC5qcAhpItzd3XHgwAE8fPhQ48jHpUuXuP1Pqjp68KS///4bpqamsLe3B1B5uiYrK6ta3KVLl8Dn86v9T/9pVaeNMjMz4e3t3WDvpb7c3d2RmZkJxpjGUZyn33PV+5BIJDq9bb2249rb20MikSAzM/OZ47m7u9f4/arar0u1+QxZWFhApVLp/HZ/f39/+Pv7Y86cOTh27Bh69OiBVatW4bPPPsMff/wBhUKB33//XeOIUHJystaxunXrhm7duuHzzz/Hpk2bMHz4cGzevBnjxo3Tac6keWl6/4UkpIUaOHAgVCoVli9frrF96dKl4PF4iIiI0Nielpamcf3D9evXsXPnToSHh0MgEEAgECA8PBw7d+7E1atXubj8/Hxs2rQJPXv2hEQieWZO4eHhsLCwwKJFi1BWVqax71lHA+r6Xupr4MCBuHXrFn777TduW2lpabXTKYGBgfDy8sLXX3+NR48eVRun6pReXdV2XD6fj8jISPzxxx84depUtbiqWg4cOBAnT55EWloat6+kpASrV69GmzZt4OfnV688a1Kbz1BUVBT++9//am3O6lO34uLiatcC+fv7g8/nc7eyVx0FevIzVlRUhHXr1mk878GDB9U+h1VH0mqaKoC0HHQEh5AmYvDgwejbty8+/vhjXL16FZ06dcL+/fuxc+dOTJ06VeMiXKDyuhiZTKZxiy8ALFiwgIv57LPPkJiYiJ49e2Ly5MkwMjLCDz/8AIVCgcWLFz83J4lEgqVLl2LcuHHo2rUr3n77bVhbW+PMmTMoLS3Fhg0bdPJe6mv8+PFYvnw5Ro4cifT0dDg7O+Pf//53tRmj+Xw+1qxZg4iICHTo0AGjR49Gq1atcPPmTSQnJ0MikeCPP/6o8+vXZdx//etf2L9/P/r06YMJEyagffv2uH37NrZu3YojR47AysoKs2bNwi+//IKIiAi89957sLGxwYYNG5Cbm4v//ve/Oj+tWZvP0BdffIHk5GQEBwdj/Pjx8PPzw/379/HXX3/hwIEDdT79dvDgQcTGxuLNN99Eu3btUFFRgX//+99cMwVUNtYikQiDBw/Gu+++i0ePHuHHH3+Eg4MDbt++zY21YcMGrFixAq+99hq8vLzw8OFD/Pjjj5BIJLQsCKHbxAnRlapbrZ93y2p0dDQzMzPTuu/hw4ds2rRpzMXFhQmFQta2bVv21VdfadyCzFjlLb4xMTHsP//5D2vbti0Ti8XspZde4m6LftJff/3FZDIZMzc3Z6ampqxv377s2LFjdcr9999/Z927d2cmJiZMIpGwoKAg9ssvv2i8p6dvQ67re3mau7s7i46O1prPk65du8ZeeeUVZmpqyuzs7Nj777/P9u7dq3GbeJWMjAz2+uuvM1tbWyYWi5m7uzt76623WFJS0jNfo+oW6Jpuba7tuNeuXWMjR45k9vb2TCwWM09PTxYTE6NxW3VOTg574403mJWVFTM2NmZBQUFs165dtcqnpu/jvHnzGAB2584dbltdPkP5+fksJiaGubm5MaFQyJycnFhoaChbvXr1c3PKzc1lANi6desYY4xduXKFjRkzhnl5eTFjY2NmY2PD+vbtyw4cOKDxvN9//50FBAQwY2Nj1qZNG/bll1+ytWvXMgAsNzeXMVb52R42bBhr3bo1E4vFzMHBgf3f//2fxq3vpOXiMaajq/gIIY2Gx+MhJiam2ikgQmqLPkPE0NE1OIQQQggxONTgEEIIIcTgUINDCCGEEIND1+AQQgghxODQERxCCCGEGBxqcAghhBBicGiiv0akVqtx69YtWFhYPHMlZkIIIYRoYozh4cOHcHFxqdWkl9TgNKJbt249d+0fQgghhNTs+vXrcHV1fW4cNTiNqGrRwevXrz93DaC6UCqV2L9/P8LDwyEUCnU2bnNHddGO6lIzqo12VJeaUW20a4i6FBcXw83NTWMB32ehBqcRVZ2WkkgkOm9wTE1NIZFI6AfsCVQX7aguNaPaaEd1qRnVRruGrEttL/Ggi4wJIYQQYnCowSGEEEKIwaEGhxBCCCEGhxocQgghhBgcanAIIYQQYnCowSGEEEKIzpWr9Pv6em1wVq5ciYCAAO62aalUij179nD7y8rKEBMTA1tbW5ibmyMqKgr5+fkaY+Tl5WHQoEEwNTWFg4MDpk+fjoqKCo2YlJQUvPzyyxCLxfD29sb69eur5RIfH482bdrA2NgYwcHBOHnypMb+2uRCCCGEtHS3Ch9j4e5LmJsugLy4TG956LXBcXV1xRdffIH09HScOnUK/fr1w6uvvorz588DAKZNm4Y//vgDW7duRWpqKm7duoXXX3+de75KpcKgQYNQXl6OY8eOYcOGDVi/fj3mzp3LxeTm5mLQoEHo27cvTp8+jalTp2LcuHHYt28fF/Prr78iLi4O8+bNw19//YVOnTpBJpOhoKCAi3leLoQQQkhLlnu3BDN+O4M+XyXj38fz8FjFw+5zcv0lxJoYa2trtmbNGlZYWMiEQiHbunUrt+/ixYsMAEtLS2OMMZaQkMD4fD6Ty+VczMqVK5lEImEKhYIxxtiMGTNYhw4dNF5jyJAhTCaTcY+DgoJYTEwM91ilUjEXFxe2aNEixhirVS61UVRUxACwoqKiWj+nNsrLy9mOHTtYeXm5Tsdt7qgu2lFdaka10Y7qUjOqDWNZ8mL23i9/MY9Zu5j7zMqvIauOsi837OT+FutCXf+GNpmZjFUqFbZu3YqSkhJIpVKkp6dDqVQiLCyMi/H19UXr1q2RlpaGbt26IS0tDf7+/nB0dORiZDIZJk2ahPPnz+Oll15CWlqaxhhVMVOnTgUAlJeXIz09HbNnz+b28/l8hIWFIS0tDQBqlYs2CoUCCoWCe1xcXAygcoZHpVJZz0pVVzWWLsc0BFQX7aguNaPaaEd1qVlLrs25m0VYmZqLxIv/O9vR18cOk3p7oqOzGRITE1FRUaGzxaXrWmO9Nzjnzp2DVCpFWVkZzM3NsX37dvj5+eH06dMQiUSwsrLSiHd0dIRcXnnISy6XazQ3Vfur9j0rpri4GI8fP8aDBw+gUqm0xly6dIkb43m5aLNo0SIsWLCg2vb9+/fD1NS0xufVV2Jios7HNARUF+2oLjWj2mhHdalZS6pNTjGw/wYfl4oqr3LhgSHAhiHcVQ1XMzluZ8pxO7MyVpd1KS0trVO83hscHx8fnD59GkVFRfjtt98QHR2N1NRUfaelE7Nnz0ZcXBz3uGqhsPDwcJ2vRZWYmIj+/fvTWihPoLpoR3WpGdVGO6pLzVpKbRhjOJpzHytTr+Dk1QcAAAGfh8H+Tni3twe8Hcw14huiLlVnQWpL7w2OSCSCt7c3ACAwMBB//vknli1bhiFDhqC8vByFhYUaR07y8/Ph5OQEAHBycqp2t1PVnU1Pxjx9t1N+fj4kEglMTEwgEAggEAi0xjw5xvNy0UYsFkMsFlfbLhQKG+QHoaHGbe6oLtpRXWpGtdGO6lIzQ60NYwxJFwvwfXI2zlwvBAAIBTy8EeiGSX280Nr22WcjdFmXuo7T5ObBUavVUCgUCAwMhFAoRFJSErcvKysLeXl5kEqlAACpVIpz585p3O2UmJgIiUQCPz8/LubJMapiqsYQiUQIDAzUiFGr1UhKSuJiapMLIYQQYihUaoZdZ28hYtlhjPv5FM5cL4TYiI9R3dvg0Iy+WPS6/3ObG33T6xGc2bNnIyIiAq1bt8bDhw+xadMmpKSkYN++fbC0tMTYsWMRFxcHGxsbSCQSTJkyBVKplLuoNzw8HH5+fhgxYgQWL14MuVyOOXPmICYmhjtyMnHiRCxfvhwzZszAmDFjcPDgQWzZsgW7d+/m8oiLi0N0dDS6dOmCoKAgfPvttygpKcHo0aMBoFa5EEIIIc2dUqXGztO3sCIlG1fulAAAzEQCjJC2wdieHrC3qH5WoqnSa4NTUFCAkSNH4vbt27C0tERAQAD27duH/v37AwCWLl0KPp+PqKgoKBQKyGQyrFixgnu+QCDArl27MGnSJEilUpiZmSE6OhoLFy7kYjw8PLB7925MmzYNy5Ytg6urK9asWQOZTMbFDBkyBHfu3MHcuXMhl8vRuXNn7N27V+PC4+flQgghhDRXigoVtp66gVWpObjx4DEAwNJEiNE92mBU9zawMhXpOcO602uD89NPPz1zv7GxMeLj4xEfH19jjLu7OxISEp45TkhICDIyMp4ZExsbi9jY2BfKhRBCCGlOSssr8MvJ61h9KAf5xZXTmtiZizCulyfe6eYOc7HeL9Wtt+abOSGEEELq5WGZEj+nXcNPR3Jxv6QcAOAkMca7fTwxtGtrmIgEes7wxVGDQwghhLQQD0rKse7YVaw/movissp1G91sTDA5xBuvv9wKYqPm39hUoQaHEEIIMXB3Hiqw5sgV/CftGkr+Webby94Msf28MTjABUaCJndT9QujBocQQggxULeLHuOH1Cv45WQeFBVqAEB7Zwli+3ojoqMT+HzdLKPQFFGDQwghhBiYa/dKsCo1B7+l34BSxQAAnd2sMKWfN/r5OuhsfaimjBocQgghxEBczn+I+ORs/H7mFtSVfQ2CPWzwXmhbdPeybRGNTRVqcAghhJBmLvNmEZYfzMbe8/9bADrExx6xfb3RpY2NHjPTH2pwCCGEkGbq1NX7WJ6cjZSsO9y2AR2cENPXG/6ulnrMTP+owSGEEEKaEcYYjmbfw/Lkyzh+5T4AgM8DXunkgsl9vdHO0ULPGTYN1OAQQgghzUDNK3u7YmIfL7jbmuk3wSaGGhxCCCGkCVOpGRLO3UZ8cjYuyR8CAMRGfAwLao0JvT3hYmWi5wybJmpwCCGEkCZIqVJjR8ZNrEzJwZW7lSt7m4uN8E4392a3src+UINDCCGENCFlShW2nrqOValXcLPwfyt7j+nhgVHd28DSVKjnDJsHanAIIYSQJqBEUYGNJ67hx8O5uPOwamVvMcb38sDwZr6ytz5QtQghhBA9Kiwtx4Zj17DuWC4KS5UAABdLY7zbxwtDurrBWGg4C2A2JmpwCCGEED3QtgCmh50ZJvXxQuRLrSAyMrwFMBsTNTiEEEJII7pZ+BirU3Ow+c/r3AKYvk4WiOnrjYH+zhAY8AKYjYkaHEIIIaQRXLnzCCtTcrA94yYq1P9bADO2rzdC27eMBTAbEzU4hBBCSAO6JC/G8oPZSDh3m1sAU+ppi9h+3i1uAczGRA0OIYQQ0gAy8h4gPjkbBy4WcNtCfR0wua83At2t9ZhZy0ANDiGEEKIjjDGcyL2P5QezcST7LgCAxwMG+jsjJsQbfi4SPWfYclCDQwghhLwgxhhSsgqw/GA2Tl17AAAQ8Hl47aVWmBTiBS97cz1n2PJQg0MIIYTUk1rNcOYeDz+uOoHMW8UAAJGAj7e6uuLd3l5wszHVc4Ytl15vsl+0aBG6du0KCwsLODg4IDIyEllZWRoxISEh4PF4Gl8TJ07UiMnLy8OgQYNgamoKBwcHTJ8+HRUVFRoxKSkpePnllyEWi+Ht7Y3169dXyyc+Ph5t2rSBsbExgoODcfLkSY39ZWVliImJga2tLczNzREVFYX8/HzdFIMQQkizUaFSY+fpm/i/+GNY+7cAmbeKYSIUYFxPDxye2RefRfpTc6Nnem1wUlNTERMTg+PHjyMxMRFKpRLh4eEoKSnRiBs/fjxu377NfS1evJjbp1KpMGjQIJSXl+PYsWPYsGED1q9fj7lz53Ixubm5GDRoEPr27YvTp09j6tSpGDduHPbt28fF/Prrr4iLi8O8efPw119/oVOnTpDJZCgo+N/FYdOmTcMff/yBrVu3IjU1Fbdu3cLrr7/egBUihBDSlJRXqLHlz+sIW5KK9zefxuWCEhgLGCb19sCRmX0x5//84Cgx1neaBHo+RbV3716Nx+vXr4eDgwPS09PRu3dvbrupqSmcnJy0jrF//35cuHABBw4cgKOjIzp37oxPP/0UM2fOxPz58yESibBq1Sp4eHjgm2++AQC0b98eR44cwdKlSyGTyQAAS5Yswfjx4zF69GgAwKpVq7B7926sXbsWs2bNQlFREX766Sds2rQJ/fr1AwCsW7cO7du3x/Hjx9GtWzed14cQQkjTUKZUYcup61iVkoNbRWUAAGtTIaKl7nAsvoQ3+reFUEiLYDYlTWoe6KKiIgCAjY2NxvaNGzfCzs4OHTt2xOzZs1FaWsrtS0tLg7+/PxwdHbltMpkMxcXFOH/+PBcTFhamMaZMJkNaWhoAoLy8HOnp6RoxfD4fYWFhXEx6ejqUSqVGjK+vL1q3bs3FEEIIMSwligqsPpSDnl8mY+7O87hVVAZ7CzE+HtgeR2b2Q0yIJ0zpatYmqcl8W9RqNaZOnYoePXqgY8eO3Pa3334b7u7ucHFxwdmzZzFz5kxkZWVh27ZtAAC5XK7R3ADgHsvl8mfGFBcX4/Hjx3jw4AFUKpXWmEuXLnFjiEQiWFlZVYupep2nKRQKKBQK7nFxceUFaEqlEkqlslZ1qY2qsXQ5piGgumhHdakZ1Ua7lliX4sdK/Hw8DxvS8lD4+H8LYE7o1QZvvNwKYqEAAGuRtamNhqhLXcdqMg1OTEwMMjMzceTIEY3tEyZM4P7t7+8PZ2dnhIaGIicnB15eXo2dZp0sWrQICxYsqLZ9//79MDXV/cVniYmJOh/TEFBdtKO61Ixqo11LqMsjJZB8m48jch7KVJUzDNsZM/RvpUYXu0cwupeJpMTMas9rCbWpD13W5cmzN7XRJBqc2NhY7Nq1C4cOHYKrq+szY4ODgwEA2dnZ8PLygpOTU7W7narubKq6bsfJyana3U75+fmQSCQwMTGBQCCAQCDQGvPkGOXl5SgsLNQ4ivNkzNNmz56NuLg47nFxcTHc3NwQHh4OiUR3kz0plUokJiaif//+dA74CVQX7aguNaPaaNcS6nK7qAw/Hb2KX8/cQJmycgHMtg5mmNTHExEdHGEk0H5FR0uoTX00RF2qzoLUll4bHMYYpkyZgu3btyMlJQUeHh7Pfc7p06cBAM7OzgAAqVSKzz//HAUFBXBwcABQ2TFKJBL4+flxMQkJCRrjJCYmQiqVAgBEIhECAwORlJSEyMhIAJWnzJKSkhAbGwsACAwMhFAoRFJSEqKiogAAWVlZyMvL48Z5mlgshlgsrrZdKBQ2yA9CQ43b3FFdtKO61Ixqo50h1uXavRKsSs3Bb+k3oFRVLhTl38oSMX29Ee7nCH4tV/Y2xNrogi7rUtdx9NrgxMTEYNOmTdi5cycsLCy4a1ksLS1hYmKCnJwcbNq0CQMHDoStrS3Onj2LadOmoXfv3ggICAAAhIeHw8/PDyNGjMDixYshl8sxZ84cxMTEcM3FxIkTsXz5csyYMQNjxozBwYMHsWXLFuzevZvLJS4uDtHR0ejSpQuCgoLw7bffoqSkhLurytLSEmPHjkVcXBxsbGwgkUgwZcoUSKVSuoOKEEKamcv5D7EiJQc7T9/kFsAM8rBBbF9v9GprRwtgGgC9NjgrV64EUDmZ35PWrVuHUaNGQSQS4cCBA1yz4ebmhqioKMyZM4eLFQgE2LVrFyZNmgSpVAozMzNER0dj4cKFXIyHhwd2796NadOmYdmyZXB1dcWaNWu4W8QBYMiQIbhz5w7mzp0LuVyOzp07Y+/evRoXHi9duhR8Ph9RUVFQKBSQyWRYsWJFA1WHEEKIrmXeLEJ8cjb2npeD/dPY9Glnj9h+3ujaxubZTybNit5PUT2Lm5sbUlNTnzuOu7t7tVNQTwsJCUFGRsYzY2JjY7lTUtoYGxsjPj4e8fHxz82JEEJI05F+7T6+P5iNlKw73DZZB0fE9m0Lf1dLPWZGGkqTuMiYEEII0TXGGI7l3MP3By/j+JX7AAA+D3ilkwsm9/VGO0cLPWdIGhI1OIQQQgwKYwwHLxXg+4PZOH29EAAgFPAQ9bIrJvbxQhs7M/0mSBoFNTiEEEIMgkrNsCfzNuKTc3DxduUtxWIjPoYFtcaE3p5wsTLRc4akMVGDQwghpFlTqtTYefoWVqRk48qdysWazUQCvCN1x7ienrC3qD5dBzF81OAQQghplsqUKvyWfgOrUnNw48FjAICliRCjurfB6B5tYGUq0nOGRJ+owSGEENKslCgqsOlEHn48fAUFDyvX+7MzF2FcL08MD24NC2OacI9Qg0MIIaSZKCpVYv2xq1h3LBeFpU8sgNnbE0ODWsNYKNBzhqQpoQaHEEJIk3bnoQI/HcnFf45fwyNFBQDAw84Mk/p4IfKlVhAZaV8nirRs1OAQQghpkm4WPsbq1Bxs/vM6FBWVC2D6Ollgcl9vDPJ3hqCW60SRlokaHEIIIU3KlTuPsCo1B9v+uomKfxaK6uRmhdi+3gj1daj1ApikZaMGhxBCSJNwSV6M+OQc7D57i1sAU+ppi9h+3ujuZUsLYJI6oQaHEEKIXp25XojlydlIvJDPbevn64CYvt4IdLfWY2akOaMGhxBCSKNjjOFE7n3EJ2fj8OW7AAAeDxjY0RmT+3qhgwstgEleDDU4hBBCGg1jDClZd7A8ORvp1x4AAAR8Hl7t7ILJId7wdjDXc4bEUFCDQwghpMGp1Ax7M+WIT87GhX/WiRIZ8fFWF1e829sLbjames6QGBpqcAghhDQYpUqNHRk3sTI1h1snylQkwDvd3DGupwccJMZ6zpAYKmpwCCGE6FyZUoUtp67jh9QruFmouU7UqO5tYG1G60SRhkUNDiGEEJ15pKjAxuPX8OPhXNx9VLVOlBjjenngnW7uMBfTnx3SOOiTRggh5IUVlpZj3dGrWH/sKooeV64T1crKBO/28cRbXdxonSjS6KjBIYQQUm8FD8vw0+HKdaJKylUAAE87M0wKqVwnSiigdaKIflCDQwghpM5uFj7GD6k5+PWpdaJi+3kjoiOtE0X0jxocQgghtXblziOsTMnB9oz/rRP1UuvKdaL6+TrQcgqkyaAGhxBCyHPdLAGm/noWe87LuXWiunvZIravN6S0ThRpgqjBIYQQUqOMvAf4PukyDmYZAZADAEJ9HRDTzxsvt6Z1okjTpdervxYtWoSuXbvCwsICDg4OiIyMRFZWlkZMWVkZYmJiYGtrC3Nzc0RFRSE/P18jJi8vD4MGDYKpqSkcHBwwffp0VFRUaMSkpKTg5Zdfhlgshre3N9avX18tn/j4eLRp0wbGxsYIDg7GyZMn65wLIYQ0d4wxpOXcwztrTuC1FcdwMOsOeGAY2NERCe/1wk+julJzQ5o8vTY4qampiImJwfHjx5GYmAilUonw8HCUlJRwMdOmTcMff/yBrVu3IjU1Fbdu3cLrr7/O7VepVBg0aBDKy8tx7NgxbNiwAevXr8fcuXO5mNzcXAwaNAh9+/bF6dOnMXXqVIwbNw779u3jYn799VfExcVh3rx5+Ouvv9CpUyfIZDIUFBTUOhdCCGnOGGNIvlSAN1alYdiPx3Ek+y6M+Dy8/pILZndWYdmQTvBzkeg7TUJqhzUhBQUFDABLTU1ljDFWWFjIhEIh27p1Kxdz8eJFBoClpaUxxhhLSEhgfD6fyeVyLmblypVMIpEwhULBGGNsxowZrEOHDhqvNWTIECaTybjHQUFBLCYmhnusUqmYi4sLW7RoUa1zeZ6ioiIGgBUVFdUqvrbKy8vZjh07WHl5uU7Hbe6oLtpRXWrWUmtToVKzXWdusYhvDzH3mbuY+8xdrO3HCezj7WdZ3r2SFluX2qDaaNcQdanr39AmdQ1OUVERAMDGxgYAkJ6eDqVSibCwMC7G19cXrVu3RlpaGrp164a0tDT4+/vD0dGRi5HJZJg0aRLOnz+Pl156CWlpaRpjVMVMnToVAFBeXo709HTMnj2b28/n8xEWFoa0tLRa5/I0hUIBhULBPS4urlxgTqlUQqlU1qtG2lSNpcsxDQHVRTuqS81aWm2UKjV+P3Mbqw/n4srdUgCV60QN6+qKMT3awMFCXBnXwupSF1Qb7RqiLnUd64UanKSkJCQlJaGgoABqtVpj39q1a+s0llqtxtSpU9GjRw907NgRACCXyyESiWBlZaUR6+joCLlczsU82dxU7a/a96yY4uJiPH78GA8ePIBKpdIac+nSpVrn8rRFixZhwYIF1bbv378fpqa6Xzk3MTFR52MaAqqLdlSXmhl6bcpVwIk7PCTd5ONBeeXdTyYChj7ODL2dKmCmzsGpwznVnmfodXkRVBvtdFmX0tLSOsXXu8FZsGABFi5ciC5dusDZ2fmFbxGMiYlBZmYmjhw58kLjNCWzZ89GXFwc97i4uBhubm4IDw+HRKK789hKpRKJiYno378/hEKhzsZt7qgu2lFdambotXmkqMCmk9ex7tg13H1UDgCwMxdhTA93DOvqVuM6UYZelxdBtdGuIepSdRakturd4KxatQrr16/HiBEj6jsEJzY2Frt27cKhQ4fg6urKbXdyckJ5eTkKCws1jpzk5+fDycmJi3n6bqeqO5uejHn6bqf8/HxIJBKYmJhAIBBAIBBojXlyjOfl8jSxWAyxWFxtu1AobJAfhIYat7mjumhHdamZodXmQUk51h27ig1PrRM1sY8n3qzDOlGGVhddotpop8u61HWcet9FVV5eju7du9f36QAqr9iPjY3F9u3bcfDgQXh4eGjsDwwMhFAoRFJSErctKysLeXl5kEqlAACpVIpz585p3O2UmJgIiUQCPz8/LubJMapiqsYQiUQIDAzUiFGr1UhKSuJiapMLIYQ0JQXFZfhXwkX0+PIgvku6jKLHSnjam+HrNzshZXoIRkjb0CKYxGDV+wjOuHHjsGnTJnzyySf1fvGYmBhs2rQJO3fuhIWFBXcti6WlJUxMTGBpaYmxY8ciLi4ONjY2kEgkmDJlCqRSKXdRb3h4OPz8/DBixAgsXrwYcrkcc+bMQUxMDHf0ZOLEiVi+fDlmzJiBMWPG4ODBg9iyZQt2797N5RIXF4fo6Gh06dIFQUFB+Pbbb1FSUoLRo0dzOT0vF0IIaQqu3y/FD4dysOXUDZT/s06Un7MEMX29MaCjE60TRVqEejc4ZWVlWL16NQ4cOICAgIBqh46WLFny3DFWrlwJAAgJCdHYvm7dOowaNQoAsHTpUvD5fERFRUGhUEAmk2HFihVcrEAgwK5duzBp0iRIpVKYmZkhOjoaCxcu5GI8PDywe/duTJs2DcuWLYOrqyvWrFkDmUzGxQwZMgR37tzB3LlzIZfL0blzZ+zdu1fjwuPn5UIIIfqUXfAQK1JysPP0Laj+WU8h0N0asX29EeJjT8spkBal3g3O2bNn0blzZwBAZmamxr7a/hAxxp4bY2xsjPj4eMTHx9cY4+7ujoSEhGeOExISgoyMjGfGxMbGIjY29oVyIYSQxpZ5swjxydnYe16Oql+rvdraIaavN4I9bKixIS1SvRuc5ORkXeZBCCGkjk5dvY/lydlIybrDbQv3c0RMX290crPSX2KENAE6mejvxo0bAKBxBxQhhBDdY4zhSPZdLD+YjRO59wEAfB4wuJMLJod4w8fJQs8ZEtI01LvBUavV+Oyzz/DNN9/g0aNHAAALCwt88MEH+Pjjj8Hn63WZK0IIMShqNUPixXysSM7GmRuVs74LBTxEveyKiX280MbOTM8ZEtK01LrBWbt2LYKCgrhZhj/++GP89NNP+OKLL9CjRw8AwJEjRzB//nyUlZXh888/b5iMCSGkBalQqbH73G2sSM5BVv5DAICxkI9hQa0xobcnnC1N9JwhIU1TrRscd3d3REREYMOGDejXrx82bNiANWvW4JVXXuFiAgIC0KpVK0yePJkaHEIIeQGKChW2/3UTK1NzcO1e5RT1FmIjjJC6Y0xPD9iZV59ElBDyP7VucEJDQ5GUlIR33nkHJ0+exP379+Hr61stztfXF/fv39dpkoQQ0lKUllfgl5PX8eOhK5AXlwEArE2FGNPDAyO7t4GlCc2WS0ht1OkanHbt2uHQoUMAgE6dOmH58uX47rvvNGKWL1+OTp066S5DQghpAYoeK/HzsatYezQXD0orl1NwlIgxvpcn3g5uDVORTu4JIaTFqPNPjLGxMQBg8eLFGDRoEA4cOMAtVZCWlobr168/d04aQgghle4+UuCnI7n4d9o1PFJUAADcbU0xqY8XXnu5FcRGtJQCIfVR7/8S9OnTB3///Tfi4+Nx6dIlAMDrr7+OyZMnw8XFRWcJEkKIIbpV+BirD13BLyfzoPhnOQUfRwtM7uuFQf7OMBLQnaiEvIgXOubp4uJCFxMTQkgdXL1bgpUpOdiWcQNKVeW0w53crBDb1xuhvg7g0zpRhOhEnRqcs2fPomPHjuDz+Th79uwzYwMCAl4oMUIIMSSX5MWIT87B7rO38M8yUZB62iK2nze6e9nScgqE6FidGpzOnTtDLpfDwcEBnTt3Bo/H07qeFI/Hg0ql0lmShBDSXGXkPUB8cg4OXMzntvXzdUBMX28EulvrMTNCDFudGpzc3FzY29tz/yaEEFIdYwxpOfcQn5KNo9n3AAA8HjDQ3xmTQ7zQwcVSzxkSYvjq1OC4u7tr/TchhJDKxubgpQLEJ2fjr7xCAIARn4fIl1phUogXvOzN9ZsgIS1IvS8yXrRoERwdHTFmzBiN7WvXrsWdO3cwc+bMF06OEEKaA5WaIeHcbcQnZ+OSvHI5BZERH0O7umFCb0+4WpvqOUNCWp56Nzg//PADNm3aVG17hw4dMHToUGpwCCEGT6lSY3vGTaxKycGVuyUAADORAO9I3TG2pwccLIz1nCEhLVe9Gxy5XA5nZ+dq2+3t7XH79u0XSooQQpqyMqUKv/55HasPXcHNwscAAEsTIUb3aINR3dvAylSk5wwJIfVucNzc3HD06FF4eHhobD969ChN9EcIMUgPy5TYeCIPaw7n4u4jBQDA3kKM8b088HawO8zFtJwCIU1FvX8ax48fj6lTp0KpVKJfv34AgKSkJMyYMQMffPCBzhIkhBB9e1BSjnXHrmL90VwUl1Uup9DKygQT+3jizS5uMBbScgqENDX1bnCmT5+Oe/fuYfLkySgvLwdQuU7VzJkzMXv2bJ0lSAgh+iIvKsOaw1ew6WQeSssr5/bytDPDpBAvRL7UCkJaToGQJqteDY5KpcLRo0cxa9YsfPLJJ7h48SJMTEzQtm1biMViXedICCGNKu9+KdYczcN/02+gXFW5TpSfswST+3ohoqMzBLScAiFNXr0aHIFAgPDwcFy8eBEeHh7o2rWrrvMihJBGdzn/EX6+zEfG8SPccgpd21hjcl9vhLSzp+UUCGlG6n2KqmPHjrhy5Uq1i4wJIaS5OXejCMuTL2Pf+XwAlaederezR0yIF4I9bfWbHCGkXup9Avmzzz7Dhx9+iF27duH27dsoLi7W+KqtQ4cOYfDgwXBxcQGPx8OOHTs09o8aNQo8Hk/ja8CAARox9+/fx/DhwyGRSGBlZYWxY8fi0aNHGjFnz55Fr169YGxsDDc3NyxevLhaLlu3boWvry+MjY3h7++PhIQEjf2MMcydOxfOzs4wMTFBWFgYLl++XOv3SghpWk5cuYeRa09i8PIj/zQ3QICNGtsmBuPnMUHU3BDSjNW7wRk4cCDOnDmDV155Ba6urrC2toa1tTWsrKxgbV37BeRKSkrQqVMnxMfH1xgzYMAA3L59m/v65ZdfNPYPHz4c58+fR2JiInbt2oVDhw5hwoQJ3P7i4mKEh4fD3d0d6enp+OqrrzB//nysXr2aizl27BiGDRuGsWPHIiMjA5GRkYiMjERmZiYXs3jxYnz33XdYtWoVTpw4ATMzM8hkMpSVldX6/RJC9IsxhpSsAry56hiGrD6OQ3/fgYDPw2svtULClO4Y66OGfytaK4qQ5q7ep6iSk5N1kkBERAQiIiKeGSMWi+Hk5KR138WLF7F37178+eef6NKlCwDg+++/x8CBA/H111/DxcUFGzduRHl5OdauXQuRSIQOHTrg9OnTWLJkCdcILVu2DAMGDMD06dMBAJ9++ikSExOxfPlyrFq1CowxfPvtt5gzZw5effVVAMDPP/8MR0dH7NixA0OHDtVJPQghDUOtZth/QY745Bycu1kEABAJ+Hijiysm9vZCa1tTKJVK0DFZQgxDvRucPn366DKPZ0pJSYGDgwOsra3Rr18/fPbZZ7C1rTx0nJaWBisrK665AYCwsDDw+XycOHECr732GtLS0tC7d2+IRP+bXVQmk+HLL7/EgwcPYG1tjbS0NMTFxWm8rkwm406Z5ebmQi6XIywsjNtvaWmJ4OBgpKWlUYNDSBOlVKnxx5lbWJGSg+yCylPXJkIB3g5ujfG9POFkScspEGKIXmjazcLCQvz000+4ePEigMp1qMaMGQNLS90d3h0wYABef/11eHh4ICcnBx999BEiIiKQlpYGgUAAuVwOBwcHjecYGRnBxsYGcrkcQOWyEk9fDO3o6Mjts7a2hlwu57Y9GfPkGE8+T1vM0xQKBRQKBfe46tokpVIJpVJZpzo8S9VYuhzTEFBdtGspdVEoVfgt4xbWHM7FjcLK08gWxkZ4J9gNo6TusDGr/A/Pk3VoKbWpK6pLzag22jVEXeo6Vr0bnFOnTkEmk8HExARBQUEAgCVLluDzzz/H/v378fLLL9d3aA1PHhnx9/dHQEAAvLy8kJKSgtDQUJ28RkNZtGgRFixYUG37/v37YWqq+9WFExMTdT6mIaC6aGeodSlTAUflPKTc5qNYWXlbt7kRQ4iLGj0dK2BSfhnHU599IspQa/OiqC41o9pop8u6lJaW1im+3g3OtGnT8Morr+DHH3+EkVHlMBUVFRg3bhymTp2KQ4cO1XfoZ/L09ISdnR2ys7MRGhoKJycnFBQUaMRUVFTg/v373HU7Tk5OyM/P14ipevy8mCf3V217cpHR/Px8dO7cWWuus2fP1jjtVVxcDDc3N4SHh0MikdT1rddIqVQiMTER/fv3h1Ao1Nm4zR3VRTtDrcuD0nL8+3gefj6eh6LHlcspOFsaY1zPNnjz5VYwET1/OQVDrc2LorrUjGqjXUPUpS53aAMveATnyeYGqDw1NGPGDI3rYXTtxo0buHfvHtdkSKVSFBYWIj09HYGBgQCAgwcPQq1WIzg4mIv5+OOPoVQquUInJibCx8eHu+NLKpUiKSkJU6dO5V4rMTERUqkUAODh4QEnJyckJSVxDU1xcTFOnDiBSZMmac1VLBZrndlZKBQ2yA9CQ43b3FFdtDOUuhQUl2HNkVz85/g1jeUUJoZ4IbJzK4iM6n6zqKHURteoLjWj2miny7rUdZx6NzgSiQR5eXnw9fXV2H79+nVYWFjUepxHjx4hOzube5ybm4vTp0/DxsYGNjY2WLBgAaKiouDk5IScnBzMmDED3t7ekMlkAID27dtjwIABGD9+PFatWgWlUonY2FgMHTqUW9X87bffxoIFCzB27FjMnDkTmZmZWLZsGZYuXcq97vvvv48+ffrgm2++waBBg7B582acOnWKu5Wcx+Nh6tSp+Oyzz9C2bVt4eHjgk08+gYuLCyIjI+tbRkJIPV2/X4pVqTnYmn4D5RWVyym0d5YghpZTIITgBRqcIUOGYOzYsfj666/RvXt3AMDRo0cxffp0DBs2rNbjnDp1Cn379uUeV53SiY6OxsqVK3H27Fls2LABhYWFcHFxQXh4OD799FONIyMbN25EbGwsQkNDwefzERUVhe+++47bb2lpif379yMmJgaBgYGws7PD3LlzNebK6d69OzZt2oQ5c+bgo48+Qtu2bbFjxw507NiRi5kxYwZKSkowYcIEFBYWomfPnti7dy+MjekuDEIaS3bBQ6xIzsHOM7eg+mc9hUB3a8T29UaIDy2nQAipVO8G5+uvvwaPx8PIkSNRUVF5vlsoFGLSpEn44osvaj1OSEgIGGM17t+3b99zx7CxscGmTZueGRMQEIDDhw8/M+bNN9/Em2++WeN+Ho+HhQsXYuHChc/NiRCiW5k3ixCfnI295+Wo+pVRtZxCkIcNNTaEEA31bnBEIhGWLVuGRYsWIScnBwDg5eXVIHcHEUJarpO59xGfnI3Uv+9w22QdHBHT1xsBrlb6S4wQ0qS90Dw4AGBqagorKyvu34QQ8qIql1O4g/jkbJy69gAAwOcBgzu5YHKIN3ycan+dHyGkZap3g1NRUYEFCxbgu+++4xa2NDc3x5QpUzBv3jy6mpwQUmcqNUPCudtYkZKDi7crbwkVCfh4s4sr3v1nOQVCCKmNejc4U6ZMwbZt27B48WLuVuq0tDTMnz8f9+7dw8qVK3WWJCHEsJVXqLE94wZWpV5B7t0SAICZSIDh3dwxrqcHHCR0IT8hpG7q3eBs2rQJmzdv1lgoMyAgAG5ubhg2bBg1OISQ5ypRVOCXk3lYczgX8uLK5RSsTIUY3d0D0d3dYWUqes4IhBCiXb0bHLFYjDZt2lTb7uHhobGoJSGEPK2wtBwbjl3DumO5KCytXF/GUSLG+F6eGBbUGmbiF748kBDSwtX7t0hsbCw+/fRTrFu3jpuTRqFQ4PPPP0dsbKzOEiSEGI6qWYc3Hr+Gkn9mHXa3NcWkPl547eVWEBs9fzkFQgipjXo3OBkZGUhKSoKrqys6deoEADhz5gzKy8sRGhqK119/nYvdtm3bi2dKCGm28u6VYtWhHPx26gbKVZWzDvs6WWByX28M7OgEI0Hdl1MghJBnqXeDY2VlhaioKI1tbm5uL5wQIcRwZMkfYmVKNn4/cwv/TDpMsw4TQhpFvRucdevW6TIPQogB+SvvAVYk5+DAxXxuG806TAhpTC98Jd+dO3eQlZUFAPDx8YG9vf0LJ0UIaX4YYziWcw/xydk4lnMPAMDjAREdnTA5xBsdW1nqOUNCSEtS7wanpKQEU6ZMwc8//wy1uvKcukAgwMiRI/H999/TrMaEtBBqNUPixXysSM7GmRtFAAAjPg+vvdQK7/bxgreDuZ4zJIS0RPVucOLi4pCamoo//vgDPXr0AAAcOXIE7733Hj744AOaB4cQA6dUqfHHmVtYmZKDywWVs5mLjfgYFtQa43t7opWViZ4zJIS0ZPVucP773//it99+Q0hICLdt4MCBMDExwVtvvUUNDiEGqkypwpZT1/FD6hXcLHwMALAQG2GE1B1jenrAzlys5wwJIeQFGpzS0lI4OjpW2+7g4IDS0tIXSooQ0vQUlynxn+PXsPZILu4+KgcA2JmLMKanB97p5g6JMa0/RwhpOurd4EilUsybNw8///wzjI0r14l5/PgxFixYwK1NRQhp/u4+UmDd0Vz8nHYND8sqAACtrEzwbh9PvNXFDcZCmpyPENL01LvB+fbbbzFgwIBqE/0ZGxtj3759OkuQEKIfNwsf48dDV7D5zzyUKStvJPCyN8PkEG+80tkFQpqcjxDShNW7wfH398fly5exceNGXLp0CQAwbNgwDB8+HCYmdHEhIc1VdsFDrEy5gp2nb6Lin9n5OrlaYlKIN8L9HMHn0xw2hJCmr14NjlKphK+vL3bt2oXx48frOidCiB6cvVGIFck52HdBDvbPrMPdvWwxOcQbPbxtaXI+QkizUq8GRygUoqysTNe5EEIaGWMMaVfuYWVKDg5fvsttD/dzxOS+3ujsZqW/5Agh5AXU+xRVTEwMvvzyS6xZswZGRi88ITIhpBGpGXDgYgFWH7mKjLxCAICAz8OrnVwwMcQL7Rwt9JsgIYS8oHp3Jn/++SeSkpKwf/9++Pv7w8zMTGM/rSBOSNOjVKmxPeMWlpwRQH78NABAZMTHkC5umNDbE242NAM5IcQw6HQ1cUJI0/S4XIVf/8zDj4dz/5mcjwdzsRFGSt0xuocH7C1ocj5CiGGpc4OjVqvx1Vdf4e+//0Z5eTn69euH+fPn051ThDRBRaVK/Jx2FeuOXcX9kv9Nzie1eYwFI/rCxoKO2BBCDFOdJ7L4/PPP8dFHH8Hc3BytWrXCd999h5iYmHoncOjQIQwePBguLi7g8XjYsWOHxn7GGObOnQtnZ2eYmJggLCwMly9f1oi5f/8+hg8fDolEAisrK4wdOxaPHj3SiDl79ix69eoFY2NjuLm5YfHixdVy2bp1K3x9fWFsbAx/f38kJCTUORdCmoL84jL8K+Eiun+RhG8S/8b9knK42Zjgs8iOSI7rhbBWDBY08zAhxIDVucH5+eefsWLFCuzbtw87duzAH3/8gY0bN3IritdVSUkJOnXqhPj4eK37Fy9ejO+++w6rVq3CiRMnYGZmBplMpnEX1/Dhw3H+/HkkJiZi165dOHToECZMmMDtLy4uRnh4ONzd3ZGeno6vvvoK8+fPx+rVq7mYY8eOYdiwYRg7diwyMjIQGRmJyMhIZGZm1ikXQvTp6t0SzN52Fr2+TMbqQ1dQUq6Cr5MFlg3tjOQPQvBON3eaeZgQ0jKwOhKJRCwvL09jm1gsZtevX6/rUNUAYNu3b+ceq9Vq5uTkxL766ituW2FhIROLxeyXX35hjDF24cIFBoD9+eefXMyePXsYj8djN2/eZIwxtmLFCmZtbc0UCgUXM3PmTObj48M9fuutt9igQYM08gkODmbvvvturXN5nqKiIgaAFRUV1Sq+tsrLy9mOHTtYeXm5Tsdt7lpSXTJvFrLJG9OZx6xdzH1m5VfUiqMs6aKcqdVqjdiWVJe6otpoR3WpGdVGu4aoS13/htb5GpyKigpu7akqQqEQSqVSJw3Xk3JzcyGXyxEWFsZts7S0RHBwMNLS0jB06FCkpaXBysoKXbp04WLCwsLA5/Nx4sQJvPbaa0hLS0Pv3r0hEom4GJlMhi+//BIPHjyAtbU10tLSEBcXp/H6MpmMO2VWm1yeplAooFAouMfFxcUAKidK1GW9qsZqiO9Bc2bodWGM4eTVB1h9OBeHLt/jtvdpZ4eJvT3Qxd0aQOXP7JMMvS4vgmqjHdWlZlQb7RqiLnUdq84NDmMMo0aNglj8v7suysrKMHHiRI1bxXVxm7hcLgeAaquWOzo6cvvkcjkcHBw09hsZGcHGxkYjxsPDo9oYVfusra0hl8uf+zrPy+VpixYtwoIFC6pt379/P0xNdX9xZ2Jios7HNASGVhc1Ay484CHxJh9XH1XOLswDw0u2DGGt1GhlJkfBeTkSzj97HEOriy5RbbSjutSMaqOdLutSWlpap/g6NzjR0dHVtr3zzjt1HaZFmD17tsZRoeLiYri5uSE8PBwSiURnr6NUKpGYmIj+/ftDKKQLR6sYWl0qVGrszszH6kO5+Lug8iJ6oYCHqJdbYVzPNnCv5Rw2hlYXXaLaaEd1qRnVRruGqEvVWZDaqnODs27duro+pd6cnJwAAPn5+XB2dua25+fno3PnzlxMQUGBxvMqKipw//597vlOTk7Iz8/XiKl6/LyYJ/c/L5enicVijSNdVYRCYYP8IDTUuM1dc69LmVKFraeu44dDV3DjwWMAgJlIgHe6uWNsTw84SIyfM4J2zb0uDYlqox3VpWZUG+10WZe6jlPnu6gak4eHB5ycnJCUlMRtKy4uxokTJyCVSgEAUqkUhYWFSE9P52IOHjwItVqN4OBgLubQoUMa5+8SExPh4+MDa2trLubJ16mKqXqd2uRCiC4VPVYiPjkbPb88iE92nseNB49hYybCh+HtcGxWKGYPbF/v5oYQQgyd3heRevToEbKzs7nHubm5OH36NGxsbNC6dWtMnToVn332Gdq2bQsPDw988skncHFxQWRkJACgffv2GDBgAMaPH49Vq1ZBqVQiNjYWQ4cOhYuLCwDg7bffxoIFCzB27FjMnDkTmZmZWLZsGZYuXcq97vvvv48+ffrgm2++waBBg7B582acOnWKu5Wcx+M9NxdCdKGguAw/Hc3FxuN5eKSovEC4lZUJJvT2xFtd3GAiotu8CSHkefTe4Jw6dQp9+/blHlddsxIdHY3169djxowZKCkpwYQJE1BYWIiePXti7969Gndybdy4EbGxsQgNDQWfz0dUVBS+++47br+lpSX279+PmJgYBAYGws7ODnPnztWYK6d79+7YtGkT5syZg48++ght27bFjh070LFjRy6mNrkQUl9X75bgh0NX8N/0GyhXVc4r1c7RHJNCvPB/AS4QCpr0AVdCCGlS9N7ghISEgDFW434ej4eFCxdi4cKFNcbY2Nhg06ZNz3ydgIAAHD58+Jkxb775Jt58880XyoWQusq8WYSVqTnYc+421P/8KAS6W2NyiBf6+jiAz+fpN0FCCGmG9N7gENISMcaQduUeVqbk4PDlu9z2fr4OmNjHC0EeNnrMjhBCmj9qcAhpRGo1Q+LFfKxIycGZ64UAAAGfh8EBzni3jxfaO+tu+gBCCGnJqMEhpBGUV6ix8/RNrErNQc6dEgCA2IiPt7q4YUJvT7jVcg4bQgghtUMNDiENqERRgc1/XsdPh6/gVlHloqwWxkYYKXXHqO4esLeoPk8SIYSQF0cNDiEN4H5JOTYcu4oNaVdRWFo5/5K9hRjjenrg7eDWsDCmCcEIIaQhUYNDiA7dLHyMHw9dwa9/XsdjpQoA0MbWFBN6e+H1l1vBWEhz2BBCSGOgBocQHbic/xCrUq9g5+mbqPjnXu+OrSSY1McbAzo6QUC3ehNCSKOiBoeQF3D6eiFWJGdj/4X/rWPWw9sWE/t4oae3HXg8amwIIUQfqMEhpI4YYziSfRcrU3JwLOceAIDHA2R+TpgU4oVOblb6TZAQQgg1OITUlkrNsDdTjh8O5eDsjSIAgBGfh8iXWmFiH094O1joOUNCCCFVqMEh5DkUFSr8N/0mfjiUg2v3SgEAxkI+hnZtjfG9PdHKykTPGRJCCHkaNTiE1OCRogKbTlzDmsO5KHioAABYmQoxUtoG0VJ32JrTHDaEENJUUYNDyFPul5Rj/dFcbEi7hqLHlXPYOEmMMa6XB4YFtYaZmH5sCCGkqaPf1IT843bRY/x4KBe/nMzj5rDxtDPDxD5eiHypFURGfD1nSAghpLaowSEtXu7dEvyQmoNtf91EuUoNoHIOm8kh3pB1oDlsCCGkOaIGh7RYF24VY0VKNhLO3cY/c/MhqI0NYvp5o3dbmsOGEEKaM2pwSItz+nohlh+8jAMXC7ht/XwdMDnEC13a2OgxM0IIIbpCDQ5pMU7m3sf3By/j8OW7ACon5xvk74zJId7wc5HoOTtCCCG6RA0OMWiMAcdy7mFFai5O5N4HAAj4PLz2UitMCvGCl725njMkhBDSEKjBIQaJMYaUv+/g20wBrh5PBwAIBTy8EeiGySFecLMx1XOGhBBCGhI1OMSgqNUM+y/kY3nyZWTeLAbAg9iIj2FBrfFuH084W9Ksw4QQ0hJQg0MMgkrNsPvcbcQfzEZW/kMAgKlIgG62Snw2og9cbOhUFCGEtCTU4JBmTalSY+fpW1iRnI0rd0sAABZiI0R3b4MRwa44nnoA9ha0pAIhhLQ0TX5q1vnz54PH42l8+fr6cvvLysoQExMDW1tbmJubIyoqCvn5+Rpj5OXlYdCgQTA1NYWDgwOmT5+OiooKjZiUlBS8/PLLEIvF8Pb2xvr166vlEh8fjzZt2sDY2BjBwcE4efJkg7xn8nyKChU2nchDv29S8OHWM7hytwRWpkLE9W+HI7P64UOZD2zMRPpOkxBCiJ40iyM4HTp0wIEDB7jHRkb/S3vatGnYvXs3tm7dCktLS8TGxuL111/H0aNHAQAqlQqDBg2Ck5MTjh07htu3b2PkyJEQCoX417/+BQDIzc3FoEGDMHHiRGzcuBFJSUkYN24cnJ2dIZPJAAC//vor4uLisGrVKgQHB+Pbb7+FTCZDVlYWHBwcGrEaLVuZUoXNJ/Pww6EruF1UBgCwMxdhXC9PvNPNHea0ThQhhBA0kwbHyMgITk5O1bYXFRXhp59+wqZNm9CvXz8AwLp169C+fXscP34c3bp1w/79+3HhwgUcOHAAjo6O6Ny5Mz799FPMnDkT8+fPh0gkwqpVq+Dh4YFvvvkGANC+fXscOXIES5cu5RqcJUuWYPz48Rg9ejQAYNWqVdi9ezfWrl2LWbNmNVIlWq4SRQU2nriG1YdycfdR5crejhIx3u3thWFBrWEiEug5Q0IIIU1Jkz9FBQCXL1+Gi4sLPD09MXz4cOTl5QEA0tPToVQqERYWxsX6+vqidevWSEtLAwCkpaXB398fjo6OXIxMJkNxcTHOnz/PxTw5RlVM1Rjl5eVIT0/XiOHz+QgLC+NiSMMoLlMiPjkbPb88iH8lXMLdRwq0sjLBZ5EdkTq9L8b09KDmhhBCSDVN/ghOcHAw1q9fDx8fH9y+fRsLFixAr169kJmZCblcDpFIBCsrK43nODo6Qi6XAwDkcrlGc1O1v2rfs2KKi4vx+PFjPHjwACqVSmvMpUuXasxdoVBAoVBwj4uLiwEASqUSSqWyDlV4tqqxdDmmvhWWKrEh7Rp+Pp6H4rLK66XcbUwxsY8HXu3kDKGAD0ANpVJd4xiGWBddoLrUjGqjHdWlZlQb7RqiLnUdq8k3OBEREdy/AwICEBwcDHd3d2zZsgUmJk17TpNFixZhwYIF1bbv378fpqa6n2guMTFR52M2todKIPkWH0fkPCjUlYtdOpkw9G+lxkt2xRDIzyBRfqZOYxpCXRoC1aVmVBvtqC41o9pop8u6lJaW1im+yTc4T7OyskK7du2QnZ2N/v37o7y8HIWFhRpHcfLz87lrdpycnKrd7VR1l9WTMU/feZWfnw+JRAITExMIBAIIBAKtMdquDaoye/ZsxMXFcY+Li4vh5uaG8PBwSCS6W/tIqVQiMTER/fv3h1Ao1Nm4jUleXIafjlzF5jM3UPbPURlfJwtM7uMBmZ8j+Py6r+xtCHVpCFSXmlFttKO61Ixqo11D1KXqLEhtNbsG59GjR8jJycGIESMQGBgIoVCIpKQkREVFAQCysrKQl5cHqVQKAJBKpfj8889RUFDA3e2UmJgIiUQCPz8/LiYhIUHjdRITE7kxRCIRAgMDkZSUhMjISACAWq1GUlISYmNja8xVLBZDLK4+B4tQKGyQH4SGGrch3XhQilWpOdjy5w2Uqyobm06ulpjSry1C2zuAx6t7Y/O05liXxkB1qRnVRjuqS82oNtrpsi51HafJNzgffvghBg8eDHd3d9y6dQvz5s2DQCDAsGHDYGlpibFjxyIuLg42NjaQSCSYMmUKpFIpunXrBgAIDw+Hn58fRowYgcWLF0Mul2POnDmIiYnhmo+JEydi+fLlmDFjBsaMGYODBw9iy5Yt2L17N5dHXFwcoqOj0aVLFwQFBeHbb79FSUkJd1cVqZurd0uwIiUb2/66iQo1AwB0bWONKf3aoldbO500NoQQQlquJt/g3LhxA8OGDcO9e/dgb2+Pnj174vjx47C3twcALF26FHw+H1FRUVAoFJDJZFixYgX3fIFAgF27dmHSpEmQSqUwMzNDdHQ0Fi5cyMV4eHhg9+7dmDZtGpYtWwZXV1esWbOGu0UcAIYMGYI7d+5g7ty5kMvl6Ny5M/bu3VvtwmPybNkFD7H8YDZ+P3ML//Q16Olth9h+3ujmaavf5AghhBiMJt/gbN68+Zn7jY2NER8fj/j4+Bpj3N3dq52CelpISAgyMjKeGRMbG/vMU1KkZtfvl2Lpgb+xPeMm2D+NTT9fB8T09Uagu7V+kyOEEGJwmnyDQ5q3u48UWH4wGxtPXINSVdnZ9PdzxHv92sLf1VLP2RFCCDFU1OCQBvFIUYEfD13BmsNXUFKuAgB097LFzAG+6ORmpd/kCCGEGDxqcIhOKSpU2Hg8D8uTs3G/pBwA4N/KEjMH+KJnWzs9Z0cIIaSloAaH6IRKzbAj4yaWJP6Nm4WPAQAedmb4MNwHER2d6jWPDSGEEFJf1OCQF8IYw8FLBVi8NwtZ+Q8BAA4WYkwNa4c3u7j+s6QCIYQQ0riowSH19ufV+/hyzyWcuvYAACAxNsKkEG+M6t6GFsAkhBCiV9TgkDq7JC/GV3uzkHSpAAAgNuJjdA8PTOrjBUtTmsmTEEKI/lGDQ2rt+v1SLE38G9tPV85lI+Dz8FYXN7wf2hZOlsb6To8QQgjhUINDnkvbXDaD/J3xQXg7eNqb6zk7QgghpDpqcEiNtM1l06utHabLfBDgaqXf5AghhJBnoAaHVKNUqbHpRB6+S7qMe//MZRPgWjmXTQ9vmsuGEEJI00cNDtFw6up9zNmRiUvyylu+Pe3M8KGsci4bWuGbEEJIc0ENDgEA3C8px5d7LuHXU9cBAFamQnwQ7oOhXd1oLhtCCCHNDjU4LZxazbA1/Tq+2HMJD0qVAIC3urhiVkR72JiJ9JwdIYQQUj/U4LRgl/MfYta2c0j/Z6I+XycLfBbZEV3a2Og5M0IIIeTFUIPTAqnUDGsOX8E3+/9GuUoNM5EA0/q3Q3T3NnQ6ihBCiEGgBqeFybnzCB9uPYOMvEIAQF8fe3z+mj9crEz0mxghhBCiQ9TgtBAqNcPaI7n4en8WFBVqWIiN8Mn/+eHNLq50dxQhhBCDQw1OC3Cr8DHe+yWDWxSzV1s7fBkVQEdtCCGEGCxqcAxc0sV8fLD1DApLlTAXG+HjQe0xtKsbHbUhhBBi0KjBMVAqNcPSxL+xPDkbAODfyhLL334J7rZmes6MEEIIaXjU4BigMqUKMRv/QtKlAgDAqO5tMHugL8RGAj1nRgghhDQOanAMTJlShQn/Tsehv+9AbMTHl1EBiHyplb7TIoQQQhoVNTgG5tNdF3Do7zswEQqwfnRXBHva6jslQgghpNHRrG71EB8fjzZt2sDY2BjBwcE4efKkvlMCAKw7dg0bT+QBAFa+8zI1N4QQQlosanDq6Ndff0VcXBzmzZuHv/76C506dYJMJkNBQYFe8zoi5+Ffe7IAAB/0b4cQHwe95kMIIYToEzU4dbRkyRKMHz8eo0ePhp+fH1atWgVTU1OsXbtWbzntPH0LW3MrLyCe2McLsf289ZYLIYQQ0hTQNTh1UF5ejvT0dMyePZvbxufzERYWhrS0tGrxCoUCCoWCe1xcXAwAUCqVUCqVOsnpz6sPMGv7eQDAO0GuiAv1REVFhU7Gbu6qaqyrWhsKqkvNqDbaUV1qRrXRriHqUtexqMGpg7t370KlUsHR0VFju6OjIy5dulQtftGiRViwYEG17fv374epqalOcvpPNh8Vaj4626oRyL+KPXuu6mRcQ5KYmKjvFJokqkvNqDbaUV1qRrXRTpd1KS0trVM8NTgNaPbs2YiLi+MeFxcXw83NDeHh4ZBIJDp5DZmaYf3RXNgWXoIsvD+EQqFOxjUESqUSiYmJ6N+f6vIkqkvNqDbaUV1qRrXRriHqUnUWpLaowakDOzs7CAQC5Ofna2zPz8+Hk5NTtXixWAyxWFxtu1Ao1Nk3XAhgbC9PJCRc0um4hoTqoh3VpWZUG+2oLjWj2min0793dRyHLjKuA5FIhMDAQCQlJXHb1Go1kpKSIJVK9ZgZIYQQQp5ER3DqKC4uDtHR0ejSpQuCgoLw7bffoqSkBKNHj9Z3aoQQQgj5BzU4dTRkyBDcuXMHc+fOhVwuR+fOnbF3795qFx4TQgghRH+owamH2NhYxMbG6jsNQgghhNSArsEhhBBCiMGhBocQQgghBocaHEIIIYQYHLoGpxExxgDUfbKi51EqlSgtLUVxcTHNw/AEqot2VJeaUW20o7rUjGqjXUPUpepvZ9Xf0uehBqcRPXz4EADg5uam50wIIYSQ5unhw4ewtLR8bhyP1bYVIi9MrVbj1q1bsLCwAI/H09m4VUtAXL9+XWdLQBgCqot2VJeaUW20o7rUjGqjXUPUhTGGhw8fwsXFBXz+86+woSM4jYjP58PV1bXBxpdIJPQDpgXVRTuqS82oNtpRXWpGtdFO13WpzZGbKnSRMSGEEEIMDjU4hBBCCDE41OAYALFYjHnz5mldubwlo7poR3WpGdVGO6pLzag22jWFutBFxoQQQggxOHQEhxBCCCEGhxocQgghhBgcanAIIYQQYnCowSGEEEKIwaEGp5mLj49HmzZtYGxsjODgYJw8eVLfKenU/PnzwePxNL58fX25/WVlZYiJiYGtrS3Mzc0RFRWF/Px8jTHy8vIwaNAgmJqawsHBAdOnT0dFRYVGTEpKCl5++WWIxWJ4e3tj/fr1jfH2au3QoUMYPHgwXFxcwOPxsGPHDo39jDHMnTsXzs7OMDExQVhYGC5fvqwRc//+fQwfPhwSiQRWVlYYO3YsHj16pBFz9uxZ9OrVC8bGxnBzc8PixYur5bJ161b4+vrC2NgY/v7+SEhI0Pn7rYvn1WbUqFHVPkMDBgzQiDG02ixatAhdu3aFhYUFHBwcEBkZiaysLI2YxvzZaUq/p2pTm5CQkGqfmYkTJ2rEGFptVq5ciYCAAG5iPqlUij179nD7m+XnhZFma/PmzUwkErG1a9ey8+fPs/HjxzMrKyuWn5+v79R0Zt68eaxDhw7s9u3b3NedO3e4/RMnTmRubm4sKSmJnTp1inXr1o11796d219RUcE6duzIwsLCWEZGBktISGB2dnZs9uzZXMyVK1eYqakpi4uLYxcuXGDff/89EwgEbO/evY36Xp8lISGBffzxx2zbtm0MANu+fbvG/i+++IJZWlqyHTt2sDNnzrBXXnmFeXh4sMePH3MxAwYMYJ06dWLHjx9nhw8fZt7e3mzYsGHc/qKiIubo6MiGDx/OMjMz2S+//MJMTEzYDz/8wMUcPXqUCQQCtnjxYnbhwgU2Z84cJhQK2blz5xq8BjV5Xm2io6PZgAEDND5D9+/f14gxtNrIZDK2bt06lpmZyU6fPs0GDhzIWrduzR49esTFNNbPTlP7PVWb2vTp04eNHz9e4zNTVFTE7TfE2vz+++9s9+7d7O+//2ZZWVnso48+YkKhkGVmZjLGmufnhRqcZiwoKIjFxMRwj1UqFXNxcWGLFi3SY1a6NW/ePNapUyet+woLC5lQKGRbt27ltl28eJEBYGlpaYyxyj9+fD6fyeVyLmblypVMIpEwhULBGGNsxowZrEOHDhpjDxkyhMlkMh2/G914+o+4Wq1mTk5O7KuvvuK2FRYWMrFYzH755RfGGGMXLlxgANiff/7JxezZs4fxeDx28+ZNxhhjK1asYNbW1lxdGGNs5syZzMfHh3v81ltvsUGDBmnkExwczN59912dvsf6qqnBefXVV2t8TkuoTUFBAQPAUlNTGWON+7PT1H9PPV0bxiobnPfff7/G57SU2lhbW7M1a9Y0288LnaJqpsrLy5Geno6wsDBuG5/PR1hYGNLS0vSYme5dvnwZLi4u8PT0xPDhw5GXlwcASE9Ph1Kp1KiBr68vWrduzdUgLS0N/v7+cHR05GJkMhmKi4tx/vx5LubJMapimksdc3NzIZfLNd6DpaUlgoODNepgZWWFLl26cDFhYWHg8/k4ceIEF9O7d2+IRCIuRiaTISsrCw8ePOBimmOtUlJS4ODgAB8fH0yaNAn37t3j9rWE2hQVFQEAbGxsADTez05z+D31dG2qbNy4EXZ2dujYsSNmz56N0tJSbp+h10alUmHz5s0oKSmBVCpttp8XWmyzmbp79y5UKpXGhwkAHB0dcenSJT1lpXvBwcFYv349fHx8cPv2bSxYsAC9evVCZmYm5HI5RCIRrKysNJ7j6OgIuVwOAJDL5VprVLXvWTHFxcV4/PgxTExMGujd6UbV+9D2Hp58jw4ODhr7jYyMYGNjoxHj4eFRbYyqfdbW1jXWqmqMpmjAgAF4/fXX4eHhgZycHHz00UeIiIhAWloaBAKBwddGrVZj6tSp6NGjBzp27AgAjfaz8+DBgyb9e0pbbQDg7bffhru7O1xcXHD27FnMnDkTWVlZ2LZtGwDDrc25c+cglUpRVlYGc3NzbN++HX5+fjh9+nSz/LxQg0OatIiICO7fAQEBCA4Ohru7O7Zs2dLkGw/SNAwdOpT7t7+/PwICAuDl5YWUlBSEhobqMbPGERMTg8zMTBw5ckTfqTQ5NdVmwoQJ3L/9/f3h7OyM0NBQ5OTkwMvLq7HTbDQ+Pj44ffo0ioqK8NtvvyE6Ohqpqan6Tqve6BRVM2VnZweBQFDtKvb8/Hw4OTnpKauGZ2VlhXbt2iE7OxtOTk4oLy9HYWGhRsyTNXByctJao6p9z4qRSCTNoomqeh/P+iw4OTmhoKBAY39FRQXu37+vk1o1p8+cp6cn7OzskJ2dDcCwaxMbG4tdu3YhOTkZrq6u3PbG+tlpyr+naqqNNsHBwQCg8ZkxxNqIRCJ4e3sjMDAQixYtQqdOnbBs2bJm+3mhBqeZEolECAwMRFJSErdNrVYjKSkJUqlUj5k1rEePHiEnJwfOzs4IDAyEUCjUqEFWVhby8vK4GkilUpw7d07jD1hiYiIkEgn8/Py4mCfHqIppLnX08PCAk5OTxnsoLi7GiRMnNOpQWFiI9PR0LubgwYNQq9XcL2+pVIpDhw5BqVRyMYmJifDx8YG1tTUX05xrBQA3btzAvXv34OzsDMAwa8MYQ2xsLLZv346DBw9WO73WWD87TfH31PNqo83p06cBQOMzY4i1eZparYZCoWi+n5c6X5ZMmozNmzczsVjM1q9fzy5cuMAmTJjArKysNK5ib+4++OADlpKSwnJzc9nRo0dZWFgYs7OzYwUFBYyxylsXW7duzQ4ePMhOnTrFpFIpk0ql3POrbl0MDw9np0+fZnv37mX29vZab12cPn06u3jxIouPj29yt4k/fPiQZWRksIyMDAaALVmyhGVkZLBr164xxipvE7eysmI7d+5kZ8+eZa+++qrW28RfeuklduLECXbkyBHWtm1bjVuhCwsLmaOjIxsxYgTLzMxkmzdvZqamptVuhTYyMmJff/01u3jxIps3b57ebxN/Vm0ePnzIPvzwQ5aWlsZyc3PZgQMH2Msvv8zatm3LysrKuDEMrTaTJk1ilpaWLCUlReNW59LSUi6msX52mtrvqefVJjs7my1cuJCdOnWK5ebmsp07dzJPT0/Wu3dvbgxDrM2sWbNYamoqy83NZWfPnmWzZs1iPB6P7d+/nzHWPD8v1OA0c99//z1r3bo1E4lELCgoiB0/flzfKenUkCFDmLOzMxOJRKxVq1ZsyJAhLDs7m9v/+PFjNnnyZGZtbc1MTU3Za6+9xm7fvq0xxtWrV1lERAQzMTFhdnZ27IMPPmBKpVIjJjk5mXXu3JmJRCLm6enJ1q1b1xhvr9aSk5MZgGpf0dHRjLHKW8U/+eQT5ujoyMRiMQsNDWVZWVkaY9y7d48NGzaMmZubM4lEwkaPHs0ePnyoEXPmzBnWs2dPJhaLWatWrdgXX3xRLZctW7awdu3aMZFIxDp06MB2797dYO+7Np5Vm9LSUhYeHs7s7e2ZUChk7u7ubPz48dV+WRpabbTVA4DG57oxf3aa0u+p59UmLy+P9e7dm9nY2DCxWMy8vb3Z9OnTNebBYczwajNmzBjm7u7ORCIRs7e3Z6GhoVxzw1jz/LzwGGOs7sd9CCGEEEKaLroGhxBCCCEGhxocQgghhBgcanAIIYQQYnCowSGEEEKIwaEGhxBCCCEGhxocQgghhBgcanAIIYQQYnCowSGEGLSrV6+Cx+Nx0+03hFGjRiEyMpJ7HBISgqlTpzbY6xFCno8aHEJIkzZq1CjweLxqXwMGDKjV893c3HD79m107NixgTP9n23btuHTTz9ttNcjhFRnpO8ECCHkeQYMGIB169ZpbBOLxbV6rkAgaPTVmW1sbBr19Qgh1dERHEJIkycWi+Hk5KTxVbWKN4/Hw8qVKxEREQETExN4enrit99+45779CmqBw8eYPjw4bC3t4eJiQnatm2r0TydO3cO/fr1g4mJCWxtbTFhwgQ8evSI269SqRAXFwcrKyvY2tpixowZeHrFm6dPUT148AAjR46EtbU1TE1NERERgcuXLzdApQghVajBIYQ0e5988gmioqJw5swZDB8+HEOHDsXFixdrjL1w4QL27NmDixcvYuXKlbCzswMAlJSUQCaTwdraGn/++Se2bt2KAwcOIDY2lnv+N998g/Xr12Pt2rU4cuQI7t+/j+3btz8zv1GjRuHUqVP4/fffkZaWBsYYBg4cCKVSqbsiEEI01WuJTkIIaSTR0dFMIBAwMzMzja/PP/+cMVa5OvTEiRM1nhMcHMwmTZrEGGMsNzeXAWAZGRmMMcYGDx7MRo8erfW1Vq9ezaytrdmjR4+4bbt372Z8Pp9bgdzZ2ZktXryY269UKpmrqyt79dVXuW19+vRh77//PmOMsb///psBYEePHuX23717l5mYmLAtW7bUryiEkOeia3AIIU1e3759sXLlSo1tT17nIpVKNfZJpdIa75qaNGkSoqKi8NdffyE8PByRkZHo3r07AODixYvo1KkTzMzMuPgePXpArVYjKysLxsbGuH37NoKDg7n9RkZG6NKlS7XTVFUuXrwIIyMjjefY2trCx8enxqNMhJAXRw0OIaTJMzMzg7e3t07GioiIwLVr15CQkIDExESEhoYiJiYGX3/9tU7GJ4Q0DXQNDiGk2Tt+/Hi1x+3bt68x3t7eHtHR0fjPf/6Db7/9FqtXrwYAtG/fHmfOnEFJSQkXe/ToUfD5fPj4+MDS0hLOzs44ceIEt7+iogLp6ek1vlb79u1RUVGh8Zx79+4hKysLfn5+dX6vhJDaoSM4hJAmT6FQQC6Xa2wzMjLiLg7eunUrunTpgp49e2Ljxo04efIkfvrpJ61jzZ07F4GBgejQoQMUCgV27drFNUPDhw/HvHnzEB0djfnz5+POnTuYMmUKRowYAUdHRwDA+++/jy+++AJt27aFr68vlixZgsLCwhpzb9u2LV599VWMHz8eP/zwAywsLDBr1iy0atUKr776qg6qQwjRho7gEEKavL1798LZ2Vnjq2fPntz+BQsWYPPmzQgICMDPP/+MX375pcajIyKRCLNnz0ZAQAB69+4NgUCAzZs3AwBMTU2xb98+3L9/H127dsUbb7yB0NBQLF++nHv+Bx98gBEjRiA6OhpSqRQWFhZ47bXXnpn/unXrEBgYiP/7v/+DVCoFYwwJCQkQCoU6qA4hRBseq+nKOEIIaQZ4PB62b9+usVQCIYTQERxCCCGEGBxqcAghhBBicOgiY0JIs0Zn2Qkh2tARHEIIIYQYHGpwCCGEEGJwqMEhhBBCiMGhBocQQgghBocaHEIIIYQYHGpwCCGEEGJwqMEhhBBCiMGhBocQQgghBocaHEIIIYQYnP8H5uvkKal3q+gAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_episode_rewards(cumsum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats['episodes'][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats['Q-table']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_len_episodes(stats[\"episodes\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "[len(episode) for episode in stats[\"episodes\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def pi_star_from_Q(env, Q):\n",
        "    \"\"\"\n",
        "    Calcula la política óptima π* a partir de la tabla de valores Q.\n",
        "\n",
        "    Parámetros:\n",
        "        env: el entorno de Gymnasium.\n",
        "        Q: la Q-table aprendida (matriz de tamaño [S, A]).\n",
        "\n",
        "    Retorna:\n",
        "        - pi_star: un array donde cada estado tiene la acción óptima.\n",
        "        - actions: una representación en texto de las acciones seguidas en un episodio.\n",
        "    \"\"\"\n",
        "    pi_star = np.zeros(env.observation_space.n, dtype=int)  # Política óptima para cada estado\n",
        "    actions = \"\"\n",
        "\n",
        "    # Recorrer todos los estados y seleccionar la mejor acción de Q\n",
        "    for state in range(env.observation_space.n):\n",
        "        best_action = np.argmax(Q[state, :])  # Acción con mayor valor Q\n",
        "        pi_star[state] = best_action\n",
        "\n",
        "    # Simular un episodio siguiendo la política óptima para ver la secuencia de acciones\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = pi_star[state]\n",
        "        actions += f\"{action}, \"\n",
        "        state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "    return pi_star, actions.strip(\", \")\n",
        "\n",
        "pi_star, actions = pi_star_from_Q(env, stats['Q-table'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pi_star, actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0ogCwKft-Ki9"
      },
      "outputs": [],
      "source": [
        "#@title Importamos el lago helado\n",
        "name = 'FrozenLake-v1'\n",
        "env4 = gym.make(name, is_slippery=False, map_name=\"4x4\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados.\n",
        "env8 = gym.make(name, is_slippery=False, map_name=\"8x8\", render_mode=\"ansi\") # No resbaladizo para entender mejor los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1ySdi2wdXdm"
      },
      "source": [
        "## **2. Diseño del Agente**\n",
        "\n",
        "El diseño del agente consta de dos partes, el algoritmo con el que aprende y las políticas (toma de decisiones) que realiza.\n",
        "\n",
        "- **Políticas del Agente**\n",
        "   - **Política epsilon-soft**: Se define una política donde todas las acciones tienen una probabilidad de ser elegida.\n",
        "   - **Política epsilon-greedy**: basada en la política epsilon-soft. De esta forma el agente tiene una pequeña probabilidad de explorar (tomar una acción aleatoria) y una mayor probabilidad de explotar (tomar la acción que considera mejor). Esto permite equilibrar la exploración y la explotación.\n",
        "   - **Política greedy**: Es la usada una vez que \"ha aprendido\".\n",
        "\n",
        "- **Algoritmo de Iteración de Valor**\n",
        "  - Se implementa el algoritmo de iteración de valor utilizando Monte Carlo.\n",
        "  - Se usa una versión \"on-policy\" de Monte Carlo con políticas epsilon greedy sobre una política epsilon-soft.\n",
        "  - Se basa en el criterio de todas las visitas.\n",
        "  - Otro aspecto es que la actualización de los retornos no se realiza en el orden inverso a las visitas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vDI1gmKfDPT"
      },
      "source": [
        "#### **Código de las políticas y algoritmo MC**\n",
        "----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lVEIYzaJ4p8N"
      },
      "outputs": [],
      "source": [
        "# @title Políticas del agente\n",
        "\n",
        "# actions\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "\n",
        "# Política epsilon-soft. Se usa para el entrenamiento\n",
        "def random_epsilon_greedy_policy(Q, epsilon, state, nA):\n",
        "    pi_A = np.ones(nA, dtype=float) * epsilon / nA\n",
        "    best_action = np.argmax(Q[state])\n",
        "    pi_A[best_action] += (1.0 - epsilon)\n",
        "    return pi_A\n",
        "\n",
        "# Política epsilon-greedy a partir de una epsilon-soft\n",
        "def epsilon_greedy_policy(Q, epsilon, state, nA):\n",
        "    pi_A = random_epsilon_greedy_policy(Q, epsilon, state, nA)\n",
        "    return np.random.choice(np.arange(nA), p=pi_A)\n",
        "\n",
        "# Política Greedy a partir de los valones Q. Se usa para mostrar la solución.\n",
        "def pi_star_from_Q(env, Q):\n",
        "    done = False\n",
        "    pi_star = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "    state, info = env.reset() # start in top-left, = 0\n",
        "    actions = \"\"\n",
        "    while not done:\n",
        "        action = np.argmax(Q[state, :])\n",
        "        actions += f\"{action}, \"\n",
        "        pi_star[state,action] = action\n",
        "        state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "    return pi_star, actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpUWKye-7YA1"
      },
      "outputs": [],
      "source": [
        "#@title Algoritmo de Iteración de Valor versión MC con Políticas epsilon-soft\n",
        "\n",
        "def on_policy_all_visit(env, num_episodes=5000, epsilon=0.4, decay=False, discount_factor=1):\n",
        "  # Matriz de valores  Q\n",
        "  nA = env.action_space.n\n",
        "  Q = np.zeros([env.observation_space.n, nA])\n",
        "\n",
        "  # Número de visitas. Vamoa a realizar la versión incremental.\n",
        "  n_visits = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "  # Para mostrar la evolución en el terminal y algún dato que mostrar\n",
        "  stats = 0.0\n",
        "  list_stats = [stats]\n",
        "  step_display = num_episodes / 10\n",
        "\n",
        "  for t in tqdm(range(num_episodes)):\n",
        "      state, info = env.reset(seed=100)\n",
        "      done = False\n",
        "      episode = []\n",
        "      result_sum = 0.0  # Retorno\n",
        "      factor = 1\n",
        "      while not done:\n",
        "          if decay:\n",
        "            epsilon = min(1.0, 1000.0/(t+1))\n",
        "\n",
        "          action = epsilon_greedy_policy(Q, epsilon, state, nA) # GET ACTION\n",
        "          new_state, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "          done = terminated or truncated\n",
        "\n",
        "          episode.append((state, action))\n",
        "          result_sum += factor * reward\n",
        "          factor *= discount_factor\n",
        "          state = new_state\n",
        "\n",
        "      # UPDATE\n",
        "      for (state, action) in episode:\n",
        "          n_visits[state, action] += 1.0\n",
        "          alpha = 1.0 / n_visits[state, action]\n",
        "          Q[state, action] += alpha * (result_sum - Q[state, action])\n",
        "\n",
        "      # Guardamos datos sobre la evolución\n",
        "      stats += result_sum\n",
        "      list_stats.append(stats/(t+1))\n",
        "\n",
        "      # Para mostrar la evolución.  Comentar si no se quiere mostrar\n",
        "      if t % step_display == 0 and t != 0:\n",
        "          print(f\"success: {stats/t}, epsilon: {epsilon}\")\n",
        "\n",
        "  return Q, list_stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XxVyTFTfVkL"
      },
      "source": [
        "## **3. Experimentación**\n",
        "\n",
        "   - En esta sección, el algoritmo de Monte Carlo con la política epsilon-soft se ejecuta tanto para el entorno de 4x4 como al de 8x8 de FrozenLake sin resbalar.\n",
        "   \n",
        "   - En ambos casos se realiza un entrenamiento con un número determinado de episodios (5000 en concreto)\n",
        "\n",
        "   - Además en el escenario 8x8 el  epsilon tiene decaimiento de acuerdo a la expresión: $\\epsilon = min(1.0, 1000.0/(t+1))$\n",
        "\n",
        "   - Durante el entrenamiento hay una visualización de la proporción de recompensas obtenidas a lo largo del entrenamiento.\n",
        "\n",
        "   - Junto a dicho volcado se muestra gráficamente la proporcion de recompensas obtendias.\n",
        "\n",
        "   - También se hace un volcado de los valores Q de cada estado, donde se muestra cómo el agente valora diferentes acciones en distintos estados del entorno, lo que puede interpretarse como su conocimiento sobre las mejores estrategias para alcanzar la meta sin caer en los agujeros.\n",
        "\n",
        "   - Además, se muestra la política óptima derivada de los valores Q. Esta política es la que el agente seguiría si tuviera que elegir siempre la acción que maximiza su recompensa esperada.\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqdLUE8zQN2v"
      },
      "source": [
        "### **3.1 Repressentaciones Gráficas**\n",
        "\n",
        "Para comprobar el aprendizaje se mostrará la función $f(t)=\\frac{\\sum_{i=1}^t R_i}{t}$ para $t=1,2,\\ldots, NumeroEpisodios$. La justificación es la siguiente. Como sabemmos que el retorno en el estados inicial 1 (pues no hay descuento) o 9, si se divide por el número de episodios ejecutados se calcular el porcentaje de recompensas positivas obtenidas. Dicho de otra forma, nos dirá el porcentaje de veces que el agente ha llegado al estado terminal.\n",
        "\n",
        "*TODO:* Contruir una gráfica que muestre la longitud de los episodios en cada estado junto con la curva de tendencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u42-YlgazukU"
      },
      "outputs": [],
      "source": [
        "# @title Funciones para mostrar los resultados\n",
        "\n",
        "def plot(list_stats):\n",
        "  # Creamos una lista de índices para el eje x\n",
        "  indices = list(range(len(list_stats)))\n",
        "\n",
        "  # Creamos el gráfico\n",
        "  plt.figure(figsize=(6, 3))\n",
        "  plt.plot(indices, list_stats)\n",
        "\n",
        "  # Añadimos título y etiquetas\n",
        "  plt.title('Proporción de recompensas')\n",
        "  plt.xlabel('Episodio')\n",
        "  plt.ylabel('Proporción')\n",
        "\n",
        "  # Mostramos el gráfico\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "# Define la función para mostrar el tamaño de los episodios\n",
        "# Pon aquí tu código.\n",
        "\n",
        "def plot_len_episodes(episodes):\n",
        "  # Creamos una lista de índices para el eje x\n",
        "\n",
        "  # Creamos el gráfico\n",
        "  plt.figure(figsize=(6, 3))\n",
        "  plt.plot(    [len(episode) for episode in episodes]\n",
        ")\n",
        "\n",
        "  # Añadimos título y etiquetas\n",
        "  plt.title('Longirud de episodios por T')\n",
        "  plt.xlabel('Episodio T')\n",
        "  plt.ylabel('Número de pasos del episodio')\n",
        "\n",
        "  # Mostramos el gráfico\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvnGJVGF_j2j"
      },
      "source": [
        "### **3.2 Experimentación en el escenario 4x4**\n",
        "\n",
        "\n",
        "\n",
        "   - Se realizan 5000 epsisodios y se actualizan los valores Q (valor de acción) basándose en las recompensas obtenidas durante cada episodio completo (e.d. aplicamos Monte Carlo) Se apica una política $\\epsilon$ greedy sobre una política $\\epsilon$ soft con un valor $\\epsilon$ constante\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "j_Dronjr_mAN",
        "outputId": "1c0f7ad3-0686-494e-b7eb-1b4a49573329"
      },
      "outputs": [],
      "source": [
        "# @title Aprendizaje\n",
        "Q, list_stats = on_policy_all_visit(env, num_episodes=50000, epsilon=0.4, discount_factor=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pi_star, actions = pi_star_from_Q(env, Q)\n",
        "pi_star, actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "KLhdk1SFtn8S",
        "outputId": "30d22b75-74ae-4735-99a7-0401d3a836ea"
      },
      "outputs": [],
      "source": [
        "#@title Proporción de aciertos por número de episodios\n",
        "\n",
        "plot(np.cumsum(stats['episode_rewards']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoP1jHL_StI9"
      },
      "source": [
        "####.\n",
        "Mostramos los valores Q para cada estado. Cada estado tienen 4 valores, que se corresponden con las 4 acciones que se pueden en cada estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "psRtMmxyFkFq",
        "outputId": "f9e44658-ea7b-49fe-affb-b1453c055dbf"
      },
      "outputs": [],
      "source": [
        "# @title Tabla de valores Q\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "print(\"Valores Q para cada estado:\\n\", Q)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsJ-AgwcTgdO"
      },
      "source": [
        "- También se muestra la política óptima (greedy) obtenida a partir del aprendizaje anterior.\n",
        "\n",
        "- Cada estado tienen 4 valores, pero todos son 0 menos 1. Es decir, en cada estado se aplica de manera determinística una única acción.\n",
        "\n",
        "*TODO:* Mostrar de forma gráfica el escenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"|-----|-----|-----|-----|\")\n",
        "print(\"|     |     |     |     |\")\n",
        "print(\"|     |     |     |     |\")\n",
        "print(\"|-----|-----|-----|-----|\")\n",
        "print(\"|     |     |     |     |\")\n",
        "print(\"|     |     |     |     |\")\n",
        "print(\"|-----|-----|-----|-----|\")\n",
        "print(\"|     |     |     |     |\")\n",
        "print(\"|     |     |     |     |\")\n",
        "print(\"|-----|-----|-----|-----|\")\n",
        "print(\"|     |     |     |     |\")\n",
        "print(\"|     |     |     |     |\")\n",
        "print(\"|-----|-----|-----|-----|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "dA0-q-woGYL2",
        "outputId": "b5cfb689-5329-49d1-8c47-b96de08a5105"
      },
      "outputs": [],
      "source": [
        "# @title Política final\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "pi, actions = pi_star_from_Q(env4, Q)\n",
        "\n",
        "print(\"Política óptima obtenida\\n\", pi, f\"\\n Acciones {actions} \\n Para el siguiente grid\\n\", env4.render())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tUyGCBuS41T"
      },
      "source": [
        "### **3.3 Experimentación en el escenario 8x8**\n",
        "\n",
        "  - Se realizan 5000 epsisodios y se actualizan los valores Q (valor de acción) basándose en las recompensas obtenidas durante cada episodio completo (e.d. aplicamos Monte Carlo) Se apica una política $\\epsilon$ greedy sobre una política $\\epsilon$ soft con un valor $\\epsilon$ decreciente\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "ttDsqDX16sSj",
        "outputId": "ea0da61a-0fd7-4fad-b75e-f92deaaf6551"
      },
      "outputs": [],
      "source": [
        "# @title Aprendizaje\n",
        "Q, list_stats = on_policy_all_visit(env8, num_episodes=50000, epsilon=0.4, decay=True, discount_factor=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Z_tbLcAq6yWR",
        "outputId": "bd14600f-00cd-4cc1-a5d0-81f972a3a295"
      },
      "outputs": [],
      "source": [
        "#@title Proporción de aciertos por número de episodios\n",
        "\n",
        "plot(list_stats)\n",
        "print(f\"Máxima proporcion: {list_stats[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dptS3Xv8v8H7"
      },
      "source": [
        "####.\n",
        "Mostramos los valores Q para cada estado. Cada estado tienen 4 valores, que se corresponden con las 4 acciones que se pueden en cada estado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "scmn1mwlwBam",
        "outputId": "f2597e0f-bcd0-4daa-e4a3-0e939279f24a"
      },
      "outputs": [],
      "source": [
        "# @title Tabla de valores Q\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "print(\"Valores Q para cada estado:\\n\", Q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWQWD7UqwH2Y"
      },
      "source": [
        "- También se muestra la política óptima (greedy) obtenida a partir del aprendizaje anterior.\n",
        "\n",
        "- Cada estado tienen 4 valores, pero todos son 0 menos 1. Es decir, en cada estado se aplica de manera determinística una única acción.\n",
        "\n",
        "*TODO:* Mostrar de forma gráfica el escenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1n6i3oMzwSG3",
        "outputId": "0dd2772e-e096-41d8-e2ae-18d809e2b098"
      },
      "outputs": [],
      "source": [
        "# @title Política final\n",
        "LEFT, DOWN, RIGHT, UP = 0,1,2,3\n",
        "pi, actions = pi_star_from_Q(env8, Q)\n",
        "\n",
        "print(\"Política óptima obtenida\\n\", pi, f\"\\n Acciones {actions} \\n Para el siguiente grid\\n\", env8.render())\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG0Z813yhKz7"
      },
      "source": [
        "## **4. Análisis y Estudios Futuros**\n",
        "\n",
        "### **4.1 Análisis de Resultados**\n",
        "\n",
        "- En los dos entornos (4x4 y 8x8), el agente comienza con un conocimiento muy limitado, pero gradualmente mejora su desempeño a medida que avanza en los episodios. Este comportamiento se puede observar en el gráfico de la proporción de recompensas, que aumenta con el tiempo.\n",
        "- En el entorno 4x4, la máxima proporción de éxito alcanzada fue 0.522, mientras que en el entorno 8x8, la máxima alcanzada fue 0.914. Esto refleja que el agente aprendió a optimizar su estrategia en un entorno más complejo.\n",
        "- La política óptima obtenida muestra las acciones recomendadas por el agente en cada estado del entorno. En el entorno 8x8, la política es más compleja debido a la mayor cantidad de estados y la dificultad del entorno.\n",
        "\n",
        "### **4.2 Propuestas para Estudios Futuros**\n",
        "\n",
        "1. **Evaluar con Otros Entornos**: Sería interesante aplicar este algoritmo a otros entornos más complejos de `gym`, como \"Taxi-v3\" o \"MountainCar\", para analizar cómo se comporta el agente en situaciones con dinámicas más complicadas.\n",
        "   \n",
        "2. **Optimización del Decaimiento de Epsilon**: Aunque se utilizó un decaimiento de epsilon en el segundo experimento, se podría investigar la efectividad de diferentes tasas de decaimiento o incluso explorar algoritmos como `Q-learning` para comparar su desempeño. Graficamente se trataría de mostrar la curva de la tasa de aciertos para distintas funciones de decaimientos\n",
        "\n",
        "3. **Análisis del Impacto de los descuentos en las Recompensas**: El estudio se ha hecho para $\\gamma = 1$; pero no se ha probado qué pasa cuando  $0 \\leq \\gamma < 1$. Se trataría de estudiar la curva para distintos valores de $\\gamma$\n",
        "\n",
        "4. **Nuevas gráficas**: Aquí solo se ha usado la proporción de aciertos, pero sería interesante qué relación entre dicha tasa y las tamaños de los episodios.\n",
        "\n",
        "4. **Ampliación del Algoritmo**: Explorar otros enfoques de Monte Carlo o incluso combinar Monte Carlo con otros algoritmos de aprendizaje por refuerzo, como el Deep Q-Network (DQN), podría mejorar aún más los resultados en entornos más complejos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNjZJK7Hx6/LtHVZ0/ulFcl",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
